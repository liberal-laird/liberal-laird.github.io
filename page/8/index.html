<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="baidu-site-verification" content="codeva-6wmKWl5hmx" />
<meta name="bytedance-verification-code" content="GcOf/MpQ8shZ5Hh/2hvr" />
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.vvbuys.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Share some post and some issue for linux program">
<meta property="og:type" content="website">
<meta property="og:title" content="VVbugs Blog">
<meta property="og:url" content="https://www.vvbuys.com/page/8/index.html">
<meta property="og:site_name" content="VVbugs Blog">
<meta property="og:description" content="Share some post and some issue for linux program">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="vvbuys">
<meta property="article:tag" content="Linux hyprland Python Rust Golang javascript">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.vvbuys.com/page/8/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/8/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>VVbugs Blog - standalone Linux lover</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">VVbugs Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">standalone Linux lover</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">vvbuys</p>
  <div class="site-description" itemprop="description">Share some post and some issue for linux program</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">113</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96/" class="post-title-link" itemprop="url">「项目复现」S3net的训练数据集读取</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-15T00:00:00+00:00">2021-11-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		本博客是作者复现《S3Net: A Single Stream Structure for Depth Guided Image Relighting》的训练数据集读取代码的笔记。</p>
<h2 id="一、函数test-trainSet"><a href="#一、函数test-trainSet" class="headerlink" title="一、函数test_trainSet()"></a>一、函数test_trainSet()</h2><p><strong>函数功能：</strong>测试类trainDataSetFromTrack2的功能。</p>
<p>1、给出输入原始图像的路径和引导图像路径</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">origin_img_path = <span class="string">&#x27;../datasets/alltrain/*.png&#x27;</span><span class="comment"># 输入的原始图像的路径</span></span><br><span class="line">guide_img_path = origin_img_path <span class="comment"># 引导图像路径</span></span><br></pre></td></tr></table></figure>

<p>2、根据图片路径和想获取的图片数量获取数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = trainDataSetFromTrack2(origin_img_path, guide_img_path,<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>3、用DataLoader获取可以输入神经网络中的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainloader = DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>4、得到一组样本图片，iter函数将可序列化的对象序列化，next按顺序取序列化后对象的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batchdict = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainloader))</span><br></pre></td></tr></table></figure>

<p>5、获取原始图像及其深度图、引导图像及其深度图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_image, guide_image, ori_depth, guide_depth = batchdict[&#x27;x&#x27;]</span><br></pre></td></tr></table></figure>

<p>6、将图片保存到对象路径中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save_img(ori_image,&#x27;./1.png&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>函数代码：</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">test_trainSet</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    # 创建数据集</span></span><br><span class="line"><span class="function">    origin_img_path =</span> <span class="string">&#x27;../datasets/alltrain/*.png&#x27;</span># 输入的原始图像的路径</span><br><span class="line">    guide_img_path = origin_img_path # 引导图像路径</span><br><span class="line">    dataset = <span class="built_in">trainDataSetFromTrack2</span>(origin_img_path, guide_img_path,<span class="number">10</span>)# 根据图片路径读取数据集</span><br><span class="line">    trainloader = <span class="built_in">DataLoader</span>(dataset, batch_size=<span class="number">1</span>, shuffle=True, num_workers=<span class="number">0</span>)</span><br><span class="line">    # 输出信息</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练集一共有&#123;&#125;/&#123;&#125;=&#123;&#125;个的批次,其中&#123;&#125;是mini-batch&quot;</span>.format(<span class="built_in">len</span>(dataset), <span class="number">1</span>, <span class="built_in">len</span>(trainloader), <span class="number">1</span>))</span><br><span class="line">    batchdict = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainloader))# 得到一组样本数据</span><br><span class="line">    ori_image, guide_image, ori_depth, guide_depth = batchdict[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">    img_name = batchdict[<span class="string">&#x27;img_name&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(ori_image.shape)</span><br><span class="line">    <span class="built_in">print</span>(guide_image.shape)</span><br><span class="line">    <span class="built_in">print</span>(ori_depth.shape)</span><br><span class="line">    <span class="built_in">print</span>(guide_depth.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;img_name&#x27;</span>, img_name)</span><br><span class="line">    <span class="built_in">save_img</span>(ori_image,<span class="string">&#x27;./1.png&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="二、类trainDataSetFromTrack2"><a href="#二、类trainDataSetFromTrack2" class="headerlink" title="二、类trainDataSetFromTrack2"></a>二、类trainDataSetFromTrack2</h2><p><strong>类trainDataSetFromTrack2的功能：</strong>实现加载数据集所需的各个函数。</p>
<h3 id="1、类头"><a href="#1、类头" class="headerlink" title="1、类头"></a>1、类头</h3><p>该类继承自类Dataset，需要重载函数__init__()、<strong>getitem</strong>(self, index)、<strong>len</strong>(self)（这三个函数开头结尾都有两个下划线，typora文档里没显示出来）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class trainDataSetFromTrack2(Dataset):</span><br></pre></td></tr></table></figure>

<h3 id="2、成员函数-init-（）"><a href="#2、成员函数-init-（）" class="headerlink" title="2、成员函数__init__（）"></a>2、成员函数__init__（）</h3><p><strong>函数代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 origin_img_path: <span class="built_in">str</span>,  <span class="comment"># 输入文件所在的路径</span></span></span><br><span class="line"><span class="params">                 guide_img_path: <span class="built_in">str</span>,  <span class="comment"># 输出文件所在的路径</span></span></span><br><span class="line"><span class="params">                 num:<span class="built_in">int</span>,<span class="comment"># 读取的图片数量</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">    <span class="built_in">super</span>(trainDataSetFromTrack2, self).__init__()</span><br><span class="line">    <span class="comment"># 获取所有图片的路径</span></span><br><span class="line">    self.origin_img_paths, self.guide_img_paths = self._get_dataset_path(origin_img_path, guide_img_path)</span><br><span class="line">    self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.origin_img_paths)</span><br><span class="line">    <span class="comment"># 选取指定数量的图片</span></span><br><span class="line">    <span class="keyword">if</span> num &gt; <span class="number">0</span> <span class="keyword">and</span> num &lt; self.<span class="built_in">len</span>:</span><br><span class="line">        self.origin_img_paths = self.origin_img_paths[:num]</span><br><span class="line">        self.guide_img_paths =self.guide_img_paths[:num]</span><br><span class="line">        self.<span class="built_in">len</span> = num</span><br><span class="line">    <span class="comment"># 获取图像预处理函数</span></span><br><span class="line">    self.preprocess_fn = data_transform</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;含有<span class="subst">&#123;self.<span class="built_in">len</span>&#125;</span> 个样本的数据集已被创建&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>函数功能</strong>：</p>
<p>1、获取所有输入的原始图像和引导图像的路径</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.origin_img_paths, self.guide_img_paths = self._get_dataset_path(origin_img_path, guide_img_path)</span><br></pre></td></tr></table></figure>

<p>2、获取读取整个数据集的大小</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.origin_img_paths)</span><br></pre></td></tr></table></figure>

<p>3、获取指定数量的图片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> num &gt; <span class="number">0</span> <span class="keyword">and</span> num &lt; self.<span class="built_in">len</span>:</span><br><span class="line">    self.origin_img_paths = self.origin_img_paths[:num]</span><br><span class="line">    self.guide_img_paths =self.guide_img_paths[:num]</span><br><span class="line">    self.<span class="built_in">len</span> = num</span><br></pre></td></tr></table></figure>

<p>4、获取图像预处理函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.preprocess_fn = data_transform</span><br></pre></td></tr></table></figure>

<h3 id="3、成员函数-getitem-（）"><a href="#3、成员函数-getitem-（）" class="headerlink" title="3、成员函数__getitem__（）"></a>3、成员函数<code>__getitem__（）</code></h3><p><strong>函数代码</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 获取一组图片数据</span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        # 获取一组样本的路径</span><br><span class="line">        origin_img_path, guide_img_path = self.origin_img_paths[index % self.len], self.guide_img_paths[index % self.len]</span><br><span class="line">        origin_depth_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27;  # 拼接出原始图像对应深度图的路径：Image000+.npy</span><br><span class="line">        guide_depth_name = guide_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27; # 拼接出指导图像对应深度图的路径: Image001+.npy</span><br><span class="line">        truth_img_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[1]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[2]# 拼接出真实图像的路径：原始图像的前缀Image000+指导图像的后缀</span><br><span class="line">        # 读取该组样本的RGB图片</span><br><span class="line">        ori_image, guide_image,truth_img = map(self._read_rgb_img, (origin_img_path, guide_img_path,truth_img_name))</span><br><span class="line"></span><br><span class="line">        # 读取该组样本的depth图片</span><br><span class="line">        ori_depth, guide_depth = map(self._read_depth_img, (origin_depth_name, guide_depth_name))</span><br><span class="line">        # 获取该组样本对应的名称</span><br><span class="line">        img_name = origin_img_path.split(&#x27;\\&#x27;)[1]</span><br><span class="line">        return &#123;&#x27;x&#x27;:(ori_image, guide_image, ori_depth, guide_depth),</span><br><span class="line">                &#x27;y&#x27;:truth_img,</span><br><span class="line">                &#x27;img_name&#x27;:img_name&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>函数功能</strong>：根据序号index，获取一组样本图片。</p>
<p>1、获取原始图像及其深度图、引导图像及其深度图、真实图像的路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 根据序号index，获取原始图像、引导图像的路径</span><br><span class="line">origin_img_path, guide_img_path = self.origin_img_paths[index % self.len], self.guide_img_paths[index % self.len]</span><br><span class="line"># 拼接出原始图像对应深度图的路径：Image000+.npy</span><br><span class="line">origin_depth_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27; </span><br><span class="line"># 拼接出指导图像对应深度图的路径: Image001+.npy</span><br><span class="line">guide_depth_name = guide_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27;</span><br><span class="line"># 拼接出真实图像的路径：原始图像的前缀Image000+指导图像的后缀</span><br><span class="line">truth_img_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[1]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[2]</span><br></pre></td></tr></table></figure>

<p>2、# 读取该组样本的RGB图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_image, guide_image,truth_img = map(self._read_rgb_img, (origin_img_path, guide_img_path,truth_img_name))</span><br></pre></td></tr></table></figure>

<p>map（）相当于调用了函数self._read_rgb_img三次，以上代码还可以写为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ori_image = self._read_rgb_img(origin_img_path)</span><br><span class="line">guide_image = self._read_rgb_img(guide_img_path)</span><br><span class="line">truth_img = self._read_rgb_img(truth_img_name)</span><br></pre></td></tr></table></figure>

<p>3、读取该组样本的depth图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_depth, guide_depth = map(self._read_depth_img, (origin_depth_name, guide_depth_name))</span><br></pre></td></tr></table></figure>

<p>4、返回读取的这组样本图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">return &#123;&#x27;x&#x27;:(ori_image, guide_image, ori_depth, guide_depth),</span><br><span class="line">        &#x27;y&#x27;:truth_img,</span><br><span class="line">        &#x27;img_name&#x27;:img_name&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4、成员函数-len-（）"><a href="#4、成员函数-len-（）" class="headerlink" title="4、成员函数 __len__（）"></a>4、成员函数 <code>__len__（）</code></h3><p><strong>函数功能：</strong>返回读取图片的数量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> self.<span class="built_in">len</span></span><br></pre></td></tr></table></figure>

<h3 id="5、成员函数-read-rgb-img（）"><a href="#5、成员函数-read-rgb-img（）" class="headerlink" title="5、成员函数_read_rgb_img（）"></a>5、成员函数<code>_read_rgb_img（）</code></h3><p>类中的成员函数加上一个下划线_，这样类外就不能访问该函数。</p>
<p><strong>函数功能：</strong>根据给定的图片路径，获取图片张量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_read_rgb_img</span>(<span class="params">self,img_path</span>):</span><br><span class="line">    img = Image.<span class="built_in">open</span>(<span class="built_in">str</span>(img_path))  <span class="comment"># （1024,1024,4）</span></span><br><span class="line">    image_tensor = self.preprocess_fn(img)  <span class="comment"># tensor，size=（4,1024,1024）</span></span><br><span class="line">    image_tensor = image_tensor[:<span class="number">3</span>, :, :]  <span class="comment"># tensor，size=（3,1024,1024）</span></span><br><span class="line">    <span class="keyword">return</span> image_tensor</span><br></pre></td></tr></table></figure>

<h3 id="6、成员函数-read-depth-img（）"><a href="#6、成员函数-read-depth-img（）" class="headerlink" title="6、成员函数_read_depth_img（）"></a>6、成员函数<code>_read_depth_img（）</code></h3><p><strong>函数功能：</strong>根据给定的图片路径，获取深度图片张量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def _read_depth_img(self,depth_path):</span><br><span class="line">    depth = np.load(depth_path, allow_pickle=True).item()[&#x27;normalized_depth&#x27;]</span><br><span class="line">    ori_depth = torch.unsqueeze(torch.from_numpy(depth), 0)  # 升维(1,1024,1024)</span><br><span class="line">    #ori_depth = torch.unsqueeze(ori_depth, 0)  # 升维(1,1,1024,1024)</span><br><span class="line">    return ori_depth</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="7、成员函数-get-dataset-path（）"><a href="#7、成员函数-get-dataset-path（）" class="headerlink" title="7、成员函数_get_dataset_path（）"></a>7、成员函数<code>_get_dataset_path（）</code></h3><p><strong>函数功能：</strong>根据给定的图片文件夹的路径，获取图片文件夹中所有图片的路径。</p>
<p>glob.glob函数：搜索所有满足条件的项。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def _get_dataset_path(self, input_file_path, target_file_path):</span><br><span class="line">    origin_img_paths = sorted(glob.glob(input_file_path, recursive=True))</span><br><span class="line">    guide_img_paths = glob.glob(target_file_path, recursive=True)</span><br><span class="line">    random.shuffle(guide_img_paths)</span><br><span class="line">    #assert len(origin_img_paths) == len(guide_img_paths)</span><br><span class="line">    return origin_img_paths, guide_img_paths</span><br></pre></td></tr></table></figure>

<h3 id="三、数据增强手段"><a href="#三、数据增强手段" class="headerlink" title="三、数据增强手段"></a>三、数据增强手段</h3><p>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h3 id="四、函数save-img"><a href="#四、函数save-img" class="headerlink" title="四、函数save_img()"></a>四、函数save_img()</h3><p><strong>函数功能：</strong>把图片张量tensor_img保存到输出文件夹output_dir中。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_img</span>(<span class="params">tensor_img,output_dir</span>):</span><br><span class="line">    <span class="comment"># 保存图像</span></span><br><span class="line">    torchvision.utils.save_image(tensor_img, output_dir)</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-05-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-05-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">「项目复现」S3net的损失函数实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-05 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-05T00:00:00+00:00">2021-11-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>《S3Net: A Single Stream Structure for Depth Guided Image Relighting》是来自中国台湾的Hao-Hsiang Yang等人发表在CVPR 2021（CCF推荐的A类会议）上的一篇WorkShip论文，本文是其项目训练代码的关键复现流程。</p>
<p>​		本博客是复现《S3Net: A Single Stream Structure for Depth Guided Image Relighting》的损失函数实现。该项目的S3Net一共使用了三个损失函数，其整体损失如下：<br>$$<br>L_{\text {Total }}&#x3D;\lambda_{1} L_{\text {cha }}+\lambda_{2} L_{W-S S I M}+\lambda_{3} L_{P e r}<br>$$<br>​		其中 $\lambda_{1}$、$\lambda_{2}$ 和 $\lambda_{3}$ 是缩放系数，用于调整三个分量的相对权重。</p>
<h1 id="一、Charbonnier-损失"><a href="#一、Charbonnier-损失" class="headerlink" title="一、Charbonnier 损失"></a>一、Charbonnier 损失</h1><p>​		该损失函数来自于《A general and adaptive robust loss function》，其可以看做是一个高鲁棒性的L1损失函数，该损失函数可以还原全局结构并且可以更鲁棒地处理异常值，其公式如下：<br>$$<br>L_{C h a}(I, \hat{I})&#x3D;\frac{1}{T} \sum_{i}^{T} \sqrt{\left(I_{i}-\hat{I}_{i}\right)^{2}+\epsilon^{2}}<br>$$<br>​       其中$I$ 和$\hat{I}$ 分别代表目标图像和该文网络输出的预测图像， $\epsilon$被视为一个微小的常数（例如$10^{-6}$​）,用来实现稳定和鲁棒的收敛。根据这篇超分辨领域的论文《Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks》，采用该函数可以使得模型的收敛速度加快。其实现代码相对简单“</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">L1_Charbonnier_loss</span>(torch.nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;L1 Charbonnierloss.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(L1_Charbonnier_loss, self).__init__()</span><br><span class="line">        self.eps = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        diff = torch.add(X, -Y)</span><br><span class="line">        error = torch.sqrt(diff * diff + self.eps)</span><br><span class="line">        loss = torch.mean(error)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<h1 id="二、SSIM-损失"><a href="#二、SSIM-损失" class="headerlink" title="二、SSIM 损失"></a>二、SSIM 损失</h1><p>​		该损失函数来自于《Loss functions for image restoration with neural networks》 ，其能够重建局部纹理和细节。 可以表示为：<br>$$<br>L_{S S I M}(I, \hat{I})&#x3D;-\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(2 \sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}\right)}<br>$$<br>​		 其中 σ 和 µ 表示图像的标准偏差、协方差和均值。 </p>
<p>​		在图像重照明任务中，为了从原始图像中去除阴影，该文扩展了 SSIM 损失函数，以便使网络可以恢复更详细的部分。 </p>
<p>​		该文使用《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》 中的方法将 DWT 组合到 SSIM 损失中，这有利于重建重光照图像的清晰细节。最初，DWT 将预测图像分解为四个不同的小sub-band图像。 操作可以表示为：<br>$$<br>\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}&#x3D;\operatorname{DWT}(\hat{I})<br>$$</p>
<p>​       其中上标表示来自各个过滤器的输出（例如，$$\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}$$）。</p>
<p>​       $$\hat{I}^{H L}, \hat{I}^{L H}, \hat{I}^{H H}$$分别是水平边缘、垂直边缘和角点检测的高通滤波器。  fLL 被视为下采样操作。 此外，DWT 可以不断分解$$\hat{I}^{L L}$$ 以生成具有不同尺度和频率信息的图像。 这一步写成：<br>$$<br>\hat{I}<em>{i+1}^{L L}, \hat{I}</em>{i+1}^{L H}, \hat{I}<em>{i+1}^{H L}, \hat{I}</em>{i+1}^{H H}&#x3D;\operatorname{DWT}\left(\hat{I}<em>{i}^{L L}\right)<br>$$<br>​       其中下标 i 表示第 i 次 DWT 迭代的输出。 上述 SSIM 损失项是根据原始图像对和各种子带图像对计算得出的。  SSIM损失和DWT的融合整合为：<br>$$<br>\begin{array}{l}<br>L</em>{W-S S I M}(I, \hat{I})&#x3D;\sum_{0}^{r} \gamma_{i} L_{\mathrm{SSIM}}\left(I_{i}^{w}, \hat{I}<em>{i}^{w}\right) \<br>w \in{L L, H L, L H, H H}<br>\end{array}<br>$$<br>其中$\gamma</em>{i}$​  基于原文来控制不同补丁的重要性。</p>
<p>​		这里的实现我们参考了<a target="_blank" rel="noopener" href="https://github.com/dectrfov/Y-net/tree/master/pytorch_ssim">wavelet_ssim</a>的实现。</p>
<h1 id="三、感知损失"><a href="#三、感知损失" class="headerlink" title="三、感知损失"></a>三、感知损失</h1><p>​		该损失函数来自于2016年代ECCV会议的《Perceptual losses for real-time style transfer and super-resolution》，该论文在图像转换问题中使用感知损失（perceptual loss）函数代替之前的逐像素（per-pixel）损失函数，结果在速度和图片质量上均得到了大幅度提升。</p>
<p>​		感知损失定义为<br>$$<br>L_{P e r}(I, \hat{I})&#x3D;\mid(\operatorname{VGG}(I)-\operatorname{VGG}(\hat{I}) \mid<br>$$</p>
<p>​		其中$\mid·\mid$ 是绝对值。</p>
<p>​		该损失函数利用从预训练的深度神经网络（例如 VGG19 （《Very deep convolutional networks for large-scale image recognition》））中获得的多尺度特征，然后使用L1损失来测量预测图像和目标图像之间的视觉特征差异，从而使得训练的图像尽可能地逼近目标图像。该项目使用在ImageNet 上预训练的 VGG19 被用作损失函数网络。</p>
<p>​		首先使用代码获取vgg19模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="comment"># 加载预训练的模型</span></span><br><span class="line">vgg_model = models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg_model.features)</span><br></pre></td></tr></table></figure>

<p>​		vgg19整体结构分为’features’, ‘avgpool’, 和 ‘classifier’三大部分,而计算损失函数只需要用到’features’部分，打印其结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">3</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">6</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">8</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">11</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">13</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">15</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">16</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">17</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">18</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">19</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">20</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">22</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">23</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">24</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">25</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">26</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">27</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">29</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">30</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">31</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">32</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">33</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">34</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">35</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">36</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这里我们使用[DRN项目中的vggloss](<a target="_blank" rel="noopener" href="https://github.com/WangLiwen1994/DeepRelight/blob/master/models/networks.py">DeepRelight&#x2F;networks.py at master · WangLiwen1994&#x2F;DeepRelight (github.com)</a>)的实现来获取多尺度特征，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vgg19</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, requires_grad=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Vgg19, self).__init__()</span><br><span class="line">        <span class="comment"># vgg_pretrained_features = models.vgg19(pretrained=True).features # #pretrained是true，导入预训练模型</span></span><br><span class="line">        <span class="comment"># 加载预训练模型</span></span><br><span class="line">        vgg19_model = models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 获取中间层特征</span></span><br><span class="line">        vgg_pretrained_features = vgg19_model.features</span><br><span class="line"></span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line">        self.slice5 = torch.nn.Sequential()</span><br><span class="line">        <span class="comment"># 获取中间层特征，把不同层的特征分别加入不同的模块</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            self.slice1.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">7</span>):</span><br><span class="line">            self.slice2.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>, <span class="number">12</span>):</span><br><span class="line">            self.slice3.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>, <span class="number">21</span>):</span><br><span class="line">            self.slice4.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>, <span class="number">28</span>):</span><br><span class="line">            self.slice5.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="comment"># 设置所有参数都不需要计算梯度，使得之后不进行反向传播及权重更新</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> self.parameters():</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        h_relu1 = self.slice1(X)</span><br><span class="line">        h_relu2 = self.slice2(h_relu1)</span><br><span class="line">        h_relu3 = self.slice3(h_relu2)</span><br><span class="line">        <span class="comment">#h_relu4 = self.slice4(h_relu3)</span></span><br><span class="line">        <span class="comment">#h_relu5 = self.slice5(h_relu4)</span></span><br><span class="line">        <span class="comment">#out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]</span></span><br><span class="line">        out = [h_relu1, h_relu2, h_relu3]<span class="comment">#, h_relu4, h_relu5]</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGGLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, gpu_ids</span>):</span><br><span class="line">        <span class="built_in">super</span>(VGGLoss, self).__init__()</span><br><span class="line">        self.vgg = Vgg19().cuda()</span><br><span class="line">        self.criterion = nn.L1Loss() <span class="comment"># L1损失，平均绝对值损失</span></span><br><span class="line">        self.weights = [<span class="number">1.0</span> / <span class="number">32</span>, <span class="number">1.0</span> / <span class="number">16</span>, <span class="number">1.0</span> / <span class="number">8</span>, <span class="number">1.0</span> / <span class="number">4</span>, <span class="number">1.0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        x_vgg, y_vgg = self.vgg(x), self.vgg(y)</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_vgg)):</span><br><span class="line">            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91DRN%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%85%89%E6%BA%90%E6%93%8D%E7%BA%B5%E7%9A%84%E6%B7%B1%E5%BA%A6%E9%87%8D%E5%85%89%E7%85%A7%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91DRN%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%85%89%E6%BA%90%E6%93%8D%E7%BA%B5%E7%9A%84%E6%B7%B1%E5%BA%A6%E9%87%8D%E5%85%89%E7%85%A7%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">「论文分享」DRN:用于图像光源操纵的深度重光照网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-04 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-04T00:00:00+00:00">2021-11-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		《Deep Relighting Networks for Image Light Source Manipulation》是发表在ECCV 2020上的一篇论文。这里是<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2008.08298"><strong>原文链接</strong></a>和<a target="_blank" rel="noopener" href="https://github.com/WangLiwen1994/DeepRelight"><strong>原文代码</strong></a></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​       操纵给定图像的光源的现有的方法通常需要额外的信息，如场景的几何结构，这可能不适用于大多数图像<strong>。在本文中，我们用公式表示单图像重照明任务，并提出了一种新的深度重照明网络（DRN）</strong>，该网络由三部分组成：</p>
<p>1）场景重建，其目的是通过深度自动编码网络显示主要场景结构，</p>
<p>2）阴影先验估计，通过对抗性学习，从新的灯光方向预先确定灯光效果，</p>
<p>3）重新渲染，将主要结构与重建的阴影视图结合起来，形成目标光源下所需的估计图像。</p>
<p>​         实验结果表明，该方法在定性和定量上都优于其他方法。具体而言，提出的DRN在2020年ECCV大会的“AIM2020-任何对一重新照明挑战”中实现了最佳峰值信噪比。</p>
<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>​         图像是这个信息时代流行的信息载体，直观易懂。 显示设备的快速发展刺激了人们对高质量画面的需求。 图像的视觉外观与照明高度相关，这在摄影和电影摄影等各种应用中至关重要。 不适当的照明通常会导致各种视觉退化问题，例如不想要的阴影和扭曲的颜色。 然而，光源（如太阳光）难以控制，或者有时无法改变（对于捕获的图像），因此很难生成令人满意的图像。 在拍摄的图像上产生想要的光源效果的方法已经是非常引人关注的高科技方法，因为它可以修改拍摄图像的光照。</p>
<p>​       已经提出了一些方法，旨在减轻由不适当照明引起的退化。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>论文</th>
<th>主要内容</th>
</tr>
</thead>
<tbody><tr>
<td>直方图均衡化 histogram equalization (HE)</td>
<td>[37]《Contrast limited adaptive histogram equalization based enhancement for real time video system》</td>
<td>重新排列强度以服从均匀分布，这可以增加对低对比度区域的识别。 它操纵全局光条件，平衡了整个图像的照明。</td>
</tr>
<tr>
<td>高动态范围 (HDR) 领域中的方法</td>
<td>[3] 《Recovering high dynamic range radiance  maps from photographs》、[36]《Deep high dynamic range imaging 》</td>
<td>通过增加低对比度区域的动态范围来提高图像质量。HDR 方法可以看作是局部对比度的细化，但缺乏对全局光的调整。</td>
</tr>
<tr>
<td>基于 Retinex 的方法</td>
<td>[29]《Retinex processing for auto-matic image enhancement》、[35]《Deep retinex decomposition for low -light enhancement》</td>
<td>将图像分离为光照和反射率的组合，其中反射存储场景的固有内容，在不同的照明条件下无法改变。 通过细化光照，可以提高图像的视觉质量。</td>
</tr>
<tr>
<td>低光图像增强方法</td>
<td>[15]《 Enlightengan: Deep light enhancement without paired supervision》【32】《Lightening network for low-light image enhancement》</td>
<td>改善黑暗环境的可见度，以照亮整个画面。</td>
</tr>
<tr>
<td>阴影去除</td>
<td>【13】《Direction-aware spatial context features for shadow detection》、【18】《Shadow removal via shadow image decomposition》</td>
<td>旨在消除光源造成的阴影效果，但不能模拟目标光源的阴影。</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>​        调整光源为基于照明的图像增强提供了一种灵活而自然的方式。 尽管已经进行了大量的研究来改进照明，但从操纵光源的角度进行研究的效果较小。 也就是说，通过控制光源来改变光照效果还处于设想阶段。 重新照明领域的文献主要关注特定应用，</p>
<p>例如</p>
<table>
<thead>
<tr>
<th>人像重新照明</th>
<th>人像重新照明相关论文</th>
</tr>
</thead>
<tbody><tr>
<td>人像重新照明：这些方法需要在一般场景中无法实现的先验信息（如面部标志、几何先验）。</td>
<td>【26】《Learning physics-guided face relighting under directional light》【31】《Single image portrait relighting》【40】《Deep single-image portrait relighting》</td>
</tr>
</tbody></table>
<p>​        卷积神经网络（CNN）最近因其强大的学习能力而备受关注。 它可以在强大的计算资源的支持下消化大量的训练数据并 提取有识别力的表征 。CNN 在各种任务中显示出显着的优势，例如</p>
<p>图像分类 [17,30]、语义分割 [27,38]、超分辨率 [8,23]、位置识别 [1,19] 等。 由于浅层的参数往往面临梯度消失和爆炸的风险，因此难以训练。残差学习 《 Deep residual learning for image recognition》 通过在每个处理块之间添加shortcut连接来减轻优化难度。 在归一化层的帮助下，梯度可以稳定地从深层流向浅层，极大地提高了深度网络的训练效率。 更深的结构通常意味着更多可训练的参数，因此可以带来更强大的学习能力，这使得可以处理更具挑战性的任务，例如单幅图像重新照明。</p>
<p>​        本文中的图像重光照方法侧重于使用强大的深度 CNN 架构来操纵光源的位置和色温。 它不仅可以调整主色调，还可以重新投射给定图像的阴影。 如图 1 所示，我们专注于特定的“any-to-one”重新照明任务，其输入:在任意光源（任意方向或色温，见图 1（a））下的凸显，目标是 估计特定光源下的图像（方向：E，色温：4500K，见图1（b））。 所提出的方法可以推广到其他与光相关的任务。 </p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211104233058382.png" alt="image-20211104233058382"></p>
<p>本文方法的创新点：</p>
<p>  1、我们不是将输入图像直接映射到目标光照条件，而是将重新照明任务分为三个部分：场景重建、光照效果估计和重新渲染过程。</p>
<p>   2、 为了保留下采样和上采样过程的更多信息，我们将反投影理论插入到自动编码器结构中，这有利于场景重建和光照效果估计。</p>
<p>   3、 光照效果难以衡量，增加了训练难度。 我们使用对抗性学习策略：新的阴影区域鉴别器，为训练过程提供指导。</p>
<h2 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h2><h2 id="Back-Projection-BP-theory"><a href="#Back-Projection-BP-theory" class="headerlink" title="Back-Projection (BP) theory"></a><strong>Back-Projection (BP) theory</strong></h2><table>
<thead>
<tr>
<th>相关工作</th>
<th>相关论文</th>
</tr>
</thead>
<tbody><tr>
<td>关于低光图像增强的工作 [32]</td>
<td>Lightening network for low-light image enhancement</td>
</tr>
<tr>
<td>BP理论在单图像超分辨率领域很流行[9,20,21]。基于 BP 的方法不是直接学习从输入到目标的映射，而是迭代地消化残差并改进估计。 它更加关注学习过程中出现的弱点（即残差），这显着提高了深度 CNN 架构的效率。</td>
<td>【9】《Deep back-projection networks for super-resolution》、【20】《 Hierarchical back projection network for image super-resolution》、【21】《Image super-resolution via attention based back projection networks》。</td>
</tr>
</tbody></table>
<p>​        关于低光图像增强的工作 [32] 将 BP 理论扩展到光域传输任务。 它假设低光 (LL) 和正常光 (NL) 图像分别位于 LL 和 NL 域。 首先，一个lightening算子从 LL 输入预测 NL 估计。 然后，darkening算子将 NL 估计映射回 LL 域（LL 估计）。 在 LL 域中，可以找到 LL 输入和 LL 估计之间的差异（LL 残差），这表明两个转移算子（变亮和变暗lightening and darkening）的弱点。 之后，LL 残差通过另一个lightening算子映射回 NL 域（NL 残差）。  NL 残差然后细化 NL 估计以获得更好的输出。 从数学上讲，enlightening过程可以写为：</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211104234138291.png" alt="image-20211104234138291"></p>
<p>​         其中 L 和 ˆN ∈ RH×W×3 分别表示 LL 输入图像和 NL 估计。  H、W 和 3分别代表高度、宽度和 RGB 通道。 符号 L1 和 L2 是两个lightening算子，分别照亮 LL 图像和 LL 残差。 符号 D 是将 NL 估计映射到 LL 域的Darkening算子。两个加权系数 λ1 和 λ2 ∈ R 用于平衡残差计算和最终细化。</p>
<h2 id="Adversarial-Learning"><a href="#Adversarial-Learning" class="headerlink" title="Adversarial Learning"></a><strong>Adversarial Learning</strong></h2><p>​        将图像转换为相应的输出图像通常形成为像素级回归任务，其损失函数（如 L1 或 L2 范数损失）表示所有像素的平均误差。 这种损失函数忽略了像素之间的相互关系，容易扭曲感知结构，导致输出模糊。 大量的研究工作已经完成了图像之间感知相似性的定量测量，如结构相似性（SSIM）[34]《Image quality assessment: from error visibility to structural similarity》、学习感知图像块相似性（LPIPS）[39]《The unreasonable effffectiveness of deep features as a perceptual metric》、Gram矩阵[6]《A neural algorithm of artistic style》等。 然而，感知评估基本上因不同的视觉任务而异，难以制定。</p>
<p>​       生成对抗网络 (GAN) [7,14,25] 【7】《Generative adversarial nets》【14】《Image-to-image translation with conditional adversarial networks》【25】《 Conditional generative adversarial nets》提供了一种新颖的解决方案，将感知测量嵌入到对抗学习的过程中。 每个 GAN 由一个生成器和一个鉴别器组成。鉴别器旨在在目标图像中找到潜在的感知结构，然后指导生成器的训练。 随后，生成器提供次优估计，作为鉴别器训练过程的负样本。 对于分组的负和正（目标图像）样本，判别器执行二元分类任务，测量两类样本之间的潜在感知差异。 整个训练过程是</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211105180808841.png" alt="image-20211105180808841"></p>
<p>​       其中 D 和 G 分别表示鉴别器和生成器。 项 X 和 Y 分别代表输入和目标图像。 在训练过程中，生成器和判别器进行两人的极小极大博弈。 鉴别器学习区分估计图像 G(X) 和目标图像 Y。生成器旨在最小化估计 G(X) 和目标图像 Y 之间的差异。训练过程遵循对抗性学习策略， 越来越多地学习和使用目标图像内的潜在分布。 最后，训练将达到动态平衡，其中生成器产生的估计具有与真实目标图像相似的潜在感知结构。</p>
<h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><p>​         如图 2 所示，所提出的深度重新照明网络 (DRN) 由三部分组成：场景重建、阴影先验估计和重新渲染器。 首先，输入图像在场景重建网络（见第 3.2 节）中处理以去除照明的影响，这从输入图像中提取固有结构。 同时，另一个分支（阴影先验估计，见3.3节）侧重于光照效果的变化，根据目标光源重新投射阴影。 接下来，重新渲染器部分（参见第 3.4 节）感知光照效果并在结构信息的支持下重新绘制图像。 场景重建和阴影先验估计网络都具有类似的深度自动编码器结构，这是一种Pix2Pix网络增强的变体。三个组件的细节展示如下：</p>
<h3 id="3-1-Assumption-of-Relighting"><a href="#3-1-Assumption-of-Relighting" class="headerlink" title="3.1 Assumption of Relighting"></a>3.1 Assumption of Relighting</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">「论文分享」S3net：深度引导图像重照明的单流结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-04 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-04T00:00:00+00:00">2021-11-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		《S3Net: A Single Stream Structure for Depth Guided Image Relighting》是来自中国台湾的Hao-Hsiang Yang等人发表在CVPR 2021（CCF推荐的A类会议）上的一篇WorkShip论文，这里是<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Yang_S3Net_A_Single_Stream_Structure_for_Depth_Guided_Image_Relighting_CVPRW_2021_paper.pdf">原文链接</a>和<a target="_blank" rel="noopener" href="https://github.com/dectrfov/NTIRE-2021-Depth-Guided-Image-Any-to-Any-relighting">原文代码</a>。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​		深度引导（Depth guided）的任意到任意（ any-to-any）图像重光照的目的是通过原始图像和相应的深度图生成重照明的图像，来匹配给定引导图像及其深度图的照明设置。 据该文所称，这项任务是一个在以前的文献中没有提及过的新挑战。 </p>
<p>​		为了解决这个问题，该文提出了一种基于深度学习的单流结构的神经网络，称为S3Net。 该网络是一个编码器-解码器（ encoder-decoder）模型，其输入是 原始图像、引导图像和相应的深度图，共计4张图（2张RGB图+2张深度图）。 该网络的特点是向解码器部分中加入了注意力模块和增强模块，用来关注引导图像中与重照明相关的区域。</p>
<p>​		最终的实验表明，该论文提出的模型在竞赛（the NTIRE 2021 Depth Guided Any-to-any Relighting Challenge）中实现了第三高的SSIM。</p>
<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>​		图像重照明是一项新兴且关键的技术，其在可视化、图像编辑和增强现实 (AR) 中的具有较大应用潜力，例如为第一人称和第三人称游戏渲染具有各种环境照明条件的图像。该文的目的是解决深度引导的any to any的重光照任务，该任务的特点是用引导图像的照明设置来重新照明输入图像。这里给出一组图像说明：</p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\any_to_any图像.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/any_to_any%E5%9B%BE%E5%83%8F.png"></p>
<h3 id="1、any-to-any重光照任务和风格转换的异同点："><a href="#1、any-to-any重光照任务和风格转换的异同点：" class="headerlink" title="1、any-to-any重光照任务和风格转换的异同点："></a>1、any-to-any重光照任务和风格转换的异同点：</h3><table>
<thead>
<tr>
<th>任务类型</th>
<th>相同点</th>
<th>不同点</th>
</tr>
</thead>
<tbody><tr>
<td>风格迁移</td>
<td>输入是原始图像和引导图像</td>
<td>风格迁移一般侧重于纹理渲染</td>
</tr>
<tr>
<td>（any to any）重光照</td>
<td>输入是原始图像和引导图像（及其深度图）</td>
<td>需要去除原始图像的阴影，并且在预测图像中生成新的阴影，风格转换一般做不到这点</td>
</tr>
</tbody></table>
<h3 id="2、any-to-any重光照任务的相关研究"><a href="#2、any-to-any重光照任务的相关研究" class="headerlink" title="2、any-to-any重光照任务的相关研究"></a>2、any-to-any重光照任务的相关研究</h3><p>​		因为深度卷积神经网络 (CNN) 在许多计算机视觉任务中取得了成功，而且之前的重光照方法都直接使用CNN并遵循端到端（end-to-end）的方式直接生成重光照图像（没有假定任何物理先验），受这些方法的启发，该文依旧使用深度学习网络来解决深度引导的任意对任意重照明任务。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Puthussery和Kuriakose等人，2020</td>
<td>WDRN: A wavelet decomposed relightnet for image relighting</td>
<td>2</td>
</tr>
<tr>
<td>Hu和Huang等人 ,ECCV，2020</td>
<td>SA-AE for any-to-any relighting</td>
<td>3</td>
</tr>
<tr>
<td>Guo和Liao等人，BMVC，2019</td>
<td>Deep learning fusion of rgb and depth images for pedestrian detection</td>
<td>4</td>
</tr>
<tr>
<td>Xu和Sunkavalli等人, ToG，2018</td>
<td>Deep image-based relighting from optimal sparse samples</td>
<td>5</td>
</tr>
<tr>
<td>Yang和Chen等人，CVPRW，2021</td>
<td>Multi modal bifurcated network for depth guided image relighting</td>
<td>6</td>
</tr>
</tbody></table>
<p>​		与传统的图像重光照任务不同，该文使用了NTIRE 2021竞赛中提供的额外的深度图，这有利于模型学习场景的物理空间表示。 </p>
<p>​		该文在解码器部分使用了多尺度特征提取器和注意力机制，多尺度特征提取器 可用于增加感受野并整合粗到细的表示，有必要采用这个模块，因为重光照图像包含各种尺度的对象；注意力机制可以分配特征图权重来放大局部区域的特征，由于重光照图像包含方向信息，使用注意力机制有利于模型学习方向的特征表示。</p>
<p>​		该文在 VIDIT 数据集上测试了我们提出的方法，多个实验表明，所提出的 S3Net 在 NTIRE 2021 深度引导任意对任意重新照明挑战中实现了第三高的 SSIM 和 MPS。</p>
<p>​		笔者认为该文的创新点或贡献如下：</p>
<p>1、提出了一个单流结构网络 (S3Net)处理any to any重光照任务</p>
<p>2、为了设计一个高效的图像重照明网络，在解码器部分加入了注意力模块和增强模块</p>
<p>3、为了进一步优化模型，该文在目标函数上使用了结合了离散小波变换（DWT）理论的多尺度损失函数，提升了准确性。</p>
<h1 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h1><h2 id="1、带有深度图的图像处理"><a href="#1、带有深度图的图像处理" class="headerlink" title="1、带有深度图的图像处理"></a>1、带有深度图的图像处理</h2><p>​       与传统的只使用RGB图像的计算机视觉任务不同，使用额外的深度信息可以提高许多计算机视觉任务的准确性，当与 RGB 图像结合使用时，深度图已被证明是提供几何和空间信息的有用提示。</p>
<p>​	   2019年Guo和Liao等人的《Deep learning fusion of rgb and depth images for pedestrian detection》，提出了 Faster RCNN模型来解决行人检测问题，该工作证明可以利用深度图来细化从 RGB 图像中提取的卷积特征， 而且可以在深度信息的帮助下探索透视投影，从而实现更准确的区域建议。</p>
<p>​	   2020年Chen和Lin等人的ECCV上的《Bi-directional cross-modality feature propagation with separation-and-aggregation gate for rgb-d semantic segmentation》中，提出了一种统一且高效的跨模态引导的语义分割编码器。 这种结构在跨模态聚合之前联合过滤和重新校准两种表示。 同时，引入了双向多步传播策略以有效融合两种模态之间的信息。  </p>
<p>​		为了有效地提取 RGB 图像和深度特征，最流行的方法是使用双流主干网络的结构，如下相关研究： </p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Pang和Zhang等人，2020</td>
<td>Hierarchical dynamic filtering network for rgb-d salient object detection</td>
<td>使用双流主干，输入为RGB图像和深度图</td>
</tr>
<tr>
<td>Chen和Fu等人 ,ECCV，2020</td>
<td>Progressively guided alternate refinement network for rgb-d salient object detection</td>
<td>使用双流主干，输入为RGB图像和深度图</td>
</tr>
</tbody></table>
<p>​		然后，VIDIT 数据集中重光照图像的大小和相应的深度图非常大（1024×1024），且每次输入都是两个RGB图像和两个深度图，所以这种输入会在双主干网络结构中造成巨大的计算负担，而且论文作者认为重光照图像包含光源方向信息，这不适合在训练期间将大图像裁剪为小块， 所以该文设计了一个单一的流结构来联合提取深度和图像特征。</p>
<h2 id="2、基于深度学习的图像重光照"><a href="#2、基于深度学习的图像重光照" class="headerlink" title="2、基于深度学习的图像重光照"></a>2、基于深度学习的图像重光照</h2><p>​        在NTIRE 2021的竞赛规则中，有两种重光照任务设置：</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>相关研究</strong></th>
</tr>
</thead>
<tbody><tr>
<td>one-to-one重光照</td>
<td>光源方向和光源色温是预先定义的</td>
<td>《WDRN: A wavelet decomposed relightnet for image relighting》、《Multi modal bifurcated network for depth guided image relighting》</td>
</tr>
<tr>
<td>any-to-any重光照</td>
<td>光源方向和光源色温是基于一张引导图像</td>
<td>《SA-AE for any-to-any relighting》</td>
</tr>
</tbody></table>
<p>​		由于都是图像到图像的转换任务，重光照任务似乎与其他低级计算机视觉任务非常相似，例如图像去雾 、图像烟雾去除、图像去雪、反射去除和水下图像增强等，但是与它们不同的是，重光照任务包含光源方向和色温的信息，需要在预测图像中估计物体的阴影。 </p>
<p>​		图像到图像的转换任务经常使用编码器-解码器架构，其中U-net [22, 23] 是最流行的图像到图像转换任务网络：</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Ronneberger和Fischer等人，2015</td>
<td>《U-net: Convolutional networks for biomedical image segmentation》</td>
<td>提出了用于生物医学图像语义分割的卷积神经网络：Unet</td>
</tr>
<tr>
<td>Hu和Shen等人，CVPR，2018</td>
<td>《Squeeze-and-excitation networks》</td>
<td>提出了通道注意力模块（CAM）</td>
</tr>
</tbody></table>
<p>​		Unet结构不仅包括编码器-解码器结构，还包括跳跃连接，它将从编码器到解码器具有相同大小的特征连接起来。 例如，Puthussery 等人 [2] 提出了一种用于图像重光照的离散小波分解重光照网络。 </p>
<h2 id="3、离散小波变换（Wavelet-Transform）"><a href="#3、离散小波变换（Wavelet-Transform）" class="headerlink" title="3、离散小波变换（Wavelet Transform）"></a>3、离散小波变换（Wavelet Transform）</h2><p>​        1999年Elsevier等人的论文《A wavelet tour of signal processing》提出了离散小波变换（DWT），该操作可以将图像分解为不同频率间隔的各种小块，可以替代现有的下采样操作，如最大池化或平均池化。 因此，许多计算机视觉任务应用 DWT 来减少特征图并实现多尺度特征，如下：</p>
<p>​		2019年ICIP上的《Wavelet U-net and the chromatic adaptation transform for single image dehazing》；</p>
<p>​		2020年ECCV上的《WDRN: A wavelet decomposed relightnet for image relighting》 。</p>
<p>​		2020年的CASSP上的《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》利用 DWT 来设计目标函数来测量真实图像和预测图像之间的相似性。受该工作的启发，该文也在损失函数中结合了 DWT，使其网络可以学习多尺度表示。</p>
<h2 id="4、注意力机制"><a href="#4、注意力机制" class="headerlink" title="4、注意力机制"></a>4、注意力机制</h2><p>​        注意机制在人类感知系统和深度学习任务中都起着重要作用。注意机制提供特征图或某些序列权重，以便可以放大区域或位置的特征。 具体来说，对于计算机视觉任务，注意力机制分为空间注意力和通道注意力。 前者在空间上利用权重来细化特征图，后者计算全局平均池化特征以实现通道注意力。 		在本文中，我们的模型利用了这两种注意力机制来进一步提高网络的性能。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Mnih和Heess 等人，2014</td>
<td>《Recurrent models of visual attention》</td>
<td>空间注意力</td>
</tr>
<tr>
<td>Hu和Shen等人，CVPR，2018</td>
<td>《Squeeze-and-excitation networks》</td>
<td>通道注意力</td>
</tr>
<tr>
<td>Yang等人，ECCV，2020</td>
<td>《Wavelet channel attention module with a fusion network for single image deraining》</td>
<td>通道注意力，注意力机制应用于图像增强领域</td>
</tr>
<tr>
<td>Hu和Huang等人 ,ECCV，2020</td>
<td>《SA-AE for any-to-any relighting》</td>
<td>空间注意力</td>
</tr>
</tbody></table>
<h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><h2 id="1、网络模型"><a href="#1、网络模型" class="headerlink" title="1、网络模型"></a>1、网络模型</h2><p>​			该文的整个网络模型的输入是原始RGB图（1024x1024x3）、原始深度图（1024x1024x1）、引导RGB图（1024x1024x3）和引导深度图（1024x1024x1）连接在一起形成的8通道张量（1024x1024x8），输出的是3通道的预测RGB图（1024x1024x3）。</p>
<p>​			本文提出的 S3Net 的架构如下图所示。该网络基于<em><strong>《Knowledge transfer dehazing network for nonhomogeneous dehazing》</strong></em>，包含编码器和解码器部分。 </p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\S3net整体架构.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/S3net%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p>
<p>​		【编码器】该文使用<em><strong>《Res2net: A new multi-scale backbone architecture》</strong></em>提出的Res2Net101网络主干作为编码器，因为Res2Net 可以在粒度级别表示多尺度特征，并增加每个网络层的感受野范围，输入通过主干后可以实现多尺度特征提取。该文的工作在Res2Net做了如下修改：</p>
<ul>
<li>修改第一个卷积使网络可以使用8 通道张量作为输入；</li>
<li>丢弃网络最后的全连接层，使最终输出的特征图的大小为 16分之一 ；</li>
<li>编码器的初始权重是用 ImageNet 训练的预训练参数，底部特征使用跳跃连接连接到解码器。</li>
</ul>
<p>​       【解码器】解码器由卷积堆栈组成，以细化特征图。</p>
<p>​		 利用注意力模块（Attention，P）来细化中间特征。 注意模块由残差层 （residual layer）<em><strong>《Deep residual learning for image recognition》</strong></em>、空间注意力模块（SAM）<em><strong>《Recurrent models of visual attention》</strong></em> 和通道注意力模块（CAM）<em><strong>《Squeeze-and-excitation networks》</strong></em> 组成。</p>
<p>​		 利用像素混洗（Pixel shuffle，P）<em><strong>《Real-time single image and video super-resolution using an efficient subpixel convolutional neural network》</strong></em>和转置卷积（Transposed convolution，T）<em><strong>《Pixel transposed convolutional networks》</strong></em>来放大特征图。</p>
<p>​		此外，受<em><strong>《Enhanced pix2pix dehazing network》</strong></em>的启发，该文章在 S3Net 中添加了增强模块。 增强模块利用不同步幅的平均池化来改变特征图和感受野的大小，这对于提取多尺度特征是有效的。 最后，应用上采样来恢复减少的特征图，并将所有特征图拼接起来。 </p>
<p>​		【跳跃连接】众所周知，类 U-Net 结构在许多任务中是有益的，例如图像去雾（《PMS-net: Robust haze removal based on patch map for single images》，《PMHLD: patch map-based hybrid learning dehazenet for single image haze removal》） 和语义分割 （<em><strong>《U-net: Convolutional networks for biomedical image segmentation》</strong></em>）。 它的跳跃连接鼓励特征重用。 因此S3Net 中也采用跳跃连接将来自主干的最后三个特征图合并到它们对应的特征图。</p>
<h2 id="2、损失函数"><a href="#2、损失函数" class="headerlink" title="2、损失函数"></a>2、损失函数</h2><p>​		该文章的S3Net一共使用了三个损失函数，其整体损失如下：<br>$$<br>L_{\text {Total }}&#x3D;\lambda_{1} L_{\text {cha }}+\lambda_{2} L_{W-S S I M}+\lambda_{3} L_{P e r}<br>$$<br>​		其中 $\lambda_{1}$、$$\lambda_{2}$ 和$ $\lambda_{3}$ 是缩放系数，用于调整三个分量的相对权重。</p>
<h3 id="（1）Charbonnier-损失"><a href="#（1）Charbonnier-损失" class="headerlink" title="（1）Charbonnier 损失"></a>（1）Charbonnier 损失</h3><p>​		该损失函数来自于《A general and adaptive robust loss function》，其可以看做是一个高鲁棒性的L1损失函数，该损失函数可以还原全局结构并且可以更鲁棒地处理异常值，其公式如下：<br>$$<br>L_{C h a}(I, \hat{I})&#x3D;\frac{1}{T} \sum_{i}^{T} \sqrt{\left(I_{i}-\hat{I}_{i}\right)^{2}+\epsilon^{2}}<br>$$<br>​       其中$I$ 和$\hat{I}$ 分别代表目标图像和该文网络输出的预测图像， $\epsilon$被视为一个微小的常数（例如$10^{-6}$）,用来实现稳定和鲁棒的收敛。</p>
<h3 id="（2）SSIM-损失"><a href="#（2）SSIM-损失" class="headerlink" title="（2）SSIM 损失"></a>（2）SSIM 损失</h3><p>​		该损失函数来自于《Loss functions for image restoration with neural networks》 ，其能够重建局部纹理和细节。 可以表示为：<br>$$<br>L_{S S I M}(I, \hat{I})&#x3D;-\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(2 \sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}\right)}<br>$$<br>​		 其中 σ 和 µ 表示图像的标准偏差、协方差和均值。 </p>
<p>​		在图像重照明任务中，为了从原始图像中去除阴影，该文扩展了 SSIM 损失函数，以便使网络可以恢复更详细的部分。 </p>
<p>​		该文使用《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》 中的方法将 DWT 组合到 SSIM 损失中，这有利于重建重光照图像的清晰细节。最初，DWT 将预测图像分解为四个不同的小sub-band图像。 操作可以表示为：<br>$$<br>\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}&#x3D;\operatorname{DWT}(\hat{I})<br>$$</p>
<p>​       其中上标表示来自各个过滤器的输出（例如，$$\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}$$）。</p>
<p>​       $$\hat{I}^{H L}, \hat{I}^{L H}, \hat{I}^{H H}$$分别是水平边缘、垂直边缘和角点检测的高通滤波器。  fLL 被视为下采样操作。 此外，DWT 可以不断分解$$\hat{I}^{L L}$$ 以生成具有不同尺度和频率信息的图像。 这一步写成：<br>$$<br>\hat{I}<em>{i+1}^{L L}, \hat{I}</em>{i+1}^{L H}, \hat{I}<em>{i+1}^{H L}, \hat{I}</em>{i+1}^{H H}&#x3D;\operatorname{DWT}\left(\hat{I}<em>{i}^{L L}\right)<br>$$<br>​       其中下标 i 表示第 i 次 DWT 迭代的输出。 上述 SSIM 损失项是根据原始图像对和各种子带图像对计算得出的。  SSIM损失和DWT的融合整合为：<br>$$<br>\begin{array}{l}<br>L</em>{W-S S I M}(I, \hat{I})&#x3D;\sum_{0}^{r} \gamma_{i} L_{\mathrm{SSIM}}\left(I_{i}^{w}, \hat{I}<em>{i}^{w}\right) \<br>w \in{L L, H L, L H, H H}<br>\end{array}<br>$$<br>       其中$$\gamma</em>{i}$$  基于原文来控制不同补丁的重要性。</p>
<h3 id="（3）感知损失"><a href="#（3）感知损失" class="headerlink" title="（3）感知损失"></a>（3）感知损失</h3><p>​			该损失函数来自于《Perceptual losses for real-time style transfer and super-resolution》， 与前面提到的两个损失函数不同，感知损失利用从预训练的深度神经网络（例如 VGG19 （《Very deep convolutional networks for large-scale image recognition》））获得的多尺度特征来测量预测图像和目标图像之间的视觉特征差异。该文章使用在ImageNet 上预训练的 VGG19 被用作损失函数网络。</p>
<p>​    		感知损失定义为<br>$$<br>L_{P e r}(I, \hat{I})&#x3D;\mid(\operatorname{VGG}(I)-\operatorname{VGG}(\hat{I}) \mid<br>$$</p>
<p>​			其中$\mid·\mid$ 是绝对值。</p>
<h1 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h1><pre><code>     该文的实验使用的是NTIRE 2021中使用的数据集是the Virtual Image Dataset for Illumination Transfer (VIDIT) 。 该图像数据集总共有15600张图片，包含390 个不同的虚拟场景及其对应的390 张深度图，每个场景具有40种不同的照明设置（从2500到6500K的五种不同色温和 8 个方位角）。 所有训练图像和深度图的大小分别为 1024 × 1024 × 3 和 1024 × 1024 × 1。  
</code></pre>
<p>​		在整个数据集中300 个场景用于训练，剩下的 90 个场景用于验证和测试。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Helou和Zhou等人，2020</td>
<td>《Vidit: Virtual image dataset for illumination transfer》</td>
<td>提出了用于图像重光照的虚拟图像数据集VIDIT</td>
</tr>
</tbody></table>
<h2 id="1、消融实验的定量分析"><a href="#1、消融实验的定量分析" class="headerlink" title="1、消融实验的定量分析"></a>1、消融实验的定量分析</h2><p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\消融实验的定量分析.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C%E7%9A%84%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90.png"></p>
<h2 id="2、消融实验的定性分析"><a href="#2、消融实验的定性分析" class="headerlink" title="2、消融实验的定性分析"></a>2、消融实验的定性分析</h2><p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\消融实验的定性分析.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C%E7%9A%84%E5%AE%9A%E6%80%A7%E5%88%86%E6%9E%90.png"></p>
<h2 id="3、与其他方法的对比实验"><a href="#3、与其他方法的对比实验" class="headerlink" title="3、与其他方法的对比实验"></a>3、与其他方法的对比实验</h2><p>​		如下表所示，列出的是本文提出的方法和在NTIRE2021 workshop的深度引导的any-to-any重光照挑战中的其他竞争方法的对比结构：</p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\对比实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C.png"></p>
<p>​        结果显示本文方法的结果在 SSIM、PSNR、LPIPS 和 MPS 方面分别获得了第 3、第 4、第 2 和第 3 名。<br>​        本文模型在测试阶段平均需要 2.042 秒来生成 1024 × 1024大小的 重光照图像。</p>
<h1 id="五、总结与不足"><a href="#五、总结与不足" class="headerlink" title="五、总结与不足"></a>五、总结与不足</h1><p>​		该文提出了一种单流结构网络（S3Net）用于深度引导的任意对任意的图像重照明。该网络的编码器部分基于Res2Net，解码器部分加入了注意力模块和增强模块 ；损失函数中加入了离散小波变换的SSIM损失。</p>
<p>​		该方法在NTIRE 2021的PMS 和 SSIM 方面获得了第三名，但是实验证明，该文的方法也会在某些条件下可能会失败，如下图所示，当原始图像包含大面积的阴影时，该文的模型无法识别它们的前景和背面，导致预测图像与真实图像非常不同，论文作者认为这是因为即使给出了深度图，这些信息也只是提供了正面而不是全方位的空间信息。  </p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\模型的失败案例.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%A1%88%E4%BE%8B.png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">「科研笔记」S3net的损失函数</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-02 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-02T00:00:00+00:00">2021-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="感知损失"><a href="#感知损失" class="headerlink" title="感知损失"></a>感知损失</h1><p>项目DRN和S3Net都是用的 J. Johnson, A. Alahi, and L. Fei-Fei,  2016《Perceptual losses for real-time style transfer and super-resolution,” in European conference on computer vision》的感知函数</p>
<p>   感知损失利用从预训练的深度神经网络（例如 VGG19 ）中获得的多尺度特征来测量真实图像和网络预测图像之间的视觉特征差异。 在DRN、S3Net中使用 ImageNet训练集 上预训练的 VGG19 网络来计算感知损失。  </p>
<p>​      感知损失（使用VGG）公式为：</p>
<p><img src="D:/个人文件夹/123wangju123.github.io/_posts//img-post/科研笔记/2021-11-02-【科研笔记】感知损失函数/VGGLOSS.png"></p>
<p><img src="/../img-post/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91%E6%84%9F%E7%9F%A5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/VGGLOSS.png"></p>
<h2 id="Vgg19网络结构："><a href="#Vgg19网络结构：" class="headerlink" title="Vgg19网络结构："></a>Vgg19网络结构：</h2><p>VGG19包含了19个隐藏层（16个卷积层和3个全连接层）。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2021/png/13013014/1632217897702-0d271030-b1b5-4953-b286-6e291f0ba5ae.png" alt="img"></p>
<h2 id="DRN代码中，使用Pytorch获取Vgg19网络："><a href="#DRN代码中，使用Pytorch获取Vgg19网络：" class="headerlink" title="DRN代码中，使用Pytorch获取Vgg19网络："></a>DRN代码中，使用Pytorch获取Vgg19网络：</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models as models</span><br><span class="line"># 加载预训练的模型</span><br><span class="line">vgg_model = models.<span class="built_in">vgg19</span>(pretrained=True)</span><br><span class="line"># 获取中间层特征</span><br><span class="line">vgg_pretrained_features = vgg_model.features</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;model.features[0]&#x27;</span>, model.features[<span class="number">0</span>]) #<span class="built_in">Conv2d</span>(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">from torchvision import models</span><br><span class="line"></span><br><span class="line">class Vgg19(torch.nn.Module):</span><br><span class="line">    def __init__(self, requires_grad=False):</span><br><span class="line">        super(Vgg19, self).__init__()</span><br><span class="line">        # 加载预训练的模型</span><br><span class="line">        # vgg_pretrained_features = models.vgg19(pretrained=True).features</span><br><span class="line">        </span><br><span class="line">        # 加载预训练模型</span><br><span class="line">        model = models.vgg19(pretrained=True)</span><br><span class="line">        # 获取中间层特征</span><br><span class="line">        vgg_pretrained_features = model.features</span><br><span class="line">        </span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line">        self.slice5 = torch.nn.Sequential()</span><br><span class="line">        # 把不同层的特征分别加入不同的模块</span><br><span class="line">        for x in range(2):</span><br><span class="line">            self.slice1.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(2, 7):</span><br><span class="line">            self.slice2.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(7, 12):</span><br><span class="line">            self.slice3.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(12, 21):</span><br><span class="line">            self.slice4.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(21, 28):</span><br><span class="line">            self.slice5.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        # 设置所有参数都不需要计算梯度</span><br><span class="line">        if not requires_grad:</span><br><span class="line">            for param in self.parameters():</span><br><span class="line">                param.requires_grad = False</span><br><span class="line"></span><br><span class="line">    def forward(self, X):</span><br><span class="line">        # 获取不同模块的特征</span><br><span class="line">        h_relu1 = self.slice1(X)</span><br><span class="line">        h_relu2 = self.slice2(h_relu1)</span><br><span class="line">        h_relu3 = self.slice3(h_relu2)</span><br><span class="line">        #h_relu4 = self.slice4(h_relu3)</span><br><span class="line">        #h_relu5 = self.slice5(h_relu4)</span><br><span class="line">        #out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]</span><br><span class="line">        out = [h_relu1, h_relu2, h_relu3]#, h_relu4, h_relu5]</span><br><span class="line">        return out</span><br></pre></td></tr></table></figure>

<h2 id="用vgg计算感知损失（VGGLoss）"><a href="#用vgg计算感知损失（VGGLoss）" class="headerlink" title="用vgg计算感知损失（VGGLoss）"></a>用vgg计算感知损失（VGGLoss）</h2><p>VGG19本是用来进行分类的，进行可视化和用作VGG loss 自然也就是用到全连接层之前的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class VGGLoss(nn.Module):</span><br><span class="line">    def __init__(self, gpu_ids):</span><br><span class="line">        super(VGGLoss, self).__init__()</span><br><span class="line">        self.vgg = Vgg19().cuda()</span><br><span class="line">        self.criterion = nn.L1Loss()</span><br><span class="line">        self.weights = [1.0 / 32, 1.0 / 16, 1.0 / 8, 1.0 / 4, 1.0]</span><br><span class="line"></span><br><span class="line">    def forward(self, x, y):</span><br><span class="line">        x_vgg, y_vgg = self.vgg(x), self.vgg(y)</span><br><span class="line">        loss = 0</span><br><span class="line">        for i in range(len(x_vgg)):</span><br><span class="line">            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())</span><br><span class="line">        return loss</span><br></pre></td></tr></table></figure>

<h1 id="Charbonnier-loss"><a href="#Charbonnier-loss" class="headerlink" title="Charbonnier loss"></a>Charbonnier loss</h1><p>Charbonnier 损失 （ A general and adaptive robust loss function ），可以看作是鲁棒的 L1 损失函数。</p>
<p>  其中 I 和 I^ 分别代表真实图像和来自提出网络的 relit 图像，并且 e 被视为一个微小的常数（例如 10−6 ）以实现稳定和鲁棒的收敛。 LC ha 可以还原全局结构并且可以更鲁棒地处理异常值。</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211103001556088.png" alt="image-20211103001556088"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;</span><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@文件名: ChaLoss.py</span></span><br><span class="line"><span class="string">@作者: XW</span></span><br><span class="line"><span class="string">@时间: 2021/11/2 23:05</span></span><br><span class="line"><span class="string">@环境: Python,Numpy</span></span><br><span class="line"><span class="string">@描述: 无</span></span><br><span class="line"><span class="string">@参考: 无</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span><span class="string">&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义L1损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cha_loss</span>(<span class="params">y_true,y_pre</span>):</span><br><span class="line"></span><br><span class="line">    e = <span class="number">10</span>**(-<span class="number">6</span>)</span><br><span class="line">    loss=torch.mean(torch.sqrt((y_true-y_pre)**<span class="number">2</span>)+e**<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># loss = torch.sqrt((y_true-y_pre)**2)</span></span><br><span class="line">    <span class="comment"># loss = np.mean(np.sqrt((y_true - y_pre) ** 2) )</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    y_true=torch.tensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>])</span><br><span class="line">    y_pre=torch.tensor([<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>])</span><br><span class="line">    res=cha_loss(y_true,y_pre)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-01-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E6%B1%82%E5%87%A0%E4%B8%AA%E6%95%B0%E4%B9%8B%E5%92%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-01-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E6%B1%82%E5%87%A0%E4%B8%AA%E6%95%B0%E4%B9%8B%E5%92%8C/" class="post-title-link" itemprop="url">「算法刷题」求几个数之和</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-01T00:00:00+00:00">2021-11-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>15</td>
<td>三数之和（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/3sum/">15. 三数之和 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91c++%E4%B8%ADsort%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91c++%E4%B8%ADsort%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">「算法刷题」c++中sort函数的使用方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>参考链接： <a target="_blank" rel="noopener" href="https://www.cnblogs.com/junbaobei/p/10776066.html">C++中sort函数使用方法 - 俊宝贝 - 博客园 (cnblogs.com)</a> </p>
<p>1.sort函数包含在头文件为#include<algorithm>的c++标准库中，调用标准库里的排序方法可以实现对数据的排序，但是sort函数是如何实现的，我们不用考虑！</p>
<p>2.sort函数的模板有三个参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp);</span><br></pre></td></tr></table></figure>

<p>（1）第一个参数first：是要排序的数组的起始地址。</p>
<p>（2）第二个参数last：是结束的地址（最后一个数据的后一个数据的地址）</p>
<p>（3）第三个参数comp是排序的方法：可以是从升序也可是降序。如果第三个参数不写，则默认的排序方法是从小到大排序。</p>
<p>3 实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> 1 #include&lt;iostream&gt;</span><br><span class="line"> 2 #include&lt;algorithm&gt;</span><br><span class="line"> 3 using namespace std;</span><br><span class="line"> 4 main()</span><br><span class="line"> 5 &#123;</span><br><span class="line"> 6 　　//sort函数第三个参数采用默认从小到大</span><br><span class="line"> 7 　　int a[]=&#123;45,12,34,77,90,11,2,4,5,55&#125;;</span><br><span class="line"> 8 　　sort(a,a+10);</span><br><span class="line"> 9 　　for(int i=0;i&lt;10;i++)</span><br><span class="line">10 　　cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;;     </span><br><span class="line">11 &#125; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> 1 #include&lt;iostream&gt;</span><br><span class="line"> 2 #include&lt;algorithm&gt;</span><br><span class="line"> 3 using namespace std;</span><br><span class="line"> 4 bool cmp(int a,int b);</span><br><span class="line"> 5 main()&#123;</span><br><span class="line"> 6 　　//sort函数第三个参数自己定义，实现从大到小 </span><br><span class="line"> 7 　　int a[]=&#123;45,12,34,77,90,11,2,4,5,55&#125;;</span><br><span class="line"> 8 　　sort(a,a+10,cmp);</span><br><span class="line"> 9 　　for(int i=0;i&lt;10;i++)</span><br><span class="line">10 　　　　cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;;     </span><br><span class="line">11 &#125;</span><br><span class="line">12 //自定义函数</span><br><span class="line">13 bool cmp(int a,int b)&#123;</span><br><span class="line">14 　　return a&gt;b;</span><br><span class="line">15 &#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/" class="post-title-link" itemprop="url">「算法刷题」哈希表的相关经典题目</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>383</td>
<td>赎金信（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/ransom-note/">383. 赎金信 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">canConstruct</span><span class="params">(string ransomNote, string magazine)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> record[<span class="number">26</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">        <span class="comment">// 记录magazine里各个字符出现的次数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;magazine.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历ransomNote，在record里对应的字符个数做--操作</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;ransomNote.<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">            record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]--;</span><br><span class="line">            <span class="comment">// 如果小于零，说明ransomNote里出现的字符，magazine里没有</span></span><br><span class="line">            <span class="keyword">if</span>(record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]&lt;<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>类似题目：</p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>242</td>
<td>有效的字母异位词（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/valid-anagram/">242. 有效的字母异位词 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p><strong>数组其实就是一个简单哈希表</strong>，而且这道题目中字符串只有小写字符，那么就可以定义一个数组，来记录字符串s里字符出现的次数。</p>
<p>定义一个数组叫做record用来上记录字符串s里字符出现的次数。</p>
<p>1、需要把字符映射到数组也就是哈希表的索引下表上，<strong>因为字符a到字符z的ASCII是26个连续的数值，所以字符a映射为下表0，相应的字符z映射为下表25。</strong></p>
<p>再遍历 字符串s的时候，<strong>只需要将 s[i] - ‘a’ 所在的元素做+1 操作即可，并不需要记住字符a的ASCII，只要求出一个相对数值就可以了。</strong> 这样就将字符串s中字符出现的次数，统计出来了。</p>
<p>2、那看一下如何检查字符串t中是否出现了这些字符，同样在遍历字符串t的时候，对t中出现的字符映射哈希表索引上的数值再做-1的操作。</p>
<p>3、那么最后检查一下，<strong>record数组如果有的元素不为零0，说明字符串s和t一定是谁多了字符或者谁少了字符，return false。</strong></p>
<p>最后如果record数组所有元素都为零0，说明字符串s和t是字母异位词，return true。</p>
<p>时间复杂度为O(n)，空间上因为定义是的一个常量大小的辅助数组，所以空间复杂度为O(1)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    bool isAnagram(string s, string t) &#123;</span><br><span class="line">        int record[26] = &#123;0&#125;;</span><br><span class="line">        for (int i = 0; i &lt; s.size(); i++) &#123;</span><br><span class="line">            // 并不需要记住字符a的ASCII，只要求出一个相对数值就可以了</span><br><span class="line">            record[s[i] - &#x27;a&#x27;]++;</span><br><span class="line">        &#125;</span><br><span class="line">        for (int i = 0; i &lt; t.size(); i++) &#123;</span><br><span class="line">            record[t[i] - &#x27;a&#x27;]--;</span><br><span class="line">        &#125;</span><br><span class="line">        for (int i = 0; i &lt; 26; i++) &#123;</span><br><span class="line">            if (record[i] != 0) &#123;</span><br><span class="line">                // record数组如果有的元素不为零0，说明字符串s和t 一定是谁多了字符或者谁少了字符。</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // record数组所有元素都为零0，说明字符串s和t是字母异位词</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="知识补充："><a href="#知识补充：" class="headerlink" title="知识补充："></a>知识补充：</h1><h2 id="1、c-memset-函数"><a href="#1、c-memset-函数" class="headerlink" title="1、c++ memset()函数"></a>1、c++ memset()函数</h2><p>memset 函数是内存赋值函数，用来给某一块内存空间进行赋值的；</p>
<p>包含在&lt;string.h&gt;头文件中,可以用它对一片内存空间逐字节进行初始化；</p>
<p>原型为 ：</p>
<p>void *memset(void *s, int v, size_t n);</p>
<p>这里s可以是数组名，也可以是指向某一内在空间的指针；</p>
<p>v为要填充的值；</p>
<p>n为要填充的字节数；</p>
<p>示例1：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct data</span><br><span class="line">&#123;</span><br><span class="line">char num[100];</span><br><span class="line">char name[100];</span><br><span class="line">int  n;</span><br><span class="line">&#125;;</span><br><span class="line">struct data  a, b[10];</span><br><span class="line"></span><br><span class="line">memset( &amp;a, 0, sizeof(a) ); //注意第一个参数是指针类型，a不是指针变量，要加&amp;</span><br><span class="line">memset( b, 0, sizeof(b) );  //b是数组名，就是指针类型，不需要加&amp;</span><br></pre></td></tr></table></figure>

<p>示例2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">char str[9];</span><br><span class="line"></span><br><span class="line">//我们用memset给str初始化为“00000000”，用法如下</span><br><span class="line"></span><br><span class="line">memset(str,0,8); </span><br><span class="line"></span><br><span class="line">//注意，memset是逐字节 拷贝的。</span><br></pre></td></tr></table></figure>

<p>示例3：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">int num[8];</span><br><span class="line"></span><br><span class="line">//我们用memset给str初始化为&#123;1,1,1,1,1,1,1,1&#125;，</span><br><span class="line">memset(num,1,8);//这样是不对的</span><br><span class="line"></span><br><span class="line">//一个int是4个字节的，8个int是32个字节，所以首先要赋值的长度就不应该为8而是32。</span><br><span class="line"></span><br><span class="line">//因为memset是 逐字节 拷贝，以num为首地址的8字节空间都被赋值为1，</span><br><span class="line"></span><br><span class="line">//即一个int变为0X00000001 00000001 00000001 00000001，显然，把这个数化为十进制不会等于1的</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2、-常见的-string-类构造函数有以下几种形式："><a href="#2、-常见的-string-类构造函数有以下几种形式：" class="headerlink" title="2、 常见的 string 类构造函数有以下几种形式："></a>2、 常见的 string 类构造函数有以下几种形式：</h2><p> strings(num, c) &#x2F;&#x2F;生成一个字符串，包含num个c字符 </p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1002</td>
<td>查找常用字符（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/find-common-characters/">1002. 查找共用字符 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">commonChars</span><span class="params">(vector&lt;string&gt;&amp; words)</span> </span>&#123;</span><br><span class="line">        vector&lt;string&gt; result;</span><br><span class="line">        <span class="keyword">if</span> (words.<span class="built_in">size</span>() == <span class="number">0</span>) <span class="keyword">return</span> result;</span><br><span class="line">        <span class="type">int</span> hash[<span class="number">26</span>] = &#123;<span class="number">0</span>&#125;; <span class="comment">// 用来统计所有字符串里字符出现的最小频率</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; words[<span class="number">0</span>].<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 用第一个字符串给hash初始化</span></span><br><span class="line">            hash[words[<span class="number">0</span>][i] - <span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> hashOtherStr[<span class="number">26</span>] = &#123;<span class="number">0</span>&#125;; <span class="comment">// 统计除第一个字符串外字符的出现频率</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; words.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">memset</span>(hashOtherStr, <span class="number">0</span>, <span class="number">26</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; words[i].<span class="built_in">size</span>(); j++) &#123;</span><br><span class="line">                hashOtherStr[words[i][j] - <span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 更新hash，保证hash里统计26个字符在所有字符串里出现的最小次数</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; <span class="number">26</span>; k++) &#123;</span><br><span class="line">                hash[k] = <span class="built_in">min</span>(hash[k], hashOtherStr[k]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将hash统计的字符次数，转成输出形式</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">26</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">while</span> (hash[i] != <span class="number">0</span>) &#123; <span class="comment">// 注意这里是while，多个重复的字符</span></span><br><span class="line">                <span class="function">string <span class="title">s</span><span class="params">(<span class="number">1</span>, i + <span class="string">&#x27;a&#x27;</span>)</span></span>; <span class="comment">// char -&gt; string</span></span><br><span class="line">                result.<span class="built_in">push_back</span>(s);</span><br><span class="line">                hash[i]--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="知识补充：-1"><a href="#知识补充：-1" class="headerlink" title="知识补充："></a>知识补充：</h1><h2 id="哈希数据结构：unordered-set"><a href="#哈希数据结构：unordered-set" class="headerlink" title="哈希数据结构：unordered_set"></a>哈希数据结构：unordered_set</h2><p><strong>参考链接</strong>： <a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7250.html">C++ STL unordered_set容器完全攻略 (biancheng.net)</a> </p>
<p>注意题目特意说明：<strong>输出结果中的每个元素一定是唯一的，也就是说输出的结果是去除了重复的元素， 同时可以不考虑输出结果的顺序</strong></p>
<p>那么用数组来做哈希表也是不错的选择，例如<a target="_blank" rel="noopener" href="https://programmercarl.com/0242.%E6%9C%89%E6%95%88%E7%9A%84%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D.html">242. 有效的字母异位词</a></p>
<p>但是要注意，<strong>使用数组来做哈希的题目，是因为题目都限制了数值的大小。</strong></p>
<p><strong>而且如果哈希值比较少、特别分散、跨度非常大，使用数组就造成空间的极大浪费。</strong></p>
<p>此时就要使用另一种结构体了，set ，关于set，C++ 给提供了如下三种可用的数据结构：</p>
<ul>
<li>std::set</li>
<li>std::multiset</li>
<li>std::unordered_set</li>
</ul>
<p>std::set和std::multiset底层实现都是红黑树，std::unordered_set的底层实现是哈希表， 使用unordered_set 读写效率是最高的，并不需要对数据进行排序，而且还不要让数据重复，所以选择unordered_set。</p>
<h3 id="c-unordered-set容器的成员方法："><a href="#c-unordered-set容器的成员方法：" class="headerlink" title="c++ unordered_set容器的成员方法："></a>c++ unordered_set容器的成员方法：</h3><p>find(key): 查找以值为 key 的元素，如果找到，则返回一个指向该元素的正向迭代器；反之，则返回一个指向容器中最后一个元素之后位置的迭代器（如果 end() 方法返回的迭代器）。 </p>
<p>思路如图所示：</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211030230213881.png" alt="image-20211030230213881"></p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>349</td>
<td>两个数组的交集（简单难度）</td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;</span><br><span class="line">        unordered_set&lt;int&gt; result_set; // 存放结果</span><br><span class="line">        unordered_set&lt;int&gt; nums_set(nums1.begin(), nums1.end());</span><br><span class="line">        for (int num : nums2) &#123;</span><br><span class="line">            // 下面的代码表示：发现nums2的元素 在nums_set里又出现过</span><br><span class="line">            //不理解的话，复习unordered_set的成员方法</span><br><span class="line">            if (nums_set.find(num) != nums_set.end()) &#123;</span><br><span class="line">                result_set.insert(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return vector&lt;int&gt;(result_set.begin(), result_set.end());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><p>那有同学可能问了，遇到哈希问题我直接都用set不就得了，用什么数组啊。</p>
<p>直接使用set 不仅占用空间比数组大，而且速度要比数组慢，set把数值映射到key上都要做hash计算的。</p>
<p>不要小瞧 这个耗时，在数据量大的情况，差距是很明显的。</p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>350</td>
<td>两个数组的交集2（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/intersection-of-two-arrays-ii/">350. 两个数组的交集 II - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>这道题和349不一样，没有要求 输出不能重复</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;</span><br><span class="line">        // 对两个数组进行排序</span><br><span class="line">        sort(nums1.begin(),nums1.end());</span><br><span class="line">        sort(nums2.begin(),nums2.end());</span><br><span class="line">        int i=0,j=0;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        //同时对两个数组遍历，有一个遍历完就结束</span><br><span class="line">        while(i&lt;nums1.size() &amp;&amp; j&lt;nums2.size())&#123;</span><br><span class="line">            // 相等，则添加到结果里</span><br><span class="line">            if(nums1[i]==nums2[j])&#123;</span><br><span class="line"></span><br><span class="line">                res.push_back(nums1[i]);</span><br><span class="line">                ++i;</span><br><span class="line">                ++j;</span><br><span class="line">            &#125;</span><br><span class="line">            else if(nums1[i]&lt;nums2[j])</span><br><span class="line">                ++i;</span><br><span class="line">            else                    </span><br><span class="line">               ++j;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>202</td>
<td>快乐数（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/happy-number/submissions/">202. 快乐数 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>题目中说了会无限循环，即在求和的过程中，sum会重复出现，这一点对解题很重要。</p>
<p>正如：<a target="_blank" rel="noopener" href="https://programmercarl.com/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html">关于哈希表，你该了解这些！</a>中所说，<strong>当我们遇到了要快速判断一个元素是否出现集合里的时候，就要考虑哈希法了。</strong></p>
<p>这道题用哈希法，来判断这个sum是否重复出现，重复则return false， 否则一直找到sum为1为止。</p>
<p>判断sum是否重复出现就可以使用unordered_set。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    // 取数值各个位上的单数之和</span><br><span class="line">    int getSum(int n) &#123;</span><br><span class="line">        int sum = 0;</span><br><span class="line">        while (n) &#123;</span><br><span class="line">            sum += (n % 10) * (n % 10);</span><br><span class="line">            n /= 10;</span><br><span class="line">        &#125;</span><br><span class="line">        return sum;</span><br><span class="line">    &#125;</span><br><span class="line">    bool isHappy(int n) &#123;</span><br><span class="line">        unordered_set&lt;int&gt; set;</span><br><span class="line">        while(1) &#123;</span><br><span class="line">            int sum = getSum(n);</span><br><span class="line">            if (sum == 1) &#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            // 如果这个sum曾经出现过，说明已经陷入了无限循环了，立刻return false</span><br><span class="line">            if (set.find(sum) != set.end()) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                set.insert(sum);</span><br><span class="line">            &#125;</span><br><span class="line">            n = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/intersection-of-two-arrays-ii/">1. 两数之和 - 力扣（LeetCode）</a></td>
</tr>
</tbody></table>
<p>则要使用map，那么来看一下使用数组和set来做哈希法的局限。</p>
<ul>
<li><p>数组的大小是受限制的，而且如果元素很少，而哈希值太大会造成内存空间的浪费。</p>
</li>
<li><p>set是一个集合，里面放的元素只能是一个key，而两数之和这道题目，不仅要判断y是否存在而且还要记录y的下标位置，因为要返回x 和 y的下标。所以set 也不能用。</p>
<p>此时就要选择另一种数据结构：map ，map是一种key value的存储结构，可以用key保存数值，用value在保存数值所在的下表。</p>
<p>C++中map，有三种类型：</p>
<table>
<thead>
<tr>
<th>映射</th>
<th>底层实现</th>
<th>是否有序</th>
<th>数值是否可以重复</th>
<th>能否更改数值</th>
<th>查询效率</th>
<th>增删效率</th>
</tr>
</thead>
<tbody><tr>
<td>std::map</td>
<td>红黑树</td>
<td>key有序</td>
<td>key不可重复</td>
<td>key不可修改</td>
<td>O(logn)</td>
<td>O(logn)</td>
</tr>
<tr>
<td>std::multimap</td>
<td>红黑树</td>
<td>key有序</td>
<td>key可重复</td>
<td>key不可修改</td>
<td>O(logn)</td>
<td>O(logn)</td>
</tr>
<tr>
<td>std::unordered_map</td>
<td>哈希表</td>
<td>key无序</td>
<td>key不可重复</td>
<td>key不可修改</td>
<td>O(1)</td>
<td>O(1)</td>
</tr>
</tbody></table>
<p>std::unordered_map 底层实现为哈希表，std::map 和std::multimap 的底层实现是红黑树。</p>
<p>同理，std::map 和std::multimap 的key也是有序的（这个问题也经常作为面试题，考察对语言容器底层的理解）。 更多哈希表的理论知识请看<a target="_blank" rel="noopener" href="https://www.programmercarl.com/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html">关于哈希表，你该了解这些！</a>。</p>
<p><strong>这道题目中并不需要key有序，选择std::unordered_map 效率更高！</strong></p>
<p><strong>解题思路：</strong></p>
<p>例如：nums&#x3D;[2,7,11,15],target&#x3D;9</p>
<p>遍历数组</p>
<p>1、寻找target-nums[i]是否在map中，</p>
<p>2、没有，9-2&#x3D;7,7不在map中，把2和对应下标0放进map中</p>
<p>3、有，9-7&#x3D;2,2在map中，找到了数值2和7相加等于9，返回其下标</p>
<p>遍历结束后，没有返回值，则返回空的数组</p>
<p>参考链接： <a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7231.html">C++ STL unordered_map容器用法详解 (biancheng.net)</a> </p>
<p>C++代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">twoSum</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">        std::unordered_map &lt;<span class="type">int</span>,<span class="type">int</span>&gt; map;<span class="comment">//创建空的umap容器</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="comment">//查找target - nums[i]是否在map中，</span></span><br><span class="line">            <span class="keyword">auto</span> iter = map.<span class="built_in">find</span>(target - nums[i]);</span><br><span class="line">            <span class="comment">// 有，返回两个数的下标</span></span><br><span class="line">            <span class="keyword">if</span>(iter != map.<span class="built_in">end</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> &#123;iter-&gt;second, i&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 没有，把该数值和其下标加入到map中</span></span><br><span class="line">            map.<span class="built_in">insert</span>(<span class="built_in">pair</span>&lt;<span class="type">int</span>, <span class="type">int</span>&gt;(nums[i], i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//没找到</span></span><br><span class="line">        <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>49</td>
<td>（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/group-anagrams/">49. 字母异位词分组 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/fuqiuai/article/details/83589593">https://blog.csdn.net/fuqiuai/article/details/83589593</a></p>
<p>解题思路：</p>
<p>1、对字符串每个词的字母按照字典序进行排序，异位词对字母进行排序后有相同的字母序列。</p>
<p>用排序后的字母序列作为map的key，将所有异位词都保存到字符串数组中，用map建立key和字符串数组之间的映射（不需要结果有序，所以用unordered map)</p>
<p>2、最后把归纳好的字符串数组存入结果res中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;string&gt;&gt; <span class="built_in">groupAnagrams</span>(vector&lt;string&gt;&amp; strs) &#123;</span><br><span class="line">        vector&lt;vector&lt;string&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(strs.<span class="built_in">size</span>()==<span class="number">0</span>)<span class="keyword">return</span> res;</span><br><span class="line">        <span class="comment">// 键为string字符串类型，值为字符串数组类型</span></span><br><span class="line">        unordered_map&lt;string,vector&lt;string&gt;&gt; map1;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;strs.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            string s=strs[i];</span><br><span class="line">            <span class="built_in">sort</span>(s.<span class="built_in">begin</span>(),s.<span class="built_in">end</span>());</span><br><span class="line">            <span class="comment">// 排序后相同的字符串放到一个数组里，键为排序后的字符串</span></span><br><span class="line">            map1[s].<span class="built_in">push_back</span>(strs[i]);<span class="comment">//map1[s]是一个值类型为字符串的数组</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> v:map1)&#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(v.second);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E8%B4%AA%E5%BF%83%E7%AE%97%E6%B3%95%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/" class="post-title-link" itemprop="url">「算法刷题」贪心算法的相关经典题目</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>455</td>
<td>分发饼干（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/ransom-note/">383. 赎金信 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>为了了满足更多的小孩，就不要造成饼干尺寸的浪费。</p>
<p>大尺寸的饼干既可以满足胃口大的孩子也可以满足胃口小的孩子，那么就应该优先满足胃口大的。</p>
<p><strong>这里的局部最优就是大饼干喂给胃口大的，充分利用饼干尺寸喂饱一个，全局最优就是喂饱尽可能多的小孩</strong>。</p>
<p>可以尝试使用贪心策略，先将饼干数组和小孩数组排序。</p>
<p>然后从后向前遍历小孩数组，用大饼干优先满足 </p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211029212703299.png" alt="image-20211029212703299"></p>
<p>这个例子可以看出饼干9只有喂给胃口为7的小孩，这样才是整体最优解，并想不出反例，那么就可以撸代码了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 时间复杂度：O(nlogn)</span></span><br><span class="line"><span class="comment">// 空间复杂度：O(1)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findContentChildren</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; g, vector&lt;<span class="type">int</span>&gt;&amp; s)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">sort</span>(g.<span class="built_in">begin</span>(), g.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">sort</span>(s.<span class="built_in">begin</span>(), s.<span class="built_in">end</span>());</span><br><span class="line">        <span class="type">int</span> index = s.<span class="built_in">size</span>() - <span class="number">1</span>; <span class="comment">// 饼干数组的下标</span></span><br><span class="line">        <span class="type">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = g.<span class="built_in">size</span>() - <span class="number">1</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            <span class="keyword">if</span> (index &gt;= <span class="number">0</span> &amp;&amp; s[index] &gt;= g[i]) &#123;</span><br><span class="line">                result++;</span><br><span class="line">                index--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>从代码中可以看出我用了一个index来控制饼干数组的遍历，遍历饼干并没有再起一个for循环，而是采用自减的方式，这也是常用的技巧。</p>
<p>有的同学看到要遍历两个数组，就想到用两个for循环，那样逻辑其实就复杂了。</p>
<p><strong>也可以换一个思路，小饼干先喂饱小胃口</strong></p>
<p>代码如下：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findContentChildren</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; g, vector&lt;<span class="type">int</span>&gt;&amp; s)</span> </span>&#123;</span><br><span class="line">        <span class="built_in">sort</span>(g.<span class="built_in">begin</span>(),g.<span class="built_in">end</span>());</span><br><span class="line">        <span class="built_in">sort</span>(s.<span class="built_in">begin</span>(),s.<span class="built_in">end</span>());</span><br><span class="line">        <span class="type">int</span> index = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>;i &lt; s.<span class="built_in">size</span>();++i)&#123;</span><br><span class="line">            <span class="keyword">if</span>(index &lt; g.<span class="built_in">size</span>() &amp;&amp; g[index] &lt;= s[i])&#123;</span><br><span class="line">                index++;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> index;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1005</td>
<td>K次取反后最大化的数组和（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/maximize-sum-of-array-after-k-negations/">1005. K 次取反后最大化的数组和 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>本题思路其实比较好想了，如何可以让数组和最大呢？</p>
<p>贪心的思路，局部最优：让绝对值大的负数变为正数，当前数值达到最大，整体最优：整个数组和达到最大。</p>
<p>局部最优可以推出全局最优。</p>
<p>那么如果将负数都转变为正数了，K依然大于0，此时的问题是一个有序正整数序列，如何转变K次正负，让 数组和 达到最大。</p>
<p>那么又是一个贪心：局部最优：只找数值最小的正整数进行反转，当前数值可以达到最大（例如正整数数组{5, 3, 1}，反转1 得到-1 比 反转5得到的-5 大多了），全局最优：整个 数组和 达到最大。</p>
<p>虽然这道题目大家做的时候，可能都不会去想什么贪心算法，一鼓作气，就AC了。</p>
<p><strong>我这里其实是为了给大家展现出来 经常被大家忽略的贪心思路，这么一道简单题，就用了两次贪心！</strong></p>
<p>那么本题的解题步骤为：</p>
<ul>
<li>第一步：将数组按照绝对值大小从大到小排序，<strong>注意要按照绝对值的大小</strong></li>
<li>第二步：从前向后遍历，遇到负数将其变为正数，同时K–</li>
<li>第三步：如果K还大于0，那么反复转变数值最小的元素，将K用完</li>
<li>第四步：求和</li>
</ul>
<p>对应C++代码如下：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">static bool cmp(int a,int b)&#123;</span><br><span class="line">    return abs(a)&gt;abs(b);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line">public:</span><br><span class="line">    int largestSumAfterKNegations(vector&lt;int&gt;&amp; A, int K) &#123;</span><br><span class="line">        //将数组按照绝对值大小，从大到小排列</span><br><span class="line">        sort(A.begin(),A.end(),cmp);</span><br><span class="line">        //如果数组中有负数，转为正数，同时k--</span><br><span class="line">        for(int i=0;i&lt;A.size()-1;i++)&#123;</span><br><span class="line">            if(A[i]&lt;0&amp;&amp;K&gt;0)&#123;</span><br><span class="line">                A[i]*=-1;</span><br><span class="line">                K--;</span><br><span class="line"></span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        //如果k不为0，把数组中最小的数反复乘以-1，直到k用完</span><br><span class="line">        //K%2==0的话，数组中的数还是原数</span><br><span class="line">        if(K%2==1)&#123;</span><br><span class="line">            A[A.size()-1]*=-1;</span><br><span class="line">        &#125;</span><br><span class="line">        //求和</span><br><span class="line">        int res=0;</span><br><span class="line">        for(int a:A)&#123;</span><br><span class="line">            res+=a;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>860</td>
<td>柠檬水找零（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/lemonade-change/">860. 柠檬水找零 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>本题只需维护三种金额的数量：5,10,20，</p>
<p>情况一：账单是5，直接收下。</p>
<p>情况二：账单是10，消耗一个5，增加一个10</p>
<p>情况三：账单是20，优先消耗一个10和一个5，如果不够，再消耗三个5</p>
<p>（收款20时，局部最优：优先消耗10和5，完成本次找零。少消耗5，因为5可以给10和20找零。全局最优：完成全部账单的找零。</p>
<p>局部最优可以推出全局最优，且找不到反例，就可以尝试贪心算法。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">lemonadeChange</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; bills)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> five=<span class="number">0</span>,ten=<span class="number">0</span>,twenty=<span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> bill:bills)&#123;</span><br><span class="line">            <span class="comment">//收到5</span></span><br><span class="line">            <span class="keyword">if</span>(bill==<span class="number">5</span>)&#123;</span><br><span class="line">                five++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//收到10</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(bill==<span class="number">10</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(five&lt;=<span class="number">0</span>)&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    ten++;</span><br><span class="line">                    five--;</span><br><span class="line">                &#125;</span><br><span class="line">                </span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">//收到20</span></span><br><span class="line">            <span class="keyword">else</span> <span class="keyword">if</span>(bill==<span class="number">20</span>)&#123;</span><br><span class="line">                <span class="keyword">if</span>(five&gt;=<span class="number">1</span>&amp;&amp;ten&gt;=<span class="number">1</span>)&#123;<span class="comment">//优先用10来找零</span></span><br><span class="line">                    five--;</span><br><span class="line">                    ten--;</span><br><span class="line">                    twenty++;<span class="comment">//可以不记录20块钱的个数，不用20找零</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span> <span class="keyword">if</span>(five&gt;=<span class="number">3</span>)&#123;</span><br><span class="line">                    five-=<span class="number">3</span>;</span><br><span class="line">                    twenty++;<span class="comment">//可以不记录20块钱的个数，不用20找零</span></span><br><span class="line">                &#125;</span><br><span class="line">                <span class="keyword">else</span>&#123;</span><br><span class="line">                    <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>53</td>
<td>最大子序和（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/maximum-subarray/">53. 最大子序和 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>局部最优：当前“连续和”为负数的时候立刻放弃，从下一个元素重新计算“连续和”，因为负数加上下一个元素 “连续和”只会越来越小。</p>
<p>全局最优：选取最大“连续和”</p>
<p>遍历nums，从头开始用count累积，如果count一旦加上nums[i]变为负数，那么就应该从nums[i+1]开始从0累积count了，因为已经变为负数的count，只会拖累总和。</p>
<p>中间的最大和由result记录下来了。</p>
<p>题目中的答案有个示例【-2，-1】</p>
<p>if(result&lt;count)和if(count&lt;&#x3D;0)，写的时候我颠倒了，会改变了count的值，res就记录不到正确的最大值了。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">maxSubArray</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> result = INT32_MIN;</span><br><span class="line">        <span class="type">int</span> count = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;nums.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            count+=nums[i];</span><br><span class="line">            <span class="keyword">if</span>(result&lt;count)&#123;</span><br><span class="line">                result=count;</span><br><span class="line">            &#125; </span><br><span class="line">            <span class="keyword">if</span>(count&lt;=<span class="number">0</span>)&#123;</span><br><span class="line">                count=<span class="number">0</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>452</td>
<td>用最少数量的箭引爆气球（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/minimum-number-of-arrows-to-burst-balloons/">452. 用最少数量的箭引爆气球 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>直觉上来看，貌似只射重叠最多的气球，用的弓箭一定最少</p>
<p>试一下举反例，发现没有这种情况。</p>
<p>那么就试一试贪心吧！</p>
<p>局部最优：当气球出现重叠，一起射，所用弓箭最少。</p>
<p>全局最优：把所有气球射爆所用弓箭最少。</p>
<p><strong>为了让气球尽可能的重叠，需要对数组进行排序</strong>。用到sort函数</p>
<p>这里的排序不是简单的对整数排序，是按照数组的第一元素从小到大排序，不能简单地用sort(nums.begin(),nums.end()),</p>
<p>而是用sort(nums.begin(),nums.end(),cmp),cmp函数必须加上static，返回值是bool类型。例如：</p>
<p>static bool cmp(vector<int>&amp; a,vector<int>&amp; b){</p>
<p>​    return a[0]&lt;b[0];</p>
<p>  }</p>
<p>传入参数时，如果是数组，用引用&amp;不会另外开辟内存，而是直接用原数组的数进行运算。不用引用&amp;，会为参数另外开辟内存，每次用cmp函数都要花时间开辟内存，可能会运行超出时间限制。</p>
<p><strong>按照气球的起始位置排序，从前向后遍历气球数组</strong>，尽可能让气球重复，前两个区间：比较第一个的右边界&gt;&#x3D;第二个的左边界，则气球重叠。有两个已经重叠，再比较第三个时，要比较前两个区间的最小右边界和第三个区间的左边界。因为如果想三个都重叠，必须满足最小的右边界（画图可以看出）。</p>
<p>前两个重叠时，不用弓箭加一，因为刚开始默认弓箭为1（因为数组数&gt;&#x3D;1）.不重叠，那肯定需要再有一个弓箭射后面的气球，这时弓箭数加一。</p>
<p>代码：</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">cmp</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; a,vector&lt;<span class="type">int</span>&gt;&amp; b)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a[<span class="number">0</span>]&lt;b[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMinArrowShots</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; points)</span> </span>&#123;</span><br><span class="line">        <span class="comment">/*输入一个二维数组，输出一个整数*/</span></span><br><span class="line">        <span class="keyword">if</span>(points.<span class="built_in">size</span>()==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 先将二维数组排序</span></span><br><span class="line">        <span class="built_in">sort</span>(points.<span class="built_in">begin</span>(),points.<span class="built_in">end</span>(),cmp);</span><br><span class="line">        <span class="type">int</span> result=<span class="number">1</span>;<span class="comment">// 需要几只箭</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;points.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="comment">// 会发生重叠</span></span><br><span class="line">            <span class="keyword">if</span>(points[i<span class="number">-1</span>][<span class="number">1</span>]&gt;=points[i][<span class="number">0</span>])&#123;</span><br><span class="line">                points[i][<span class="number">1</span>]=<span class="built_in">min</span>(points[i][<span class="number">1</span>],points[i<span class="number">-1</span>][<span class="number">1</span>]);<span class="comment">// 更新当前气球的右边界</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 没有重叠</span></span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                result++;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>435</td>
<td>无重叠区间（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/non-overlapping-intervals/">435. 无重叠区间 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>本题与i452的区别：</p>
<p>移除重叠区间，按照右边界从小到大排序，如果前一个的右边界大于下一个的左边界，则算是重叠，然后保留重叠两个区间的右边界最小值（较大的可能会重叠更多区间，题目要求是移除区间的最小数量）</p>
<p>cmp两种都可以，第二种，考虑了如果两个元素相等，再怎么判断。但a[0]&lt;b[0];应该会对相等情况给一个结果应该。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"> <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">cmp</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; a,vector&lt;<span class="type">int</span>&gt;&amp; b)</span></span>&#123;</span><br><span class="line">         </span><br><span class="line">    <span class="keyword">return</span> a[<span class="number">0</span>]&lt;b[<span class="number">0</span>];</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p>和</p>
<pre><code> static bool cmp(vector&lt;int&gt;&amp; a,vector&lt;int&gt;&amp; b)&#123;
    if(a[0]==b[0])&#123;
         return a[1]&lt;b[1];
    &#125;
    return a[0]&lt;b[0];
&#125;
</code></pre>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">cmp</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; a,vector&lt;<span class="type">int</span>&gt;&amp; b)</span></span>&#123;</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">if</span>(a[<span class="number">0</span>]==b[<span class="number">0</span>])&#123;</span><br><span class="line">            <span class="keyword">return</span> a[<span class="number">1</span>]&lt;b[<span class="number">1</span>];</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> a[<span class="number">0</span>]&lt;b[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">findMinArrowShots</span><span class="params">(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; points)</span> </span>&#123;</span><br><span class="line">        <span class="comment">/*输入一个二维数组，输出一个整数*/</span></span><br><span class="line">        <span class="keyword">if</span>(points.<span class="built_in">size</span>()==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 先将二维数组排序</span></span><br><span class="line">        <span class="built_in">sort</span>(points.<span class="built_in">begin</span>(),points.<span class="built_in">end</span>(),cmp);</span><br><span class="line">        <span class="type">int</span> result=<span class="number">1</span>;<span class="comment">// 需要几只箭</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;points.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="comment">// 会发生重叠</span></span><br><span class="line">            <span class="keyword">if</span>(points[i<span class="number">-1</span>][<span class="number">1</span>]&gt;=points[i][<span class="number">0</span>])&#123;</span><br><span class="line">                points[i][<span class="number">1</span>]=<span class="built_in">min</span>(points[i][<span class="number">1</span>],points[i<span class="number">-1</span>][<span class="number">1</span>]);<span class="comment">// 更新当前气球的右边界</span></span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 没有重叠</span></span><br><span class="line">            <span class="keyword">else</span>&#123;</span><br><span class="line">                result++;</span><br><span class="line">            &#125;</span><br><span class="line">            </span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>56</td>
<td>合并区间（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/merge-intervals/">56. 合并区间 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="type">static</span> <span class="type">bool</span> <span class="title">cmp</span><span class="params">(vector&lt;<span class="type">int</span>&gt; &amp;a,vector&lt;<span class="type">int</span>&gt; &amp;b)</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> a[<span class="number">0</span>]&lt;b[<span class="number">0</span>];</span><br><span class="line">    &#125;</span><br><span class="line">    vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; <span class="built_in">merge</span>(vector&lt;vector&lt;<span class="type">int</span>&gt;&gt;&amp; intervals) &#123;</span><br><span class="line">        <span class="comment">/*输入一个二维数组，输出一个二维数组*/</span></span><br><span class="line">        <span class="keyword">if</span>(intervals.<span class="built_in">size</span>()==<span class="number">1</span>)&#123;</span><br><span class="line">            <span class="keyword">return</span> intervals;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//对数组进行排序</span></span><br><span class="line">        <span class="built_in">sort</span>(intervals.<span class="built_in">begin</span>(),intervals.<span class="built_in">end</span>(),cmp);</span><br><span class="line">        <span class="comment">//</span></span><br><span class="line">        vector&lt;vector&lt;<span class="type">int</span>&gt;&gt; result;</span><br><span class="line">        <span class="type">bool</span> flag = <span class="literal">false</span>;<span class="comment">// 标记最后一个区间有没有合并</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">1</span>;i&lt;intervals.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            <span class="comment">// 当相邻区间重叠时，合并，当前区间i就是合并后的区间</span></span><br><span class="line">            <span class="type">int</span> start=intervals[i<span class="number">-1</span>][<span class="number">0</span>];</span><br><span class="line">            <span class="type">int</span> end = intervals[i<span class="number">-1</span>][<span class="number">1</span>];</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">while</span>(i&lt;intervals.<span class="built_in">size</span>()&amp;&amp;end&gt;=intervals[i][<span class="number">0</span>])&#123;</span><br><span class="line">                end = <span class="built_in">max</span>(intervals[i][<span class="number">1</span>],end);</span><br><span class="line">                <span class="keyword">if</span> (i == intervals.<span class="built_in">size</span>() - <span class="number">1</span>) flag = <span class="literal">true</span>;</span><br><span class="line">                i++;</span><br><span class="line">            &#125;</span><br><span class="line">            result.<span class="built_in">push_back</span>(&#123;start,end&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 如果最后一个区间没有和前一个区间重叠，将需单独加入result</span></span><br><span class="line">        <span class="keyword">if</span> (flag == <span class="literal">false</span>) &#123;</span><br><span class="line">            result.<span class="built_in">push_back</span>(&#123;intervals[intervals.<span class="built_in">size</span>() - <span class="number">1</span>][<span class="number">0</span>], intervals[intervals.<span class="built_in">size</span>() - <span class="number">1</span>][<span class="number">1</span>]&#125;);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th><em>LeetCode题目</em>*</th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>55</td>
<td>跳跃游戏（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/jump-game/submissions/">55. 跳跃游戏 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>该题判断是否能跳到终点。</p>
<p>刚看到本题一开始可能想：当前位置元素如果是3，我究竟是跳一步呢，还是两步呢，还是三步呢，究竟跳几步才是最优呢？</p>
<p>其实跳几步无所谓，关键在于可跳的覆盖范围！不一定非要明确一次究竟跳几步，每次取最大的跳跃步数，这个就是可以跳跃的覆盖范围。</p>
<p>这个范围内，别管是怎么跳的，反正一定可以跳过来。</p>
<p><strong>那么这个问题就转化为跳跃覆盖范围究竟可不可以覆盖到终点！</strong></p>
<p>每次移动取最大跳跃步数（得到最大的覆盖范围），每移动一个单位，就更新最大覆盖范围。</p>
<p><strong>贪心算法局部最优解：每次取最大跳跃步数（取最大覆盖范围），整体最优解：最后得到整体最大覆盖范围，看是否能到终点</strong>。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">canJump</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> cover = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">if</span> (nums.<span class="built_in">size</span>() == <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 只有一个元素，就是能达到</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt;= cover; i++) &#123; <span class="comment">// 注意这里是小于等于cover</span></span><br><span class="line">            cover = <span class="built_in">max</span>(i + nums[i], cover);</span><br><span class="line">            <span class="keyword">if</span> (cover &gt;= nums.<span class="built_in">size</span>() - <span class="number">1</span>) <span class="keyword">return</span> <span class="literal">true</span>; <span class="comment">// 说明可以覆盖到终点了</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<table>
<thead>
<tr>
<th>题目</th>
<th>相关链接</th>
</tr>
</thead>
<tbody><tr>
<td>763划分字母区间（中等难度）</td>
<td></td>
</tr>
</tbody></table>
<p>记录每个字符在数组中出现的最远距离，找到之前遍历过的所有字母的最远边界，这个边界点就是分割点。前面出现的所有字母最远就到这个边界。</p>
<p>分为两步：</p>
<p>1 统计每个字符出现的最远位置</p>
<p>2 从头遍历字符，更新字符出现的最远下表，如果找到字符最远出现位置下表和当前下标相等，则找到了分割点。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span>&#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">partitionLabels</span><span class="params">(string s)</span></span>&#123;</span><br><span class="line">        <span class="comment">// 记录每个字符出现的最远下标</span></span><br><span class="line">        <span class="type">int</span> hash[<span class="number">27</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;s.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            hash[s[i]-<span class="string">&#x27;a&#x27;</span>]=i;</span><br><span class="line">        &#125;</span><br><span class="line">        vector&lt;<span class="type">int</span>&gt; res;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;s.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            right=<span class="built_in">max</span>(right,hash[s[i]-<span class="string">&#x27;a&#x27;</span>]);</span><br><span class="line">            <span class="keyword">if</span>(i==right)&#123;</span><br><span class="line">                res.<span class="built_in">push_back</span>(right-left+<span class="number">1</span>);</span><br><span class="line">                left=i+<span class="number">1</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">        </span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><em>LeetCode题目</em>*</th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>135</td>
<td>（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/jump-game/submissions/">55. 跳跃游戏 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>这道题目一定是要确定一边之后，再确定另一边，例如比较每一个孩子的左边，然后再比较右边，<strong>如果两边一起考虑一定会顾此失彼。</strong></p>
<p>先确定右边评分大于左边的情况（也就是从前向后遍历）</p>
<p>此时局部最优：只要右边评分比左边大，右边的孩子就多一个糖果，全局最优：相邻的孩子中，评分高的右孩子获得比左边孩子更多的糖果</p>
<p>2.再确定左孩子大于右孩子的情况（从后向前遍历）</p>
<p>遍历顺序这里有同学可能会有疑问，为什么不能从前向后遍历呢？</p>
<p>因为如果从前向后遍历，根据 ratings[i + 1] 来确定 ratings[i] 对应的糖果，那么每次都不能利用上前一次的比较结果了。</p>
<p>如果 ratings[i] &gt; ratings[i + 1]，此时candyVec[i]（第i个小孩的糖果数量）就有两个选择了，一个是candyVec[i + 1] + 1（从右边这个加1得到的糖果数量），一个是candyVec[i]（之前比较右孩子大于左孩子得到的糖果数量）。</p>
<p>那么又要贪心了，局部最优：取candyVec[i + 1] + 1 和 candyVec[i] 最大的糖果数量，保证第i个小孩的糖果数量即大于左边的也大于右边的。全局最优：相邻的孩子中，评分高的孩子获得更多的糖果。</p>
<p>整体代码：     </p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">int</span> <span class="title">candy</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; ratings)</span> </span>&#123;</span><br><span class="line">        <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">candyVec</span><span class="params">(ratings.size(), <span class="number">1</span>)</span></span>;</span><br><span class="line">        <span class="comment">// 从前向后</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; ratings.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ratings[i] &gt; ratings[i - <span class="number">1</span>]) candyVec[i] = candyVec[i - <span class="number">1</span>] + <span class="number">1</span>;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 从后向前</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = ratings.<span class="built_in">size</span>() - <span class="number">2</span>; i &gt;= <span class="number">0</span>; i--) &#123;</span><br><span class="line">            <span class="keyword">if</span> (ratings[i] &gt; ratings[i + <span class="number">1</span>] ) &#123;</span><br><span class="line">                candyVec[i] = <span class="built_in">max</span>(candyVec[i], candyVec[i + <span class="number">1</span>] + <span class="number">1</span>);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 统计结果</span></span><br><span class="line">        <span class="type">int</span> result = <span class="number">0</span>;</span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; candyVec.<span class="built_in">size</span>(); i++) result += candyVec[i];</span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbugs Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbugs Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/" class="post-title-link" itemprop="url">「论文分享」自适应神经树</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		《Adaptive Neural Trees》是来自英国伦敦的Ryutaro Tanno等人发表在ICML 2019（CCF推荐的A类会议）上的一篇论文，这里是<a target="_blank" rel="noopener" href="http://proceedings.mlr.press/v97/tanno19a/tanno19a.pdf">原文链接</a>和<a target="_blank" rel="noopener" href="https://github.com/rtanno21609/AdaptiveNeuralTrees">原文代码</a>。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​		深层神经网络和决策树在很大程度上依赖于不同的范式；通常，前者使用 预先指定的体系结构进行表征学习，而后者通过使用数据驱动的体系结构学习预先指定的特征的层次结构来实现。本文通过自适应神经树（ANTs）将这两种方法结合起来，该算法将表征学习融入决策树的<strong>边缘</strong>（edges）、<strong>路由函数</strong>（routing functions）和<strong>叶节点</strong>（leaf nodes），以及基于反向传播的训练算法，该算法从原始模块（例如卷积层）自适应地增长体系结构。本文证明，ANTs不仅在实现分类和再分类数据集上具有竞争性能，而且具备如下好处：</p>
<p>（i）通过条件计算进行轻量级推理；</p>
<p>（ii）对任务有用的特征进行更高层次的分离，例如学习有意义的类关联，如分离自然和人造对象；</p>
<p>（iii）使体系结构适应训练数据集大小和复杂性的机制。</p>
<h1 id="1、简介"><a href="#1、简介" class="headerlink" title="1、简介"></a>1、简介</h1><p>​		神经网络（NNs）和决策树（DTs）都是强大的机器学习模型，在学术和商业应用中都取得了成功。然而，这两种方法通常具有相互排斥的优点和局限性。</p>
<table>
<thead>
<tr>
<th><strong>模型</strong></th>
<th><strong>优点</strong></th>
<th><strong>局限性</strong></th>
<th><strong>常见改进思路</strong></th>
</tr>
</thead>
<tbody><tr>
<td>神经网络（NN）</td>
<td>自动学习数据的分层表示，减少了对数据特征工程的需求；使用随机优化法进行训练，可以扩展到大型数据集；在现代硬件加持下可以在众多问题中取得前所未有的精度。</td>
<td>体系结构通常需要针对特定任务或数据集进行设计或修改；大型模型具备重量级推理，计算量很大</td>
<td>知识蒸馏、迁移学习</td>
</tr>
<tr>
<td>决策树（DT）</td>
<td>自动学习分层数据集群和如何分割输入空间，具备高度可解释性；体系结构可以根据训练数据进行优化；轻量级推理</td>
<td>需要手动设计好的数据特征，路径函数表达能力不如神经网络，无法直接使用神经网络的优化方法，</td>
<td>增加决策树数量的方法，如随机森林等</td>
</tr>
</tbody></table>
<p>​		该文的工作的目标是结合NNs和DTs，以获得这两种方法的互补优势。</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的改进.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E6%94%B9%E8%BF%9B.png"></p>
<p>​		根据该文介绍，ANTs从DTs和NNs继承了以下理想特性：</p>
<p>​	（1）表征学习：由于ANTs的每个根到叶路径都是一个神经网络，因此可通过基于梯度的优化进行端到端的特征学习。</p>
<p>​	（2）架构学习：通过逐渐增长的ANTs，架构适应数据集的可用性和复杂性，增长过程可以看作是对模型类具有硬约束的体系结构搜索。</p>
<p>​	（3）轻量级推理：在推理时，ANTs进行条件计算，在每个样本的基础上选择树上的单个根到叶路径，只激活模型参数的一个子集。</p>
<p>​		该文通过基于如下三个数据集的实验验证了ANTs在回归任务和分类任务的高性能表现：</p>
<table>
<thead>
<tr>
<th><strong>数据集</strong></th>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
</tr>
</thead>
<tbody><tr>
<td>MNIST分类数据集</td>
<td>LeCun等人，1998年</td>
<td>《Gradient-based learning applied to document recognition》</td>
</tr>
<tr>
<td>CIFAR-10分类数据集</td>
<td>Krizhevsky和Hinton，2009年</td>
<td>《Learning multiple layers of features from tiny images》</td>
</tr>
<tr>
<td>SARCOS多元回归数据集</td>
<td>Vijayakumar和Schaal，2000年</td>
<td>《Locally weighted projection regression: An o(n) algorithm for incremental real time learning in high dimensional space》</td>
</tr>
</tbody></table>
<p>​		实验结果显示，在SARCOS多元回归数据集上性能最好的方法都是基于树的，ANTs的在均方误差（MSE）指标上最小；ANT在图像分类方面远远优于最先进的深度随机森林RF（Zhou&amp;Feng，2017）和GBT（Ponomareva等人，2017）方法，其结构在MNIST上的准确率超过99%，在CIFAR-10上的准确率超过90%。</p>
<h1 id="2、相关工作"><a href="#2、相关工作" class="headerlink" title="2、相关工作"></a>2、相关工作</h1><p>​		决策树是机器学习中的一种预测模型，常应用于数据挖掘中。模糊决策树是传统决策树的一个扩充和完善，使决策树可以处理不确定性。</p>
<p>软决策树是模糊决策树中的一类，通过结合树的生长和修剪来确定软决策树的结构，并对树进行了修正来提高它的泛化能力。软决策树的决策准则是一个范围区间，而非一个特定的数值。相比较于标准决策树，软决策树的分类结果更准确。</p>
<p>​		决策树和神经网络结合的相关工作：</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Jordan和Jacobs，1994</td>
<td>Hierarchical mixtures of experts and the em algorithm</td>
<td>提出了一种树结构的监督学习体系结构：分层混合专家（HME），其模型的学习被视为一个最大似然问题，然后使用一种期望最大化（EM）算法来调整结构的参数。该模型中树的分割不是硬决策（hard decision），而是由软概率（soft probabilistic）决定的，但是其树结构是固定的，路由器是简单的线性分类器。</td>
</tr>
<tr>
<td>Suarez和Lutsko ,1999</td>
<td>Globally optimal fuzzy decision  trees for classification and regression</td>
<td>提出了一种新颖的模糊决策树，其通过在CART决策树的骨架上叠加模糊结构将决策树转换为一种强大的函数逼近，并可以使用一种自动生成方法来处理分类和回归问题。</td>
</tr>
<tr>
<td>Irsoy等人，2012</td>
<td>Soft decision trees</td>
<td>提出了一种新的决策树结构，其既具备HME的软决策，又可以在需要时添加新节点，并使用梯度下降学习参数。</td>
</tr>
<tr>
<td>Irsoy等人，2014</td>
<td>Budding trees</td>
<td>提出了一种萌芽树BT，其中一个节点既可以是叶子，也可以是内部决策节点。每个花蕾节点从一个叶节点开始，然后可以生长子节点，但随后，如果必要，可以修剪其子节点。</td>
</tr>
<tr>
<td>Laptev和Buhmann, 2014.</td>
<td>Convolutional decision trees for feature learning and segmentation</td>
<td>提出了一种通用的分割算法ConvDT，在构建多元决策树的同时，将信息量最大、可解释性最强的特征提取为卷积核。该算法的训练速度比常规CNN快几个数量级，并在基准数据集的处理质量方面达到了最先进的水平。</td>
</tr>
<tr>
<td>Rota Bulo和Kontschieder, 2014</td>
<td>Neural decision forests for semantic image labelling</td>
<td>提出了神经决策森林NDT，用于分割语义图像；该文章通过引入随机多层感知器（rMLP）作为新的分割节点来弥补这一差距，该节点可以学习非线性、数据特定的表示，并通过为新出现的子节点找到最佳预测来利用它们。</td>
</tr>
<tr>
<td>Kontschieder等人，2015</td>
<td>Deep neural decision forests</td>
<td>提出了一种新的深度决策森林NDF，通过端到端的方式对分类树进行训练，将分类树与深度卷积网络中已知的表示学习功能统一起来。</td>
</tr>
<tr>
<td>Leon和Denoyer, 2016</td>
<td>Policy-gradient methods for decision trees.</td>
<td>提出了一种新的强化决策树（RDT），主要思想是将分类问题视为一个序贯决策过程，通过直接求解全局（可导）目标函数，而不使用基于启发式的贪婪技术来学习分类策略；</td>
</tr>
<tr>
<td>Ioannou等人，2016</td>
<td>Decision forests, convolutional networks and the models</td>
<td>将决策森林和卷积神经网络结合在一起，提出了条件网络（CNet）。</td>
</tr>
<tr>
<td>Frosst和Hinton，2017</td>
<td>Distilling a neural network into a soft decision tree</td>
<td>使用软决策树来从一个训练好的神经网络中提取知识，从而尝试解释神经网络的分类决策，其结果证明，这种软决策树比直接从训练数据中学习的软决策树具有更好的泛化能力。</td>
</tr>
<tr>
<td>Xiao ,2017</td>
<td>Neual decision tree towards fully functioned neural graph</td>
<td>提出了一种神经决策树的变体NDT，其在反向传播过程中，可以近似地计算出特定条件变量的梯度，从而生成一个功能完备的神经网络图。</td>
</tr>
</tbody></table>
<h1 id="3、自适应神经树"><a href="#3、自适应神经树" class="headerlink" title="3、自适应神经树"></a>3、自适应神经树</h1><p>​		ANT使用了自己的一套术语来定义其结构，其结构基本统一了许多现有的树结构模型。</p>
<p>​		首先ANT的学习仍然是一种监督学习，其训练数据简记为一组N个标记过的样本：$\left(\mathbf{x}^{(1)}, \mathbf{y}^{(1)}\right), \ldots,\left(\mathbf{x}^{(N)}, \mathbf{y}^{(N)}\right) \in \mathcal{X} \times \mathcal{Y}$，ANT的目标是从中学习一个条件分布 $p(\mathbf{y} \mid \mathbf{x})$。</p>
<p>​		该文将ANT定义为一个二元组 $(\mathbb{T}, \mathbb{O})$,其中$\mathbb{T}$表示模型的拓扑结构（本质是一个有限图结构），$\mathbb{O}$表示其拓扑结构上进行的操作集（本质是一系列非线性函数）。</p>
<h2 id="（1）拓扑结构-mathbb-T"><a href="#（1）拓扑结构-mathbb-T" class="headerlink" title="（1）拓扑结构$\mathbb{T}$"></a>（1）拓扑结构$\mathbb{T}$</h2><p>拓扑结构$\mathbb{T}$定义为$\mathbb{T}:&#x3D;{\mathcal{N}, \mathcal{E}}$，其中$\mathcal{N} $是所有节点的集合，$\mathcal{E}$是所有节点边的集合，</p>
<p>ANT的拓扑结构也是基于二叉树的图结构，除了顶部根节点外，每个节点都是一个父节点的子节点。</p>
<table>
<thead>
<tr>
<th>种类</th>
<th>符号表示</th>
<th>定义和其他标准树对比</th>
</tr>
</thead>
<tbody><tr>
<td>内部节点</td>
<td>$j\in \mathcal{N}_{\text {int }}$</td>
<td>基本相同，每个内部节点$j\in \mathcal{N}_{\text {int }}$正好有两个子节点，由$\operatorname{left}(j)$和$\operatorname{right}(j)$表示。</td>
</tr>
<tr>
<td>叶子节点</td>
<td>$l \in \mathcal{N}_{\text {leaf }}$</td>
<td>基本相同，没有子节点的节点叫做叶节点$\mathcal{N}_{\text {leaf }}$</td>
</tr>
<tr>
<td>边</td>
<td>$e \in \mathcal{E}$</td>
<td>略有不同，$\mathcal{E}$包含输入数据$\mathbf{x}$到根节点的边。</td>
</tr>
</tbody></table>
<h2 id="（2）操作集-mathbb-O"><a href="#（2）操作集-mathbb-O" class="headerlink" title="（2）操作集$\mathbb{O}$"></a>（2）操作集$\mathbb{O}$</h2><p>操作集$\mathbb{O}$定义为一个三元组$\mathbb{O}&#x3D;(\mathcal{R}, \mathcal{T}, \mathcal{S})$，其所有操作都由三个可微模块构建：</p>
<table>
<thead>
<tr>
<th>可微模块</th>
<th>模块特点</th>
<th>内部计算</th>
</tr>
</thead>
<tbody><tr>
<td>路由器（Routers，$\mathcal{R}$）</td>
<td>每个内部节点$j\in \mathcal{N}_{\text {int }}$对应一个路由器模块，其负责将来自传入边的样本发送到左子节点或右子节点。</td>
<td>$r_{j}^{\theta}: \mathcal{X}<em>{j} \rightarrow[0,1] \in \mathcal{R} $、 由$\theta$参数化，其中$\mathcal{X}</em>{j}$表示节点j处的输入，对于每个$\mathbf{x}<em>{j} \in \mathcal{X}</em>{j}$，输入$r_{j}^{\boldsymbol{\theta}}$（可以是一个小的CNN），得到输出值$r_{j}^{\boldsymbol{\theta}}\left(\mathbf{x}<em>{j}\right)$求若干个$r</em>{j}^{\boldsymbol{\theta}}\left(\mathbf{x}_{j}\right)$的均值，然后构建一个伯努利分布，从分步中采样一个一个0或1的决策（左分支为1，右分支为0）</td>
</tr>
<tr>
<td>转换器（Transformers，$\mathcal{T}$）</td>
<td>每条边$e \in \mathcal{E}$对应一或多个转换器模块,每个转换器负责将前一个模块的样本转换为下一个模块的样本。</td>
<td>每个转换器$t_{e}^{\psi} \in \mathcal{T}$是一个非线性函数，由$\psi$参数化。其形式可以是一个卷积层和ReLU。和标准的决策树不同，其每条边允许通过添加更多转换器来“增长”。</td>
</tr>
<tr>
<td>求解器（Solvers，$\mathcal{S}$）</td>
<td>每个叶节点$l \in \mathcal{N}_{\text {leaf }}$对应一个求解器模块，其负责将输入数据转换为一个条件分布$p(\mathbf{y} \mid \mathbf{x})$的近似值。</td>
<td>$s_{l}^{\phi}: \mathcal{X}<em>{l} \rightarrow \mathcal{Y} \in \mathcal{S}$、 参数化为$\phi$，对于分类任务，$s^{\phi}$可以定义为特征空间$\mathcal{X}</em>{l}$上的线性分类器，该分类器输出类的分布。</td>
</tr>
</tbody></table>
<p>整个ANT树的结构由下图所示：</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT树的结构.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E6%A0%91%E7%9A%84%E7%BB%93%E6%9E%84.png"></p>
<p>在上图中，黑色圆圈表示边上的转换器，白色圆圈表示内部节点上的路由器，灰色圆圈表示叶子节点上的求解器。</p>
<p>以红色阴影路径为例，其计算如下</p>
<p>输入$\mathbf{x}$经历一系列转换器和路由器之后：$\mathbf{x} \rightarrow \mathbf{x}<em>{0}^{\psi}:&#x3D;   t</em>{0}^{\psi}(\mathbf{x}) \rightarrow \mathbf{x}<em>{1}^{\psi}:&#x3D;t</em>{1}^{\psi}\left(\mathbf{x}<em>{0}^{\psi}\right) \rightarrow \mathbf{x}</em>{4}^{\psi}:&#x3D;t_{4}^{\psi}\left(\mathbf{x}_{1}^{\psi}\right) $，</p>
<p>经过求解器模块产生预测分布：$p_{4}^{\phi, \dot{\psi}}(\mathbf{y}):&#x3D;s_{4}^{\phi}\left(\mathbf{x}_{4}^{\psi}\right)$。</p>
<p>选择这条路径的概率：$\pi_{2}^{\psi, \theta}(\mathbf{x}):&#x3D;   r_{0}^{\boldsymbol{\theta}}\left(\mathbf{x}<em>{0}^{\boldsymbol{\psi}}\right) \cdot\left(1-r</em>{1}^{\boldsymbol{\theta}}\left(\mathbf{x}_{1}^{\boldsymbol{\psi}}\right)\right)$。</p>
<h2 id="（3）概率模型"><a href="#（3）概率模型" class="headerlink" title="（3）概率模型"></a>（3）概率模型</h2><p>假设我们有L个叶节点，参数$ \Theta&#x3D;(\boldsymbol{\theta}, \boldsymbol{\psi}, \boldsymbol{\phi})$，其中$\boldsymbol{\theta}, \boldsymbol{\psi}, \boldsymbol{\phi}$分别表示树中路由器、转换器和解算器模块的参数，则完整的概率分布预测计算由叶子分配概率$\pi_{l}^{\theta, \psi} $和叶子预测概率$p_{l}^{\phi, \psi}$组成：</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;全预测分布公式.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/%E5%85%A8%E9%A2%84%E6%B5%8B%E5%88%86%E5%B8%83%E5%85%AC%E5%BC%8F.png"></p>
<p>其中$\mathbf{z} \in{0,1}^{L}$是一个L维的二元潜在变量，并且满足$\sum_{l&#x3D;1}^{L} z_{l}&#x3D;1$，其用来描述叶节点的选择（例如，$z_{l}&#x3D;1$表示使用叶节点L）。</p>
<h3 id="A-叶子分配概率-pi-l-theta-psi-的计算"><a href="#A-叶子分配概率-pi-l-theta-psi-的计算" class="headerlink" title="A  叶子分配概率$\pi_{l}^{\theta, \psi} $的计算"></a>A  叶子分配概率$\pi_{l}^{\theta, \psi} $的计算</h3><p>$\pi_{l}^{\theta, \psi}(\mathbf{x}):&#x3D;p\left(z_{l}&#x3D;1 \mid \mathbf{x}, \boldsymbol{\psi}, \boldsymbol{\theta}\right)$量化了x被分配给叶l的概率，其由从根节点到叶节点$l$的唯一路径$P_{1}$上所有路由器模块的决策概率的乘积给出：</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;某条路径的概率.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/%E6%9F%90%E6%9D%A1%E8%B7%AF%E5%BE%84%E7%9A%84%E6%A6%82%E7%8E%87.png"></p>
<p>其中$l \swarrow j$是表示叶子结点$l$是否在内部节点$j$的左子树中，$\mathbf{x}_{j}^{\psi}$是$\mathbf{x}$在节点$j$下的特征表示。</p>
<p>假设$\mathcal{T}<em>{j}&#x3D;\left{t</em>{e_{1}}^{\psi}, \ldots, t_{e_{n}}^{\psi}\right}$表示从根节点到节点j的路径上的n个转换器模块的有序集，特征向量$\mathbf{x}_{j}^{\psi}$计算如下：</p>
<p>$\mathbf{x}<em>{j}^{\psi}:&#x3D;\left(t</em>{e_{n}}^{\psi} \circ \ldots \circ t_{e_{2}}^{\psi} \circ t_{e_{1}}^{\psi}\right)(\mathbf{x})$</p>
<h3 id="B-叶子预测概率-p-l-phi-psi-的计算"><a href="#B-叶子预测概率-p-l-phi-psi-的计算" class="headerlink" title="B  叶子预测概率$p_{l}^{\phi, \psi}$的计算"></a>B  叶子预测概率$p_{l}^{\phi, \psi}$的计算</h3><p>叶子预测概率$p_{l}^{\phi, \psi}$的计算如下：</p>
<p>$p_{l}^{\phi, \boldsymbol{\psi}}(\mathbf{y}):&#x3D;p\left(\mathbf{y} \mid \mathbf{x}, z_{l}&#x3D;1, \boldsymbol{\phi}, \boldsymbol{\psi}\right)$</p>
<p>其预测了一个叶子节点l上的求解器$s_{l}^{\phi}\left(\mathbf{x}_{\text {parent }(l)}^{\psi}\right) $在目标$\mathbf{y}$上的近似值</p>
<h2 id="（4）推理方案"><a href="#（4）推理方案" class="headerlink" title="（4）推理方案"></a>（4）推理方案</h2><p>该文在准确率和计算力的权衡上考虑了两个推理方案，分别是多路径推理和和单路径推理。</p>
<table>
<thead>
<tr>
<th>推理方案</th>
<th>预测分布的计算方式</th>
<th>特点</th>
</tr>
</thead>
<tbody><tr>
<td>多路径推理</td>
<td>使用完整地概率预测分布，其需要平均所有叶节点上的分布，包括计算树的所有节点和边上的所有操作，</td>
<td>对于大型ANT来说是必要的</td>
</tr>
<tr>
<td>单路径推理</td>
<td>使用其中一条特殊路径的预测分布，该特殊路径通过贪婪地在路由器的最高置信度方向遍历树的决策而得到</td>
<td>将计算限制在一条路径上，从而实现更节省内存和时间的推理</td>
</tr>
</tbody></table>
<h1 id="4、优化"><a href="#4、优化" class="headerlink" title="4、优化"></a>4、优化</h1><p>ANT的训练分两个阶段进行：</p>
<p>1）生长阶段，局部优化学习模型架构；</p>
<p>2）细化阶段，全局优化调整模型参数。</p>
<p>其损失函数使用负对数似然（NLL）：</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的损失函数.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0.png"></p>
<p>由于ANT的所有组件模块都是可微的，所以该方法可以使用基于梯度的优化。</p>
<h2 id="（1）生长阶段"><a href="#（1）生长阶段" class="headerlink" title="（1）生长阶段"></a>（1）生长阶段</h2><p>生长阶段的目的是局部优化模型的结构。</p>
<p>其方法是首先按广度优先顺序选择一个叶节点，对于选择的每个叶节点都可以使用如下3类评估：</p>
<p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的生长阶段.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E7%94%9F%E9%95%BF%E9%98%B6%E6%AE%B5.png"></p>
<p>固定计算图的前一部分，局部优化新添加的（1）和（2）操作，然后计算各自损失值，如果损失值得到减少，则选择该类型的操作否则保留原来的模型。</p>
<h2 id="（2）细化阶段"><a href="#（2）细化阶段" class="headerlink" title="（2）细化阶段"></a>（2）细化阶段</h2><p>生长阶段确定了模型的拓扑结构后，然后继续执行全局优化来优化模型的整体参数。</p>
<h1 id="5、实验"><a href="#5、实验" class="headerlink" title="5、实验"></a>5、实验</h1><h2 id="（1）实验设置"><a href="#（1）实验设置" class="headerlink" title="（1）实验设置"></a>（1）实验设置</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;实验设置.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/%E5%AE%9E%E9%AA%8C%E8%AE%BE%E7%BD%AE.png"></p>
<h2 id="（2）消融实验"><a href="#（2）消融实验" class="headerlink" title="（2）消融实验"></a>（2）消融实验</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的消融实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C.png"></p>
<h2 id="（3）SARCOS多元回归实验的性能对比"><a href="#（3）SARCOS多元回归实验的性能对比" class="headerlink" title="（3）SARCOS多元回归实验的性能对比"></a>（3）SARCOS多元回归实验的性能对比</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的SARCOS回归实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84SARCOS%E5%9B%9E%E5%BD%92%E5%AE%9E%E9%AA%8C.png"></p>
<h2 id="（4）MNIST数字分类实验的性能对比"><a href="#（4）MNIST数字分类实验的性能对比" class="headerlink" title="（4）MNIST数字分类实验的性能对比"></a>（4）MNIST数字分类实验的性能对比</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的MNIST实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84MNIST%E5%AE%9E%E9%AA%8C.png"></p>
<h2 id="（5）CIFAR-10图像分类实验的性能对比"><a href="#（5）CIFAR-10图像分类实验的性能对比" class="headerlink" title="（5）CIFAR-10图像分类实验的性能对比"></a>（5）CIFAR-10图像分类实验的性能对比</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的CIFAR-10实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84CIFAR-10%E5%AE%9E%E9%AA%8C.png"></p>
<h2 id="（6）模型的可解释性"><a href="#（6）模型的可解释性" class="headerlink" title="（6）模型的可解释性"></a>（6）模型的可解释性</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的可解释性.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E5%8F%AF%E8%A7%A3%E9%87%8A%E6%80%A7.png"></p>
<h2 id="（7）细化阶段的影响"><a href="#（7）细化阶段的影响" class="headerlink" title="（7）细化阶段的影响"></a>（7）细化阶段的影响</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的细化阶段的影响.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E7%BB%86%E5%8C%96%E9%98%B6%E6%AE%B5%E7%9A%84%E5%BD%B1%E5%93%8D.png"></p>
<h2 id="（8）自适应模型的复杂性"><a href="#（8）自适应模型的复杂性" class="headerlink" title="（8）自适应模型的复杂性"></a>（8）自适应模型的复杂性</h2><p>![](&#x2F;img-post&#x2F;论文分享&#x2F;2021-10-29-自适应神经树&#x2F;ANT的自适应模型复杂性.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-10-29-%E8%87%AA%E9%80%82%E5%BA%94%E7%A5%9E%E7%BB%8F%E6%A0%91/ANT%E7%9A%84%E8%87%AA%E9%80%82%E5%BA%94%E6%A8%A1%E5%9E%8B%E5%A4%8D%E6%9D%82%E6%80%A7.png"></p>
<h1 id="6、总结"><a href="#6、总结" class="headerlink" title="6、总结"></a>6、总结</h1><p>​		本文引入了自适应神经树（ANTs），将决策树（DTs）的体系结构学习、条件计算和层次聚类与深层神经网络（DNN）的层次表示学习和梯度下降优化相结合，结合本文提出的训练算法来渐进式增长和优化ANTs的参数和结构。<br>​       实验证明ANTs在回归（SARCOS数据集）和分类（MNIST和CIFAR10数据集）方面的优势，同时仍然实现了高性能。</p>
<p>​		ANT模型和shortcut connections的结合可能使ANT在图像分类上的性能进一步提升。</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/7/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/7/">7</a><span class="page-number current">8</span><a class="page-number" href="/page/9/">9</a><span class="space">&hellip;</span><a class="page-number" href="/page/12/">12</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/9/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">vvbuys</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
