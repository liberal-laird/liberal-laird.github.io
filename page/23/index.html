<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width">
<meta name="baidu-site-verification" content="codeva-6wmKWl5hmx" />
<meta name="bytedance-verification-code" content="GcOf/MpQ8shZ5Hh/2hvr" />
<meta name="google-site-verification" content="wivqPhuFdISMEKkFZjOWHPYJGSvd716d9R7Bwy2Jj-A" />
<script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-4636539228226058"
     crossorigin="anonymous"></script>
<meta name="theme-color" content="#222"><meta name="generator" content="Hexo 7.1.1">

  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">



<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.0/css/all.min.css" integrity="sha256-yIDrPSXHZdOZhAqiBP7CKzIwMQmRCJ8UeB8Jo17YC4o=" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous">

<script class="next-config" data-name="main" type="application/json">{"hostname":"www.vvbuys.com","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.19.1","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12},"copycode":{"enable":false,"style":null},"fold":{"enable":false,"height":500},"bookmark":{"enable":false,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"i18n":{"placeholder":"Searching...","empty":"We didn't find any results for the search: ${query}","hits_time":"${hits} results found in ${time} ms","hits":"${hits} results found"}}</script><script src="/js/config.js"></script>

    <meta name="description" content="Share some post and some issue for linux program">
<meta property="og:type" content="website">
<meta property="og:title" content="VVbuys Blog">
<meta property="og:url" content="https://www.vvbuys.com/page/23/index.html">
<meta property="og:site_name" content="VVbuys Blog">
<meta property="og:description" content="Share some post and some issue for linux program">
<meta property="og:locale" content="en_US">
<meta property="article:author" content="vvbuys">
<meta property="article:tag" content="Linux hyprland Python Rust Golang javascript">
<meta name="twitter:card" content="summary">


<link rel="canonical" href="https://www.vvbuys.com/page/23/">



<script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"en","comments":"","permalink":"","path":"page/23/index.html","title":""}</script>

<script class="next-config" data-name="calendar" type="application/json">""</script>
<title>VVbuys Blog - standalone Linux lover</title>
  








  <noscript>
    <link rel="stylesheet" href="/css/noscript.css">
  </noscript>
</head>

<body itemscope itemtype="http://schema.org/WebPage" class="use-motion">
  <div class="headband"></div>

  <main class="main">
    <div class="column">
      <header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="Toggle navigation bar" role="button">
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
        <span class="toggle-line"></span>
    </div>
  </div>

  <div class="site-meta">

    <a href="/" class="brand" rel="start">
      <i class="logo-line"></i>
      <h1 class="site-title">VVbuys Blog</h1>
      <i class="logo-line"></i>
    </a>
      <p class="site-subtitle" itemprop="description">standalone Linux lover</p>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger" aria-label="Search" role="button">
    </div>
  </div>
</div>



<nav class="site-nav">
  <ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>Home</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>Tags</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>Archives</a></li><li class="menu-item menu-item-sitemap"><a href="/sitemap.xml" rel="section"><i class="fa fa-sitemap fa-fw"></i>Sitemap</a></li><li class="menu-item menu-item-commonweal"><a href="/404/" rel="section"><i class="fa fa-heartbeat fa-fw"></i>Commonweal 404</a></li>
  </ul>
</nav>




</header>
        
  
  <aside class="sidebar">

    <div class="sidebar-inner sidebar-overview-active">
      <ul class="sidebar-nav">
        <li class="sidebar-nav-toc">
          Table of Contents
        </li>
        <li class="sidebar-nav-overview">
          Overview
        </li>
      </ul>

      <div class="sidebar-panel-container">
        <!--noindex-->
        <div class="post-toc-wrap sidebar-panel">
        </div>
        <!--/noindex-->

        <div class="site-overview-wrap sidebar-panel">
          <div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person">
  <p class="site-author-name" itemprop="name">vvbuys</p>
  <div class="site-description" itemprop="description">Share some post and some issue for linux program</div>
</div>
<div class="site-state-wrap animated">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
        <a href="/archives/">
          <span class="site-state-item-count">265</span>
          <span class="site-state-item-name">posts</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
          <a href="/categories/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">categories</span></a>
      </div>
      <div class="site-state-item site-state-tags">
          <a href="/tags/">
        <span class="site-state-item-count">36</span>
        <span class="site-state-item-name">tags</span></a>
      </div>
  </nav>
</div>

        </div>
      </div>
    </div>

    
  </aside>


    </div>

    <div class="main-inner index posts-expand">

    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-15-%E3%80%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%91%E5%9C%A8VS%20Code%E4%B8%AD%E9%85%8D%E7%BD%AELeetCode/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-15-%E3%80%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E3%80%91%E5%9C%A8VS%20Code%E4%B8%AD%E9%85%8D%E7%BD%AELeetCode/" class="post-title-link" itemprop="url">「环境配置」在VS Code中配置LeetCode</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-15T00:00:00+00:00">2021-11-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>本博客记录在VS code中配置LeetCode的过程，在VS Code中可以方便我们调试代码。</p>
<h1 id="一、配置环境"><a href="#一、配置环境" class="headerlink" title="一、配置环境"></a>一、配置环境</h1><h2 id="1、安装VSCode并配置环境"><a href="#1、安装VSCode并配置环境" class="headerlink" title="1、安装VSCode并配置环境"></a>1、安装<a target="_blank" rel="noopener" href="https://so.csdn.net/so/search?from=pc_blog_highlight&q=VSCode">VSCode</a>并配置环境</h2><p>Leetcode插件本身是不需要配置编程语言环境的，因为它使用的是LeetCode官方编译器进行调试。</p>
<p>所以正常只需要安装VSCode即可，这一步比较简单。</p>
<h2 id="2、-安装LeetCode插件"><a href="#2、-安装LeetCode插件" class="headerlink" title="2、 安装LeetCode插件"></a>2、 安装LeetCode插件</h2><p>在插件扩展中搜索LeetCode插件，安装热度最高的那个即可。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;安装LeetCode.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;安装LeetCode.png)</p>
<h2 id="3、-安装Node-js"><a href="#3、-安装Node-js" class="headerlink" title="3、 安装Node.js"></a>3、 安装Node.js</h2><p>在安装完LeetCode插件之后，点击LeetCode插件的选项页，会提示你安装Node.js，按照安装程序的提示安装即可。</p>
<p>Node.js在安装完成之后会自动配置环境变量，但需要记住安装位置，后边配置LeetCode会使用到。</p>
<h2 id="4、登录LeetCode账户"><a href="#4、登录LeetCode账户" class="headerlink" title="4、登录LeetCode账户"></a>4、登录LeetCode账户</h2><p>完成上述操作后，建议重启一次VS Code。</p>
<h3 id="（1）修改站点"><a href="#（1）修改站点" class="headerlink" title="（1）修改站点"></a>（1）修改站点</h3><p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;修改站点为中国LeetCode.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;修改站点为中国LeetCode.png)</p>
<h3 id="（2）登录账户"><a href="#（2）登录账户" class="headerlink" title="（2）登录账户"></a>（2）登录账户</h3><p>登录账户前请登录网页版LeetCode确认自己的账户名（非昵称）和密码（很可能没有设置）。</p>
<p>然后点击LeetCode插件按钮，点击Sign in LeetCode，然后输入自己的账号和密码，即可登录。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;登录LeetCode.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;登录LeetCode.png)</p>
<h2 id="5、-配置Node-js路径"><a href="#5、-配置Node-js路径" class="headerlink" title="5、 配置Node.js路径"></a>5、 配置Node.js路径</h2><p>点击扩展按钮，选中LeetCode插件，鼠标右键选择扩展设置<br>找到Node Path，选择相应路径。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;配置nodejs路径.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;配置nodejs路径.png)</p>
<h2 id="6、-配置文件路径"><a href="#6、-配置文件路径" class="headerlink" title="6、 配置文件路径"></a>6、 配置文件路径</h2><p>编程的代码文件都会保存到本地，默认路径为“$HOME.leetcode”。</p>
<p>我们可以自行设置其保存到我们的项目路径<br>点击扩展按钮，选中LeetCode插件，鼠标右键选择扩展设置<br>找到Workspace Folder，输入绝对路径。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;答案文件路径.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;答案文件路径.png)</p>
<p>这样我们就可以在当前路径中找到我们写过的每一个问题的代码：</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;问题代码展示.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;问题代码展示.png)</p>
<h1 id="二、使用操作"><a href="#二、使用操作" class="headerlink" title="二、使用操作"></a>二、使用操作</h1><h2 id="1、选择题目"><a href="#1、选择题目" class="headerlink" title="1、选择题目"></a>1、选择题目</h2><p>LeetCode插件提供类似网页版的题目筛选功能，可以按照题目序号、难度、标签等筛选。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;选择题目.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;选择题目.png)</p>
<h2 id="2、编辑题目代码"><a href="#2、编辑题目代码" class="headerlink" title="2、编辑题目代码"></a>2、编辑题目代码</h2><p>选择一个题目，双击就能出现具体的题目描述。</p>
<p>左侧显示编程窗口，右侧显示题目描述。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;题目描述.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;题目描述.png)</p>
<p>如果代码中出现STL报错，这是因为默认模板中并没有增加STL头文件，</p>
<p>为了方便编程过程中提示，我们可以主动增加头文件。</p>
<p>点击上图中的<strong>Submit</strong>按钮就可以提交结果，</p>
<h2 id="3、使用测试用例"><a href="#3、使用测试用例" class="headerlink" title="3、使用测试用例"></a>3、使用测试用例</h2><p>点击<strong>Test</strong>，会有三个选项供你选择。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;测试用例.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;测试用例.png)</p>
<p>需要注意的是：在使用第二个自行输入用例时，可能有的用例会有多个输入，需要用到换行符，由于LeetCode插件默认“Enter”键为输入结束，所以输入用例时不能使用“Enter”表示换行，需要我们手动输入<strong>“\n“</strong>代替换行符。</p>
<h2 id="4、打印输出信息"><a href="#4、打印输出信息" class="headerlink" title="4、打印输出信息"></a>4、打印输出信息</h2><p>在代码中添加输出信息，然后使用Test可以输出信息。</p>
<p>![](&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;使用测试案例输出信息.png)</p>
<p>![](..&#x2F;&#x2F;img-post&#x2F;环境配置&#x2F;2021-11-15-在VS Code中配置LeetCode&#x2F;使用测试案例输出信息.png)</p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E4%BB%A3%E7%A0%81%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">「项目复现」S3net的训练代码实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-15T00:00:00+00:00">2021-11-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		本博客是作者复现《S3Net: A Single Stream Structure for Depth Guided Image Relighting》的训练代码的笔记。</p>
<h1 id="S3net项目的程序结构"><a href="#S3net项目的程序结构" class="headerlink" title="S3net项目的程序结构"></a>S3net项目的程序结构</h1><blockquote>
<h3 id="一、搭建网络模型"><a href="#一、搭建网络模型" class="headerlink" title="一、搭建网络模型"></a>一、搭建网络模型</h3><h3 id="二、训练网络模型"><a href="#二、训练网络模型" class="headerlink" title="二、训练网络模型"></a>二、训练网络模型</h3><p>1、<strong>获取数据集dataloader</strong>、<strong>获取模型model</strong>、<strong>获取优化器optimizer</strong>、<strong>获取学习率调整器scheduler</strong></p>
<p>2、使用数据集跑n个epoch</p>
<p>​		（1）跑1个eopch	（遍历一遍数据集）</p>
<p>​				获取x，y</p>
<p>​				正向传播得到y’（model.forward）</p>
<p>​				<strong>计算损失</strong>（get_loss）</p>
<p>​				反向传播（optimizer.zero_grad，loss.backward,optimizer.step）</p>
<p>​		（2）动态调整学习率（scheduler.step）</p>
<p>​		（3）定期保存模型（torch.load,model.load_state_dict）</p>
<p>​		（4）打印日志到控制台（tqdn进度条技术）</p>
<p>3、保存实验数据到磁盘（MetricRecorder类）</p>
<p>​	（1）<strong>保存损失、PSNR、SSIM等到.csv文件</strong></p>
<p>​	（2）<strong>保存输入图片、预测图片、目标图片为.png</strong></p>
<h3 id="三、测试网络模型"><a href="#三、测试网络模型" class="headerlink" title="三、测试网络模型"></a>三、测试网络模型</h3></blockquote>
<h2 id="1、如何加载模型和保存模型"><a href="#1、如何加载模型和保存模型" class="headerlink" title="1、如何加载模型和保存模型"></a>1、如何加载模型和保存模型</h2><p><strong>函数：保存模型：</strong></p>
<p>torch.save({‘state_dict’:network.state_dict()}, save_path)是下述代码中最重要的API</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 保存模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">save_model</span>(<span class="params">self, save_dir, network, epoch</span>):</span><br><span class="line">    <span class="comment"># 获取保存文件路径</span></span><br><span class="line">    save_filename = <span class="string">&#x27;%s_net.pth&#x27;</span> % (epoch)//模型文件名</span><br><span class="line">    save_path = os.path.join(save_dir, save_filename)</span><br><span class="line">    <span class="comment"># 保存网络模型</span></span><br><span class="line">    torch.save(&#123;<span class="string">&#x27;state_dict&#x27;</span>:network.state_dict()&#125;, save_path)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>用以上save_model函数定期保存模型：</strong></p>
<p>技巧：在每个epoch保存模型时，同时保存latest模型，万一中断训练，方便加载模型、继续训练。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 定期保存模型</span><br><span class="line"># if self.metric_recorder.update_best_model(&#x27;PSNR&#x27;):</span><br><span class="line">#     self.model.save(self.option.model_path, &#x27;best&#x27;)</span><br><span class="line">if epoch % self.option.save_freq == 0 and epoch != 0:</span><br><span class="line">    self.save_model(self.option.model_path,self.model, &#x27;latest&#x27;)</span><br><span class="line">    self.save_model(self.option.model_path,self.model, epoch)</span><br><span class="line">    np.savetxt(self.iter_path, (epoch, self.n_total_iter), delimiter=&#x27;,&#x27;, fmt=&#x27;%d&#x27;)</span><br><span class="line">    print(&#x27;成功保存模型：epoch %d, iters %d&#x27; % (epoch, self.n_total_iter))</span><br></pre></td></tr></table></figure>



<p><strong>函数：加载模型：</strong></p>
<p>torch.load(save_path)和model.load_state_dict(checkpoint[‘state_dict’])是下述代码中最重要的API</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 导入网络模型</span></span><br><span class="line"><span class="keyword">from</span> network.res2net2 <span class="keyword">import</span> Dehaze3</span><br><span class="line"><span class="comment"># 获取模型</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">get_model</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="comment"># 加载网络模型</span></span><br><span class="line">    model = Dehaze3().to(self.option.device)</span><br><span class="line">    <span class="comment"># 是否加载预训练好的模型</span></span><br><span class="line">    <span class="keyword">if</span> self.option.is_pretrain_model:</span><br><span class="line">        <span class="comment"># 得到保存模型的路径</span></span><br><span class="line">        save_path = os.path.join(self.option.model_path, <span class="string">&#x27;latest_net.pth&#x27;</span>)</span><br><span class="line">        <span class="comment"># 加载之前保存好的模型</span></span><br><span class="line">        checkpoint = torch.load(save_path)</span><br><span class="line">        self.start_epoch, self.n_total_iter = np.loadtxt(self.iter_path, delimiter=<span class="string">&#x27;,&#x27;</span>, dtype=<span class="built_in">int</span>)//<span class="built_in">iter</span>.txt保存之前训练保存的最后的模型的epoch和<span class="built_in">iter</span></span><br><span class="line">        model.load_state_dict(checkpoint[<span class="string">&#x27;state_dict&#x27;</span>])</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;成功预加载网络模型！&#x27;</span>)</span><br><span class="line">    <span class="keyword">else</span>:</span><br><span class="line">        self.start_epoch = <span class="number">0</span></span><br><span class="line">        self.n_total_iter = <span class="number">0</span>  <span class="comment"># 训练的总迭代次数</span></span><br><span class="line">        <span class="built_in">print</span>(<span class="string">&#x27;成功创建网络模型！&#x27;</span>)</span><br><span class="line">    <span class="keyword">return</span> model</span><br></pre></td></tr></table></figure>

<h2 id="2、如何输出实验数据到-csv"><a href="#2、如何输出实验数据到-csv" class="headerlink" title="2、如何输出实验数据到.csv"></a>2、如何输出实验数据到.csv</h2><p>MetricRecorder类：用于记录数据</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">MetricRecorder</span>():</span><br><span class="line">    <span class="comment"># 把实验数据添加到scalarDict字典中</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">add_current_scalar</span>(<span class="params">self, log_dict:<span class="built_in">dict</span></span>):</span><br><span class="line">        <span class="keyword">for</span> tag, value <span class="keyword">in</span> log_dict.items():</span><br><span class="line">            self.scalarDict[tag].append(value)</span><br><span class="line">    <span class="comment">#把scalarDict字典中的每条实验数据添加到csv文件中</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">_write_to_csv</span>(<span class="params">self,epoch_num,validation</span>):</span><br><span class="line">        <span class="keyword">if</span> self.save_to_csv:</span><br><span class="line">            csv_name = <span class="string">&#x27;val_result.csv&#x27;</span> <span class="keyword">if</span> validation <span class="keyword">else</span> <span class="string">&#x27;train_result.csv&#x27;</span>//得到csv文件的名字</span><br><span class="line">            self.csv_helper.save_one_epoch(epoch_num, log_dict=self.scalarDict,csv_name=csv_name)</span><br><span class="line">    <span class="comment">#  self.save_to_csv为True，则调用 self._write_to_csv()把实验数据添加到csv中</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">write_one_epoch</span>(<span class="params">self, epoch_num, validation=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="keyword">if</span> self.use_tb_log:</span><br><span class="line">            self._write_to_tensorboard(epoch_num,validation)</span><br><span class="line">        <span class="keyword">if</span> self.save_to_csv:</span><br><span class="line">            self._write_to_csv(epoch_num,validation)</span><br><span class="line">        <span class="keyword">if</span> self.save_to_png:</span><br><span class="line">            self._write_to_png(epoch_num)</span><br></pre></td></tr></table></figure>

<p><strong>使用MetricRecorder类得到数据，并保存数据：</strong></p>
<p>初始化MetricRecorder类</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># save_to_csv=True,  # 是否保存到.csv确认把实验数据保存到csv文件中</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Trainer</span>():</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,option:argparse.Namespace</span>):</span><br><span class="line">        <span class="comment"># 初始化数据记录器</span></span><br><span class="line">        self.metric_recorder = MetricRecorder(self.option.output_path,</span><br><span class="line">                                              use_tb_log=<span class="literal">False</span>,  <span class="comment"># 是否使用tb日志</span></span><br><span class="line">                                              save_to_csv=<span class="literal">True</span>,  <span class="comment"># 是否保存到.csv</span></span><br><span class="line">                                              save_to_png=<span class="literal">True</span>,  <span class="comment"># 是否保存到.png</span></span><br><span class="line">                                              csv_name=<span class="literal">None</span>,</span><br><span class="line">                                                         write_header=self.option.is_pretrain_model</span><br><span class="line">                                              )  <span class="comment"># 实验描述</span></span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>得到数据字典logDict，用self.metric_recorder.add_current_scalar函数获取到数据字典logDict，使MetricRecorder类里的函数_write_to_csv能使用logDict数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">logDict = &#123;<span class="string">&#x27;loss&#x27;</span>: losses[<span class="string">&#x27;loss&#x27;</span>].item(), <span class="string">&quot;loss_chaL1&quot;</span>: losses[<span class="string">&#x27;loss_chaL1&#x27;</span>].item(),</span><br><span class="line">                       <span class="string">&quot;loss_wssim&quot;</span>: losses[<span class="string">&#x27;loss_wssim&#x27;</span>].item(),<span class="string">&quot;loss_pre&quot;</span>: losses[<span class="string">&#x27;loss_pre&#x27;</span>].item(),</span><br><span class="line">                       <span class="string">&quot;PSNR&quot;</span>: curr_psnr, <span class="string">&quot;SSIM&quot;</span>: curr_ssim&#125;</span><br><span class="line">self.metric_recorder.add_current_scalar(logDict)</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p>调用metric_recorder.write_one_epoch，保存每个回合的数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"># 保存该回合的数据</span><br><span class="line">        self.metric_recorder.write_one_epoch(epoch, validation=False)</span><br></pre></td></tr></table></figure>

<h2 id="3、如何保存预测图片"><a href="#3、如何保存预测图片" class="headerlink" title="3、如何保存预测图片"></a>3、如何保存预测图片</h2><p>调用metric_recorder.add_current_imgs获取图片名称和图片的字典，使metric_recorder里的_write_to_png函数能使用图片，并保存</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 输出图片</span><br><span class="line">if i == epoch_size-1:# 当i是最后一个批次时保存图片</span><br><span class="line">   # 添加本回合的生成的图片</span><br><span class="line">   imgDict = &#123;&#x27;ori_image&#x27;: ori_image, &#x27;guide_image&#x27;: guide_image, &#x27;pre_image&#x27;: pre_image,&#x27;truth_img&#x27;: truth_img&#125;</span><br><span class="line">   self.metric_recorder.add_current_imgs(imgDict)  # 记录图片</span><br></pre></td></tr></table></figure>

<p>调用metric_recorder.write_one_epoch，保存每个回合的数据：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"># 保存该回合的数据</span><br><span class="line">        self.metric_recorder.write_one_epoch(epoch, validation=False)</span><br></pre></td></tr></table></figure>

<h2 id="4、如何使用进度条功能"><a href="#4、如何使用进度条功能" class="headerlink" title="4、如何使用进度条功能"></a>4、如何使用进度条功能</h2>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-15-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E8%AE%AD%E7%BB%83%E6%95%B0%E6%8D%AE%E9%9B%86%E8%AF%BB%E5%8F%96/" class="post-title-link" itemprop="url">「项目复现」S3net的训练数据集读取</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-15 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-15T00:00:00+00:00">2021-11-15</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		本博客是作者复现《S3Net: A Single Stream Structure for Depth Guided Image Relighting》的训练数据集读取代码的笔记。</p>
<h2 id="一、函数test-trainSet"><a href="#一、函数test-trainSet" class="headerlink" title="一、函数test_trainSet()"></a>一、函数test_trainSet()</h2><p><strong>函数功能：</strong>测试类trainDataSetFromTrack2的功能。</p>
<p>1、给出输入原始图像的路径和引导图像路径</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">origin_img_path = <span class="string">&#x27;../datasets/alltrain/*.png&#x27;</span><span class="comment"># 输入的原始图像的路径</span></span><br><span class="line">guide_img_path = origin_img_path <span class="comment"># 引导图像路径</span></span><br></pre></td></tr></table></figure>

<p>2、根据图片路径和想获取的图片数量获取数据集。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">dataset = trainDataSetFromTrack2(origin_img_path, guide_img_path,<span class="number">10</span>)</span><br></pre></td></tr></table></figure>

<p>3、用DataLoader获取可以输入神经网络中的数据集</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">trainloader = DataLoader(dataset, batch_size=<span class="number">1</span>, shuffle=<span class="literal">True</span>, num_workers=<span class="number">0</span>)</span><br></pre></td></tr></table></figure>

<p>4、得到一组样本图片，iter函数将可序列化的对象序列化，next按顺序取序列化后对象的数据。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">batchdict = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainloader))</span><br></pre></td></tr></table></figure>

<p>5、获取原始图像及其深度图、引导图像及其深度图。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_image, guide_image, ori_depth, guide_depth = batchdict[&#x27;x&#x27;]</span><br></pre></td></tr></table></figure>

<p>6、将图片保存到对象路径中</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">save_img(ori_image,&#x27;./1.png&#x27;)</span><br></pre></td></tr></table></figure>

<p><strong>函数代码：</strong></p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function">def <span class="title">test_trainSet</span><span class="params">()</span>:</span></span><br><span class="line"><span class="function">    # 创建数据集</span></span><br><span class="line"><span class="function">    origin_img_path =</span> <span class="string">&#x27;../datasets/alltrain/*.png&#x27;</span># 输入的原始图像的路径</span><br><span class="line">    guide_img_path = origin_img_path # 引导图像路径</span><br><span class="line">    dataset = <span class="built_in">trainDataSetFromTrack2</span>(origin_img_path, guide_img_path,<span class="number">10</span>)# 根据图片路径读取数据集</span><br><span class="line">    trainloader = <span class="built_in">DataLoader</span>(dataset, batch_size=<span class="number">1</span>, shuffle=True, num_workers=<span class="number">0</span>)</span><br><span class="line">    # 输出信息</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&quot;训练集一共有&#123;&#125;/&#123;&#125;=&#123;&#125;个的批次,其中&#123;&#125;是mini-batch&quot;</span>.format(<span class="built_in">len</span>(dataset), <span class="number">1</span>, <span class="built_in">len</span>(trainloader), <span class="number">1</span>))</span><br><span class="line">    batchdict = <span class="built_in">next</span>(<span class="built_in">iter</span>(trainloader))# 得到一组样本数据</span><br><span class="line">    ori_image, guide_image, ori_depth, guide_depth = batchdict[<span class="string">&#x27;x&#x27;</span>]</span><br><span class="line">    img_name = batchdict[<span class="string">&#x27;img_name&#x27;</span>]</span><br><span class="line">    <span class="built_in">print</span>(ori_image.shape)</span><br><span class="line">    <span class="built_in">print</span>(guide_image.shape)</span><br><span class="line">    <span class="built_in">print</span>(ori_depth.shape)</span><br><span class="line">    <span class="built_in">print</span>(guide_depth.shape)</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">&#x27;img_name&#x27;</span>, img_name)</span><br><span class="line">    <span class="built_in">save_img</span>(ori_image,<span class="string">&#x27;./1.png&#x27;</span>)</span><br></pre></td></tr></table></figure>

<h2 id="二、类trainDataSetFromTrack2"><a href="#二、类trainDataSetFromTrack2" class="headerlink" title="二、类trainDataSetFromTrack2"></a>二、类trainDataSetFromTrack2</h2><p><strong>类trainDataSetFromTrack2的功能：</strong>实现加载数据集所需的各个函数。</p>
<h3 id="1、类头"><a href="#1、类头" class="headerlink" title="1、类头"></a>1、类头</h3><p>该类继承自类Dataset，需要重载函数__init__()、<strong>getitem</strong>(self, index)、<strong>len</strong>(self)（这三个函数开头结尾都有两个下划线，typora文档里没显示出来）。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">class trainDataSetFromTrack2(Dataset):</span><br></pre></td></tr></table></figure>

<h3 id="2、成员函数-init-（）"><a href="#2、成员函数-init-（）" class="headerlink" title="2、成员函数__init__（）"></a>2、成员函数__init__（）</h3><p><strong>函数代码</strong>：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self,</span></span><br><span class="line"><span class="params">                 origin_img_path: <span class="built_in">str</span>,  <span class="comment"># 输入文件所在的路径</span></span></span><br><span class="line"><span class="params">                 guide_img_path: <span class="built_in">str</span>,  <span class="comment"># 输出文件所在的路径</span></span></span><br><span class="line"><span class="params">                 num:<span class="built_in">int</span>,<span class="comment"># 读取的图片数量</span></span></span><br><span class="line"><span class="params">                 </span>):</span><br><span class="line">    <span class="built_in">super</span>(trainDataSetFromTrack2, self).__init__()</span><br><span class="line">    <span class="comment"># 获取所有图片的路径</span></span><br><span class="line">    self.origin_img_paths, self.guide_img_paths = self._get_dataset_path(origin_img_path, guide_img_path)</span><br><span class="line">    self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.origin_img_paths)</span><br><span class="line">    <span class="comment"># 选取指定数量的图片</span></span><br><span class="line">    <span class="keyword">if</span> num &gt; <span class="number">0</span> <span class="keyword">and</span> num &lt; self.<span class="built_in">len</span>:</span><br><span class="line">        self.origin_img_paths = self.origin_img_paths[:num]</span><br><span class="line">        self.guide_img_paths =self.guide_img_paths[:num]</span><br><span class="line">        self.<span class="built_in">len</span> = num</span><br><span class="line">    <span class="comment"># 获取图像预处理函数</span></span><br><span class="line">    self.preprocess_fn = data_transform</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">f&#x27;含有<span class="subst">&#123;self.<span class="built_in">len</span>&#125;</span> 个样本的数据集已被创建&#x27;</span>)</span><br></pre></td></tr></table></figure>

<p><strong>函数功能</strong>：</p>
<p>1、获取所有输入的原始图像和引导图像的路径</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.origin_img_paths, self.guide_img_paths = self._get_dataset_path(origin_img_path, guide_img_path)</span><br></pre></td></tr></table></figure>

<p>2、获取读取整个数据集的大小</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.<span class="built_in">len</span> = <span class="built_in">len</span>(self.origin_img_paths)</span><br></pre></td></tr></table></figure>

<p>3、获取指定数量的图片</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> num &gt; <span class="number">0</span> <span class="keyword">and</span> num &lt; self.<span class="built_in">len</span>:</span><br><span class="line">    self.origin_img_paths = self.origin_img_paths[:num]</span><br><span class="line">    self.guide_img_paths =self.guide_img_paths[:num]</span><br><span class="line">    self.<span class="built_in">len</span> = num</span><br></pre></td></tr></table></figure>

<p>4、获取图像预处理函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">self.preprocess_fn = data_transform</span><br></pre></td></tr></table></figure>

<h3 id="3、成员函数-getitem-（）"><a href="#3、成员函数-getitem-（）" class="headerlink" title="3、成员函数__getitem__（）"></a>3、成员函数<code>__getitem__（）</code></h3><p><strong>函数代码</strong>：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"># 获取一组图片数据</span><br><span class="line">    def __getitem__(self, index):</span><br><span class="line">        # 获取一组样本的路径</span><br><span class="line">        origin_img_path, guide_img_path = self.origin_img_paths[index % self.len], self.guide_img_paths[index % self.len]</span><br><span class="line">        origin_depth_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27;  # 拼接出原始图像对应深度图的路径：Image000+.npy</span><br><span class="line">        guide_depth_name = guide_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27; # 拼接出指导图像对应深度图的路径: Image001+.npy</span><br><span class="line">        truth_img_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[1]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[2]# 拼接出真实图像的路径：原始图像的前缀Image000+指导图像的后缀</span><br><span class="line">        # 读取该组样本的RGB图片</span><br><span class="line">        ori_image, guide_image,truth_img = map(self._read_rgb_img, (origin_img_path, guide_img_path,truth_img_name))</span><br><span class="line"></span><br><span class="line">        # 读取该组样本的depth图片</span><br><span class="line">        ori_depth, guide_depth = map(self._read_depth_img, (origin_depth_name, guide_depth_name))</span><br><span class="line">        # 获取该组样本对应的名称</span><br><span class="line">        img_name = origin_img_path.split(&#x27;\\&#x27;)[1]</span><br><span class="line">        return &#123;&#x27;x&#x27;:(ori_image, guide_image, ori_depth, guide_depth),</span><br><span class="line">                &#x27;y&#x27;:truth_img,</span><br><span class="line">                &#x27;img_name&#x27;:img_name&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<p><strong>函数功能</strong>：根据序号index，获取一组样本图片。</p>
<p>1、获取原始图像及其深度图、引导图像及其深度图、真实图像的路径</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 根据序号index，获取原始图像、引导图像的路径</span><br><span class="line">origin_img_path, guide_img_path = self.origin_img_paths[index % self.len], self.guide_img_paths[index % self.len]</span><br><span class="line"># 拼接出原始图像对应深度图的路径：Image000+.npy</span><br><span class="line">origin_depth_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27; </span><br><span class="line"># 拼接出指导图像对应深度图的路径: Image001+.npy</span><br><span class="line">guide_depth_name = guide_img_path.split(&#x27;_&#x27;)[0]+&#x27;.npy&#x27;</span><br><span class="line"># 拼接出真实图像的路径：原始图像的前缀Image000+指导图像的后缀</span><br><span class="line">truth_img_name = origin_img_path.split(&#x27;_&#x27;)[0]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[1]+&#x27;_&#x27;+guide_img_path.split(&#x27;_&#x27;)[2]</span><br></pre></td></tr></table></figure>

<p>2、# 读取该组样本的RGB图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_image, guide_image,truth_img = map(self._read_rgb_img, (origin_img_path, guide_img_path,truth_img_name))</span><br></pre></td></tr></table></figure>

<p>map（）相当于调用了函数self._read_rgb_img三次，以上代码还可以写为</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">ori_image = self._read_rgb_img(origin_img_path)</span><br><span class="line">guide_image = self._read_rgb_img(guide_img_path)</span><br><span class="line">truth_img = self._read_rgb_img(truth_img_name)</span><br></pre></td></tr></table></figure>

<p>3、读取该组样本的depth图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ori_depth, guide_depth = map(self._read_depth_img, (origin_depth_name, guide_depth_name))</span><br></pre></td></tr></table></figure>

<p>4、返回读取的这组样本图片</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">return &#123;&#x27;x&#x27;:(ori_image, guide_image, ori_depth, guide_depth),</span><br><span class="line">        &#x27;y&#x27;:truth_img,</span><br><span class="line">        &#x27;img_name&#x27;:img_name&#125;</span><br></pre></td></tr></table></figure>

<h3 id="4、成员函数-len-（）"><a href="#4、成员函数-len-（）" class="headerlink" title="4、成员函数 __len__（）"></a>4、成员函数 <code>__len__（）</code></h3><p><strong>函数功能：</strong>返回读取图片的数量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">__len__</span>(<span class="params">self</span>):</span><br><span class="line">    <span class="keyword">return</span> self.<span class="built_in">len</span></span><br></pre></td></tr></table></figure>

<h3 id="5、成员函数-read-rgb-img（）"><a href="#5、成员函数-read-rgb-img（）" class="headerlink" title="5、成员函数_read_rgb_img（）"></a>5、成员函数<code>_read_rgb_img（）</code></h3><p>类中的成员函数加上一个下划线_，这样类外就不能访问该函数。</p>
<p><strong>函数功能：</strong>根据给定的图片路径，获取图片张量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">_read_rgb_img</span>(<span class="params">self,img_path</span>):</span><br><span class="line">    img = Image.<span class="built_in">open</span>(<span class="built_in">str</span>(img_path))  <span class="comment"># （1024,1024,4）</span></span><br><span class="line">    image_tensor = self.preprocess_fn(img)  <span class="comment"># tensor，size=（4,1024,1024）</span></span><br><span class="line">    image_tensor = image_tensor[:<span class="number">3</span>, :, :]  <span class="comment"># tensor，size=（3,1024,1024）</span></span><br><span class="line">    <span class="keyword">return</span> image_tensor</span><br></pre></td></tr></table></figure>

<h3 id="6、成员函数-read-depth-img（）"><a href="#6、成员函数-read-depth-img（）" class="headerlink" title="6、成员函数_read_depth_img（）"></a>6、成员函数<code>_read_depth_img（）</code></h3><p><strong>函数功能：</strong>根据给定的图片路径，获取深度图片张量。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def _read_depth_img(self,depth_path):</span><br><span class="line">    depth = np.load(depth_path, allow_pickle=True).item()[&#x27;normalized_depth&#x27;]</span><br><span class="line">    ori_depth = torch.unsqueeze(torch.from_numpy(depth), 0)  # 升维(1,1024,1024)</span><br><span class="line">    #ori_depth = torch.unsqueeze(ori_depth, 0)  # 升维(1,1,1024,1024)</span><br><span class="line">    return ori_depth</span><br><span class="line"></span><br></pre></td></tr></table></figure>

<h3 id="7、成员函数-get-dataset-path（）"><a href="#7、成员函数-get-dataset-path（）" class="headerlink" title="7、成员函数_get_dataset_path（）"></a>7、成员函数<code>_get_dataset_path（）</code></h3><p><strong>函数功能：</strong>根据给定的图片文件夹的路径，获取图片文件夹中所有图片的路径。</p>
<p>glob.glob函数：搜索所有满足条件的项。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">def _get_dataset_path(self, input_file_path, target_file_path):</span><br><span class="line">    origin_img_paths = sorted(glob.glob(input_file_path, recursive=True))</span><br><span class="line">    guide_img_paths = glob.glob(target_file_path, recursive=True)</span><br><span class="line">    random.shuffle(guide_img_paths)</span><br><span class="line">    #assert len(origin_img_paths) == len(guide_img_paths)</span><br><span class="line">    return origin_img_paths, guide_img_paths</span><br></pre></td></tr></table></figure>

<h3 id="三、数据增强手段"><a href="#三、数据增强手段" class="headerlink" title="三、数据增强手段"></a>三、数据增强手段</h3><p>代码</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">data_transform = transforms.Compose([</span><br><span class="line">    transforms.ToTensor(),</span><br><span class="line">])</span><br></pre></td></tr></table></figure>

<h3 id="四、函数save-img"><a href="#四、函数save-img" class="headerlink" title="四、函数save_img()"></a>四、函数save_img()</h3><p><strong>函数功能：</strong>把图片张量tensor_img保存到输出文件夹output_dir中。</p>
<p><strong>函数代码：</strong></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">save_img</span>(<span class="params">tensor_img,output_dir</span>):</span><br><span class="line">    <span class="comment"># 保存图像</span></span><br><span class="line">    torchvision.utils.save_image(tensor_img, output_dir)</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-05-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-05-%E3%80%90%E9%A1%B9%E7%9B%AE%E5%A4%8D%E7%8E%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0%E5%AE%9E%E7%8E%B0/" class="post-title-link" itemprop="url">「项目复现」S3net的损失函数实现</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-05 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-05T00:00:00+00:00">2021-11-05</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>《S3Net: A Single Stream Structure for Depth Guided Image Relighting》是来自中国台湾的Hao-Hsiang Yang等人发表在CVPR 2021（CCF推荐的A类会议）上的一篇WorkShip论文，本文是其项目训练代码的关键复现流程。</p>
<p>​		本博客是复现《S3Net: A Single Stream Structure for Depth Guided Image Relighting》的损失函数实现。该项目的S3Net一共使用了三个损失函数，其整体损失如下：<br>$$<br>L_{\text {Total }}&#x3D;\lambda_{1} L_{\text {cha }}+\lambda_{2} L_{W-S S I M}+\lambda_{3} L_{P e r}<br>$$<br>​		其中 $\lambda_{1}$、$\lambda_{2}$ 和 $\lambda_{3}$ 是缩放系数，用于调整三个分量的相对权重。</p>
<h1 id="一、Charbonnier-损失"><a href="#一、Charbonnier-损失" class="headerlink" title="一、Charbonnier 损失"></a>一、Charbonnier 损失</h1><p>​		该损失函数来自于《A general and adaptive robust loss function》，其可以看做是一个高鲁棒性的L1损失函数，该损失函数可以还原全局结构并且可以更鲁棒地处理异常值，其公式如下：<br>$$<br>L_{C h a}(I, \hat{I})&#x3D;\frac{1}{T} \sum_{i}^{T} \sqrt{\left(I_{i}-\hat{I}_{i}\right)^{2}+\epsilon^{2}}<br>$$<br>​       其中$I$ 和$\hat{I}$ 分别代表目标图像和该文网络输出的预测图像， $\epsilon$被视为一个微小的常数（例如$10^{-6}$​）,用来实现稳定和鲁棒的收敛。根据这篇超分辨领域的论文《Fast and Accurate Image Super-Resolution with Deep Laplacian Pyramid Networks》，采用该函数可以使得模型的收敛速度加快。其实现代码相对简单“</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">L1_Charbonnier_loss</span>(torch.nn.Module):</span><br><span class="line">    <span class="string">&quot;&quot;&quot;L1 Charbonnierloss.&quot;&quot;&quot;</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self</span>):</span><br><span class="line">        <span class="built_in">super</span>(L1_Charbonnier_loss, self).__init__()</span><br><span class="line">        self.eps = <span class="number">1e-6</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X, Y</span>):</span><br><span class="line">        diff = torch.add(X, -Y)</span><br><span class="line">        error = torch.sqrt(diff * diff + self.eps)</span><br><span class="line">        loss = torch.mean(error)</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>

<h1 id="二、SSIM-损失"><a href="#二、SSIM-损失" class="headerlink" title="二、SSIM 损失"></a>二、SSIM 损失</h1><p>​		该损失函数来自于《Loss functions for image restoration with neural networks》 ，其能够重建局部纹理和细节。 可以表示为：<br>$$<br>L_{S S I M}(I, \hat{I})&#x3D;-\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(2 \sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}\right)}<br>$$<br>​		 其中 σ 和 µ 表示图像的标准偏差、协方差和均值。 </p>
<p>​		在图像重照明任务中，为了从原始图像中去除阴影，该文扩展了 SSIM 损失函数，以便使网络可以恢复更详细的部分。 </p>
<p>​		该文使用《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》 中的方法将 DWT 组合到 SSIM 损失中，这有利于重建重光照图像的清晰细节。最初，DWT 将预测图像分解为四个不同的小sub-band图像。 操作可以表示为：<br>$$<br>\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}&#x3D;\operatorname{DWT}(\hat{I})<br>$$</p>
<p>​       其中上标表示来自各个过滤器的输出（例如，$$\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}$$）。</p>
<p>​       $$\hat{I}^{H L}, \hat{I}^{L H}, \hat{I}^{H H}$$分别是水平边缘、垂直边缘和角点检测的高通滤波器。  fLL 被视为下采样操作。 此外，DWT 可以不断分解$$\hat{I}^{L L}$$ 以生成具有不同尺度和频率信息的图像。 这一步写成：<br>$$<br>\hat{I}<em>{i+1}^{L L}, \hat{I}</em>{i+1}^{L H}, \hat{I}<em>{i+1}^{H L}, \hat{I}</em>{i+1}^{H H}&#x3D;\operatorname{DWT}\left(\hat{I}<em>{i}^{L L}\right)<br>$$<br>​       其中下标 i 表示第 i 次 DWT 迭代的输出。 上述 SSIM 损失项是根据原始图像对和各种子带图像对计算得出的。  SSIM损失和DWT的融合整合为：<br>$$<br>\begin{array}{l}<br>L</em>{W-S S I M}(I, \hat{I})&#x3D;\sum_{0}^{r} \gamma_{i} L_{\mathrm{SSIM}}\left(I_{i}^{w}, \hat{I}<em>{i}^{w}\right) \<br>w \in{L L, H L, L H, H H}<br>\end{array}<br>$$<br>其中$\gamma</em>{i}$​  基于原文来控制不同补丁的重要性。</p>
<p>​		这里的实现我们参考了<a target="_blank" rel="noopener" href="https://github.com/dectrfov/Y-net/tree/master/pytorch_ssim">wavelet_ssim</a>的实现。</p>
<h1 id="三、感知损失"><a href="#三、感知损失" class="headerlink" title="三、感知损失"></a>三、感知损失</h1><p>​		该损失函数来自于2016年代ECCV会议的《Perceptual losses for real-time style transfer and super-resolution》，该论文在图像转换问题中使用感知损失（perceptual loss）函数代替之前的逐像素（per-pixel）损失函数，结果在速度和图片质量上均得到了大幅度提升。</p>
<p>​		感知损失定义为<br>$$<br>L_{P e r}(I, \hat{I})&#x3D;\mid(\operatorname{VGG}(I)-\operatorname{VGG}(\hat{I}) \mid<br>$$</p>
<p>​		其中$\mid·\mid$ 是绝对值。</p>
<p>​		该损失函数利用从预训练的深度神经网络（例如 VGG19 （《Very deep convolutional networks for large-scale image recognition》））中获得的多尺度特征，然后使用L1损失来测量预测图像和目标图像之间的视觉特征差异，从而使得训练的图像尽可能地逼近目标图像。该项目使用在ImageNet 上预训练的 VGG19 被用作损失函数网络。</p>
<p>​		首先使用代码获取vgg19模型：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models <span class="keyword">as</span> models</span><br><span class="line"><span class="comment"># 加载预训练的模型</span></span><br><span class="line">vgg_model = models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line"><span class="built_in">print</span>(vgg_model.features)</span><br></pre></td></tr></table></figure>

<p>​		vgg19整体结构分为’features’, ‘avgpool’, 和 ‘classifier’三大部分,而计算损失函数只需要用到’features’部分，打印其结果如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><span class="line">Sequential(</span><br><span class="line">  (<span class="number">0</span>): Conv2d(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">1</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">2</span>): Conv2d(<span class="number">64</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">3</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">4</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">5</span>): Conv2d(<span class="number">64</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">6</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">7</span>): Conv2d(<span class="number">128</span>, <span class="number">128</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">8</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">9</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">10</span>): Conv2d(<span class="number">128</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">11</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">12</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">13</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">14</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">15</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">16</span>): Conv2d(<span class="number">256</span>, <span class="number">256</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">17</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">18</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">19</span>): Conv2d(<span class="number">256</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">20</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">21</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">22</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">23</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">24</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">25</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">26</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">27</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">  (<span class="number">28</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">29</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">30</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">31</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">32</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">33</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">34</span>): Conv2d(<span class="number">512</span>, <span class="number">512</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br><span class="line">  (<span class="number">35</span>): ReLU(inplace)</span><br><span class="line">  (<span class="number">36</span>): MaxPool2d(kernel_size=<span class="number">2</span>, stride=<span class="number">2</span>, padding=<span class="number">0</span>, dilation=<span class="number">1</span>, ceil_mode=<span class="literal">False</span>)</span><br><span class="line">)</span><br></pre></td></tr></table></figure>

<p>这里我们使用[DRN项目中的vggloss](<a target="_blank" rel="noopener" href="https://github.com/WangLiwen1994/DeepRelight/blob/master/models/networks.py">DeepRelight&#x2F;networks.py at master · WangLiwen1994&#x2F;DeepRelight (github.com)</a>)的实现来获取多尺度特征，如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Vgg19</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, requires_grad=<span class="literal">False</span></span>):</span><br><span class="line">        <span class="built_in">super</span>(Vgg19, self).__init__()</span><br><span class="line">        <span class="comment"># vgg_pretrained_features = models.vgg19(pretrained=True).features # #pretrained是true，导入预训练模型</span></span><br><span class="line">        <span class="comment"># 加载预训练模型</span></span><br><span class="line">        vgg19_model = models.vgg19(pretrained=<span class="literal">True</span>)</span><br><span class="line">        <span class="comment"># 获取中间层特征</span></span><br><span class="line">        vgg_pretrained_features = vgg19_model.features</span><br><span class="line"></span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line">        self.slice5 = torch.nn.Sequential()</span><br><span class="line">        <span class="comment"># 获取中间层特征，把不同层的特征分别加入不同的模块</span></span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>):</span><br><span class="line">            self.slice1.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">2</span>, <span class="number">7</span>):</span><br><span class="line">            self.slice2.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">7</span>, <span class="number">12</span>):</span><br><span class="line">            self.slice3.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">12</span>, <span class="number">21</span>):</span><br><span class="line">            self.slice4.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="keyword">for</span> x <span class="keyword">in</span> <span class="built_in">range</span>(<span class="number">21</span>, <span class="number">28</span>):</span><br><span class="line">            self.slice5.add_module(<span class="built_in">str</span>(x), vgg_pretrained_features[x])</span><br><span class="line">        <span class="comment"># 设置所有参数都不需要计算梯度，使得之后不进行反向传播及权重更新</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> requires_grad:</span><br><span class="line">            <span class="keyword">for</span> param <span class="keyword">in</span> self.parameters():</span><br><span class="line">                param.requires_grad = <span class="literal">False</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, X</span>):</span><br><span class="line"></span><br><span class="line">        h_relu1 = self.slice1(X)</span><br><span class="line">        h_relu2 = self.slice2(h_relu1)</span><br><span class="line">        h_relu3 = self.slice3(h_relu2)</span><br><span class="line">        <span class="comment">#h_relu4 = self.slice4(h_relu3)</span></span><br><span class="line">        <span class="comment">#h_relu5 = self.slice5(h_relu4)</span></span><br><span class="line">        <span class="comment">#out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]</span></span><br><span class="line">        out = [h_relu1, h_relu2, h_relu3]<span class="comment">#, h_relu4, h_relu5]</span></span><br><span class="line">        <span class="keyword">return</span> out</span><br><span class="line"><span class="keyword">class</span> <span class="title class_">VGGLoss</span>(nn.Module):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">__init__</span>(<span class="params">self, gpu_ids</span>):</span><br><span class="line">        <span class="built_in">super</span>(VGGLoss, self).__init__()</span><br><span class="line">        self.vgg = Vgg19().cuda()</span><br><span class="line">        self.criterion = nn.L1Loss() <span class="comment"># L1损失，平均绝对值损失</span></span><br><span class="line">        self.weights = [<span class="number">1.0</span> / <span class="number">32</span>, <span class="number">1.0</span> / <span class="number">16</span>, <span class="number">1.0</span> / <span class="number">8</span>, <span class="number">1.0</span> / <span class="number">4</span>, <span class="number">1.0</span>]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">forward</span>(<span class="params">self, x, y</span>):</span><br><span class="line">        x_vgg, y_vgg = self.vgg(x), self.vgg(y)</span><br><span class="line">        loss = <span class="number">0.0</span></span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> <span class="built_in">range</span>(<span class="built_in">len</span>(x_vgg)):</span><br><span class="line">            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())</span><br><span class="line">        <span class="keyword">return</span> loss</span><br></pre></td></tr></table></figure>




      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91DRN%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%85%89%E6%BA%90%E6%93%8D%E7%BA%B5%E7%9A%84%E6%B7%B1%E5%BA%A6%E9%87%8D%E5%85%89%E7%85%A7%E7%BD%91%E7%BB%9C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91DRN%EF%BC%9A%E7%94%A8%E4%BA%8E%E5%9B%BE%E5%83%8F%E5%85%89%E6%BA%90%E6%93%8D%E7%BA%B5%E7%9A%84%E6%B7%B1%E5%BA%A6%E9%87%8D%E5%85%89%E7%85%A7%E7%BD%91%E7%BB%9C/" class="post-title-link" itemprop="url">「论文分享」DRN:用于图像光源操纵的深度重光照网络</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-04 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-04T00:00:00+00:00">2021-11-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		《Deep Relighting Networks for Image Light Source Manipulation》是发表在ECCV 2020上的一篇论文。这里是<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2008.08298"><strong>原文链接</strong></a>和<a target="_blank" rel="noopener" href="https://github.com/WangLiwen1994/DeepRelight"><strong>原文代码</strong></a></p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​       操纵给定图像的光源的现有的方法通常需要额外的信息，如场景的几何结构，这可能不适用于大多数图像<strong>。在本文中，我们用公式表示单图像重照明任务，并提出了一种新的深度重照明网络（DRN）</strong>，该网络由三部分组成：</p>
<p>1）场景重建，其目的是通过深度自动编码网络显示主要场景结构，</p>
<p>2）阴影先验估计，通过对抗性学习，从新的灯光方向预先确定灯光效果，</p>
<p>3）重新渲染，将主要结构与重建的阴影视图结合起来，形成目标光源下所需的估计图像。</p>
<p>​         实验结果表明，该方法在定性和定量上都优于其他方法。具体而言，提出的DRN在2020年ECCV大会的“AIM2020-任何对一重新照明挑战”中实现了最佳峰值信噪比。</p>
<h1 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h1><p>​         图像是这个信息时代流行的信息载体，直观易懂。 显示设备的快速发展刺激了人们对高质量画面的需求。 图像的视觉外观与照明高度相关，这在摄影和电影摄影等各种应用中至关重要。 不适当的照明通常会导致各种视觉退化问题，例如不想要的阴影和扭曲的颜色。 然而，光源（如太阳光）难以控制，或者有时无法改变（对于捕获的图像），因此很难生成令人满意的图像。 在拍摄的图像上产生想要的光源效果的方法已经是非常引人关注的高科技方法，因为它可以修改拍摄图像的光照。</p>
<p>​       已经提出了一些方法，旨在减轻由不适当照明引起的退化。</p>
<table>
<thead>
<tr>
<th>方法</th>
<th>论文</th>
<th>主要内容</th>
</tr>
</thead>
<tbody><tr>
<td>直方图均衡化 histogram equalization (HE)</td>
<td>[37]《Contrast limited adaptive histogram equalization based enhancement for real time video system》</td>
<td>重新排列强度以服从均匀分布，这可以增加对低对比度区域的识别。 它操纵全局光条件，平衡了整个图像的照明。</td>
</tr>
<tr>
<td>高动态范围 (HDR) 领域中的方法</td>
<td>[3] 《Recovering high dynamic range radiance  maps from photographs》、[36]《Deep high dynamic range imaging 》</td>
<td>通过增加低对比度区域的动态范围来提高图像质量。HDR 方法可以看作是局部对比度的细化，但缺乏对全局光的调整。</td>
</tr>
<tr>
<td>基于 Retinex 的方法</td>
<td>[29]《Retinex processing for auto-matic image enhancement》、[35]《Deep retinex decomposition for low -light enhancement》</td>
<td>将图像分离为光照和反射率的组合，其中反射存储场景的固有内容，在不同的照明条件下无法改变。 通过细化光照，可以提高图像的视觉质量。</td>
</tr>
<tr>
<td>低光图像增强方法</td>
<td>[15]《 Enlightengan: Deep light enhancement without paired supervision》【32】《Lightening network for low-light image enhancement》</td>
<td>改善黑暗环境的可见度，以照亮整个画面。</td>
</tr>
<tr>
<td>阴影去除</td>
<td>【13】《Direction-aware spatial context features for shadow detection》、【18】《Shadow removal via shadow image decomposition》</td>
<td>旨在消除光源造成的阴影效果，但不能模拟目标光源的阴影。</td>
</tr>
<tr>
<td></td>
<td></td>
<td></td>
</tr>
</tbody></table>
<p>​        调整光源为基于照明的图像增强提供了一种灵活而自然的方式。 尽管已经进行了大量的研究来改进照明，但从操纵光源的角度进行研究的效果较小。 也就是说，通过控制光源来改变光照效果还处于设想阶段。 重新照明领域的文献主要关注特定应用，</p>
<p>例如</p>
<table>
<thead>
<tr>
<th>人像重新照明</th>
<th>人像重新照明相关论文</th>
</tr>
</thead>
<tbody><tr>
<td>人像重新照明：这些方法需要在一般场景中无法实现的先验信息（如面部标志、几何先验）。</td>
<td>【26】《Learning physics-guided face relighting under directional light》【31】《Single image portrait relighting》【40】《Deep single-image portrait relighting》</td>
</tr>
</tbody></table>
<p>​        卷积神经网络（CNN）最近因其强大的学习能力而备受关注。 它可以在强大的计算资源的支持下消化大量的训练数据并 提取有识别力的表征 。CNN 在各种任务中显示出显着的优势，例如</p>
<p>图像分类 [17,30]、语义分割 [27,38]、超分辨率 [8,23]、位置识别 [1,19] 等。 由于浅层的参数往往面临梯度消失和爆炸的风险，因此难以训练。残差学习 《 Deep residual learning for image recognition》 通过在每个处理块之间添加shortcut连接来减轻优化难度。 在归一化层的帮助下，梯度可以稳定地从深层流向浅层，极大地提高了深度网络的训练效率。 更深的结构通常意味着更多可训练的参数，因此可以带来更强大的学习能力，这使得可以处理更具挑战性的任务，例如单幅图像重新照明。</p>
<p>​        本文中的图像重光照方法侧重于使用强大的深度 CNN 架构来操纵光源的位置和色温。 它不仅可以调整主色调，还可以重新投射给定图像的阴影。 如图 1 所示，我们专注于特定的“any-to-one”重新照明任务，其输入:在任意光源（任意方向或色温，见图 1（a））下的凸显，目标是 估计特定光源下的图像（方向：E，色温：4500K，见图1（b））。 所提出的方法可以推广到其他与光相关的任务。 </p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211104233058382.png" alt="image-20211104233058382"></p>
<p>本文方法的创新点：</p>
<p>  1、我们不是将输入图像直接映射到目标光照条件，而是将重新照明任务分为三个部分：场景重建、光照效果估计和重新渲染过程。</p>
<p>   2、 为了保留下采样和上采样过程的更多信息，我们将反投影理论插入到自动编码器结构中，这有利于场景重建和光照效果估计。</p>
<p>   3、 光照效果难以衡量，增加了训练难度。 我们使用对抗性学习策略：新的阴影区域鉴别器，为训练过程提供指导。</p>
<h2 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h2><h2 id="Back-Projection-BP-theory"><a href="#Back-Projection-BP-theory" class="headerlink" title="Back-Projection (BP) theory"></a><strong>Back-Projection (BP) theory</strong></h2><table>
<thead>
<tr>
<th>相关工作</th>
<th>相关论文</th>
</tr>
</thead>
<tbody><tr>
<td>关于低光图像增强的工作 [32]</td>
<td>Lightening network for low-light image enhancement</td>
</tr>
<tr>
<td>BP理论在单图像超分辨率领域很流行[9,20,21]。基于 BP 的方法不是直接学习从输入到目标的映射，而是迭代地消化残差并改进估计。 它更加关注学习过程中出现的弱点（即残差），这显着提高了深度 CNN 架构的效率。</td>
<td>【9】《Deep back-projection networks for super-resolution》、【20】《 Hierarchical back projection network for image super-resolution》、【21】《Image super-resolution via attention based back projection networks》。</td>
</tr>
</tbody></table>
<p>​        关于低光图像增强的工作 [32] 将 BP 理论扩展到光域传输任务。 它假设低光 (LL) 和正常光 (NL) 图像分别位于 LL 和 NL 域。 首先，一个lightening算子从 LL 输入预测 NL 估计。 然后，darkening算子将 NL 估计映射回 LL 域（LL 估计）。 在 LL 域中，可以找到 LL 输入和 LL 估计之间的差异（LL 残差），这表明两个转移算子（变亮和变暗lightening and darkening）的弱点。 之后，LL 残差通过另一个lightening算子映射回 NL 域（NL 残差）。  NL 残差然后细化 NL 估计以获得更好的输出。 从数学上讲，enlightening过程可以写为：</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211104234138291.png" alt="image-20211104234138291"></p>
<p>​         其中 L 和 ˆN ∈ RH×W×3 分别表示 LL 输入图像和 NL 估计。  H、W 和 3分别代表高度、宽度和 RGB 通道。 符号 L1 和 L2 是两个lightening算子，分别照亮 LL 图像和 LL 残差。 符号 D 是将 NL 估计映射到 LL 域的Darkening算子。两个加权系数 λ1 和 λ2 ∈ R 用于平衡残差计算和最终细化。</p>
<h2 id="Adversarial-Learning"><a href="#Adversarial-Learning" class="headerlink" title="Adversarial Learning"></a><strong>Adversarial Learning</strong></h2><p>​        将图像转换为相应的输出图像通常形成为像素级回归任务，其损失函数（如 L1 或 L2 范数损失）表示所有像素的平均误差。 这种损失函数忽略了像素之间的相互关系，容易扭曲感知结构，导致输出模糊。 大量的研究工作已经完成了图像之间感知相似性的定量测量，如结构相似性（SSIM）[34]《Image quality assessment: from error visibility to structural similarity》、学习感知图像块相似性（LPIPS）[39]《The unreasonable effffectiveness of deep features as a perceptual metric》、Gram矩阵[6]《A neural algorithm of artistic style》等。 然而，感知评估基本上因不同的视觉任务而异，难以制定。</p>
<p>​       生成对抗网络 (GAN) [7,14,25] 【7】《Generative adversarial nets》【14】《Image-to-image translation with conditional adversarial networks》【25】《 Conditional generative adversarial nets》提供了一种新颖的解决方案，将感知测量嵌入到对抗学习的过程中。 每个 GAN 由一个生成器和一个鉴别器组成。鉴别器旨在在目标图像中找到潜在的感知结构，然后指导生成器的训练。 随后，生成器提供次优估计，作为鉴别器训练过程的负样本。 对于分组的负和正（目标图像）样本，判别器执行二元分类任务，测量两类样本之间的潜在感知差异。 整个训练过程是</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211105180808841.png" alt="image-20211105180808841"></p>
<p>​       其中 D 和 G 分别表示鉴别器和生成器。 项 X 和 Y 分别代表输入和目标图像。 在训练过程中，生成器和判别器进行两人的极小极大博弈。 鉴别器学习区分估计图像 G(X) 和目标图像 Y。生成器旨在最小化估计 G(X) 和目标图像 Y 之间的差异。训练过程遵循对抗性学习策略， 越来越多地学习和使用目标图像内的潜在分布。 最后，训练将达到动态平衡，其中生成器产生的估计具有与真实目标图像相似的潜在感知结构。</p>
<h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><p>​         如图 2 所示，所提出的深度重新照明网络 (DRN) 由三部分组成：场景重建、阴影先验估计和重新渲染器。 首先，输入图像在场景重建网络（见第 3.2 节）中处理以去除照明的影响，这从输入图像中提取固有结构。 同时，另一个分支（阴影先验估计，见3.3节）侧重于光照效果的变化，根据目标光源重新投射阴影。 接下来，重新渲染器部分（参见第 3.4 节）感知光照效果并在结构信息的支持下重新绘制图像。 场景重建和阴影先验估计网络都具有类似的深度自动编码器结构，这是一种Pix2Pix网络增强的变体。三个组件的细节展示如下：</p>
<h3 id="3-1-Assumption-of-Relighting"><a href="#3-1-Assumption-of-Relighting" class="headerlink" title="3.1 Assumption of Relighting"></a>3.1 Assumption of Relighting</h3>
      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-04-%E3%80%90%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB%E3%80%91s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/" class="post-title-link" itemprop="url">「论文分享」S3net：深度引导图像重照明的单流结构</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-04 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-04T00:00:00+00:00">2021-11-04</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>​		《S3Net: A Single Stream Structure for Depth Guided Image Relighting》是来自中国台湾的Hao-Hsiang Yang等人发表在CVPR 2021（CCF推荐的A类会议）上的一篇WorkShip论文，这里是<a target="_blank" rel="noopener" href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/papers/Yang_S3Net_A_Single_Stream_Structure_for_Depth_Guided_Image_Relighting_CVPRW_2021_paper.pdf">原文链接</a>和<a target="_blank" rel="noopener" href="https://github.com/dectrfov/NTIRE-2021-Depth-Guided-Image-Any-to-Any-relighting">原文代码</a>。</p>
<h1 id="摘要"><a href="#摘要" class="headerlink" title="摘要"></a>摘要</h1><p>​		深度引导（Depth guided）的任意到任意（ any-to-any）图像重光照的目的是通过原始图像和相应的深度图生成重照明的图像，来匹配给定引导图像及其深度图的照明设置。 据该文所称，这项任务是一个在以前的文献中没有提及过的新挑战。 </p>
<p>​		为了解决这个问题，该文提出了一种基于深度学习的单流结构的神经网络，称为S3Net。 该网络是一个编码器-解码器（ encoder-decoder）模型，其输入是 原始图像、引导图像和相应的深度图，共计4张图（2张RGB图+2张深度图）。 该网络的特点是向解码器部分中加入了注意力模块和增强模块，用来关注引导图像中与重照明相关的区域。</p>
<p>​		最终的实验表明，该论文提出的模型在竞赛（the NTIRE 2021 Depth Guided Any-to-any Relighting Challenge）中实现了第三高的SSIM。</p>
<h2 id="一、简介"><a href="#一、简介" class="headerlink" title="一、简介"></a>一、简介</h2><p>​		图像重照明是一项新兴且关键的技术，其在可视化、图像编辑和增强现实 (AR) 中的具有较大应用潜力，例如为第一人称和第三人称游戏渲染具有各种环境照明条件的图像。该文的目的是解决深度引导的any to any的重光照任务，该任务的特点是用引导图像的照明设置来重新照明输入图像。这里给出一组图像说明：</p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\any_to_any图像.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/any_to_any%E5%9B%BE%E5%83%8F.png"></p>
<h3 id="1、any-to-any重光照任务和风格转换的异同点："><a href="#1、any-to-any重光照任务和风格转换的异同点：" class="headerlink" title="1、any-to-any重光照任务和风格转换的异同点："></a>1、any-to-any重光照任务和风格转换的异同点：</h3><table>
<thead>
<tr>
<th>任务类型</th>
<th>相同点</th>
<th>不同点</th>
</tr>
</thead>
<tbody><tr>
<td>风格迁移</td>
<td>输入是原始图像和引导图像</td>
<td>风格迁移一般侧重于纹理渲染</td>
</tr>
<tr>
<td>（any to any）重光照</td>
<td>输入是原始图像和引导图像（及其深度图）</td>
<td>需要去除原始图像的阴影，并且在预测图像中生成新的阴影，风格转换一般做不到这点</td>
</tr>
</tbody></table>
<h3 id="2、any-to-any重光照任务的相关研究"><a href="#2、any-to-any重光照任务的相关研究" class="headerlink" title="2、any-to-any重光照任务的相关研究"></a>2、any-to-any重光照任务的相关研究</h3><p>​		因为深度卷积神经网络 (CNN) 在许多计算机视觉任务中取得了成功，而且之前的重光照方法都直接使用CNN并遵循端到端（end-to-end）的方式直接生成重光照图像（没有假定任何物理先验），受这些方法的启发，该文依旧使用深度学习网络来解决深度引导的任意对任意重照明任务。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Puthussery和Kuriakose等人，2020</td>
<td>WDRN: A wavelet decomposed relightnet for image relighting</td>
<td>2</td>
</tr>
<tr>
<td>Hu和Huang等人 ,ECCV，2020</td>
<td>SA-AE for any-to-any relighting</td>
<td>3</td>
</tr>
<tr>
<td>Guo和Liao等人，BMVC，2019</td>
<td>Deep learning fusion of rgb and depth images for pedestrian detection</td>
<td>4</td>
</tr>
<tr>
<td>Xu和Sunkavalli等人, ToG，2018</td>
<td>Deep image-based relighting from optimal sparse samples</td>
<td>5</td>
</tr>
<tr>
<td>Yang和Chen等人，CVPRW，2021</td>
<td>Multi modal bifurcated network for depth guided image relighting</td>
<td>6</td>
</tr>
</tbody></table>
<p>​		与传统的图像重光照任务不同，该文使用了NTIRE 2021竞赛中提供的额外的深度图，这有利于模型学习场景的物理空间表示。 </p>
<p>​		该文在解码器部分使用了多尺度特征提取器和注意力机制，多尺度特征提取器 可用于增加感受野并整合粗到细的表示，有必要采用这个模块，因为重光照图像包含各种尺度的对象；注意力机制可以分配特征图权重来放大局部区域的特征，由于重光照图像包含方向信息，使用注意力机制有利于模型学习方向的特征表示。</p>
<p>​		该文在 VIDIT 数据集上测试了我们提出的方法，多个实验表明，所提出的 S3Net 在 NTIRE 2021 深度引导任意对任意重新照明挑战中实现了第三高的 SSIM 和 MPS。</p>
<p>​		笔者认为该文的创新点或贡献如下：</p>
<p>1、提出了一个单流结构网络 (S3Net)处理any to any重光照任务</p>
<p>2、为了设计一个高效的图像重照明网络，在解码器部分加入了注意力模块和增强模块</p>
<p>3、为了进一步优化模型，该文在目标函数上使用了结合了离散小波变换（DWT）理论的多尺度损失函数，提升了准确性。</p>
<h1 id="二、相关工作"><a href="#二、相关工作" class="headerlink" title="二、相关工作"></a>二、相关工作</h1><h2 id="1、带有深度图的图像处理"><a href="#1、带有深度图的图像处理" class="headerlink" title="1、带有深度图的图像处理"></a>1、带有深度图的图像处理</h2><p>​       与传统的只使用RGB图像的计算机视觉任务不同，使用额外的深度信息可以提高许多计算机视觉任务的准确性，当与 RGB 图像结合使用时，深度图已被证明是提供几何和空间信息的有用提示。</p>
<p>​	   2019年Guo和Liao等人的《Deep learning fusion of rgb and depth images for pedestrian detection》，提出了 Faster RCNN模型来解决行人检测问题，该工作证明可以利用深度图来细化从 RGB 图像中提取的卷积特征， 而且可以在深度信息的帮助下探索透视投影，从而实现更准确的区域建议。</p>
<p>​	   2020年Chen和Lin等人的ECCV上的《Bi-directional cross-modality feature propagation with separation-and-aggregation gate for rgb-d semantic segmentation》中，提出了一种统一且高效的跨模态引导的语义分割编码器。 这种结构在跨模态聚合之前联合过滤和重新校准两种表示。 同时，引入了双向多步传播策略以有效融合两种模态之间的信息。  </p>
<p>​		为了有效地提取 RGB 图像和深度特征，最流行的方法是使用双流主干网络的结构，如下相关研究： </p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Pang和Zhang等人，2020</td>
<td>Hierarchical dynamic filtering network for rgb-d salient object detection</td>
<td>使用双流主干，输入为RGB图像和深度图</td>
</tr>
<tr>
<td>Chen和Fu等人 ,ECCV，2020</td>
<td>Progressively guided alternate refinement network for rgb-d salient object detection</td>
<td>使用双流主干，输入为RGB图像和深度图</td>
</tr>
</tbody></table>
<p>​		然后，VIDIT 数据集中重光照图像的大小和相应的深度图非常大（1024×1024），且每次输入都是两个RGB图像和两个深度图，所以这种输入会在双主干网络结构中造成巨大的计算负担，而且论文作者认为重光照图像包含光源方向信息，这不适合在训练期间将大图像裁剪为小块， 所以该文设计了一个单一的流结构来联合提取深度和图像特征。</p>
<h2 id="2、基于深度学习的图像重光照"><a href="#2、基于深度学习的图像重光照" class="headerlink" title="2、基于深度学习的图像重光照"></a>2、基于深度学习的图像重光照</h2><p>​        在NTIRE 2021的竞赛规则中，有两种重光照任务设置：</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>相关研究</strong></th>
</tr>
</thead>
<tbody><tr>
<td>one-to-one重光照</td>
<td>光源方向和光源色温是预先定义的</td>
<td>《WDRN: A wavelet decomposed relightnet for image relighting》、《Multi modal bifurcated network for depth guided image relighting》</td>
</tr>
<tr>
<td>any-to-any重光照</td>
<td>光源方向和光源色温是基于一张引导图像</td>
<td>《SA-AE for any-to-any relighting》</td>
</tr>
</tbody></table>
<p>​		由于都是图像到图像的转换任务，重光照任务似乎与其他低级计算机视觉任务非常相似，例如图像去雾 、图像烟雾去除、图像去雪、反射去除和水下图像增强等，但是与它们不同的是，重光照任务包含光源方向和色温的信息，需要在预测图像中估计物体的阴影。 </p>
<p>​		图像到图像的转换任务经常使用编码器-解码器架构，其中U-net [22, 23] 是最流行的图像到图像转换任务网络：</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Ronneberger和Fischer等人，2015</td>
<td>《U-net: Convolutional networks for biomedical image segmentation》</td>
<td>提出了用于生物医学图像语义分割的卷积神经网络：Unet</td>
</tr>
<tr>
<td>Hu和Shen等人，CVPR，2018</td>
<td>《Squeeze-and-excitation networks》</td>
<td>提出了通道注意力模块（CAM）</td>
</tr>
</tbody></table>
<p>​		Unet结构不仅包括编码器-解码器结构，还包括跳跃连接，它将从编码器到解码器具有相同大小的特征连接起来。 例如，Puthussery 等人 [2] 提出了一种用于图像重光照的离散小波分解重光照网络。 </p>
<h2 id="3、离散小波变换（Wavelet-Transform）"><a href="#3、离散小波变换（Wavelet-Transform）" class="headerlink" title="3、离散小波变换（Wavelet Transform）"></a>3、离散小波变换（Wavelet Transform）</h2><p>​        1999年Elsevier等人的论文《A wavelet tour of signal processing》提出了离散小波变换（DWT），该操作可以将图像分解为不同频率间隔的各种小块，可以替代现有的下采样操作，如最大池化或平均池化。 因此，许多计算机视觉任务应用 DWT 来减少特征图并实现多尺度特征，如下：</p>
<p>​		2019年ICIP上的《Wavelet U-net and the chromatic adaptation transform for single image dehazing》；</p>
<p>​		2020年ECCV上的《WDRN: A wavelet decomposed relightnet for image relighting》 。</p>
<p>​		2020年的CASSP上的《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》利用 DWT 来设计目标函数来测量真实图像和预测图像之间的相似性。受该工作的启发，该文也在损失函数中结合了 DWT，使其网络可以学习多尺度表示。</p>
<h2 id="4、注意力机制"><a href="#4、注意力机制" class="headerlink" title="4、注意力机制"></a>4、注意力机制</h2><p>​        注意机制在人类感知系统和深度学习任务中都起着重要作用。注意机制提供特征图或某些序列权重，以便可以放大区域或位置的特征。 具体来说，对于计算机视觉任务，注意力机制分为空间注意力和通道注意力。 前者在空间上利用权重来细化特征图，后者计算全局平均池化特征以实现通道注意力。 		在本文中，我们的模型利用了这两种注意力机制来进一步提高网络的性能。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Mnih和Heess 等人，2014</td>
<td>《Recurrent models of visual attention》</td>
<td>空间注意力</td>
</tr>
<tr>
<td>Hu和Shen等人，CVPR，2018</td>
<td>《Squeeze-and-excitation networks》</td>
<td>通道注意力</td>
</tr>
<tr>
<td>Yang等人，ECCV，2020</td>
<td>《Wavelet channel attention module with a fusion network for single image deraining》</td>
<td>通道注意力，注意力机制应用于图像增强领域</td>
</tr>
<tr>
<td>Hu和Huang等人 ,ECCV，2020</td>
<td>《SA-AE for any-to-any relighting》</td>
<td>空间注意力</td>
</tr>
</tbody></table>
<h1 id="三、方法"><a href="#三、方法" class="headerlink" title="三、方法"></a>三、方法</h1><h2 id="1、网络模型"><a href="#1、网络模型" class="headerlink" title="1、网络模型"></a>1、网络模型</h2><p>​			该文的整个网络模型的输入是原始RGB图（1024x1024x3）、原始深度图（1024x1024x1）、引导RGB图（1024x1024x3）和引导深度图（1024x1024x1）连接在一起形成的8通道张量（1024x1024x8），输出的是3通道的预测RGB图（1024x1024x3）。</p>
<p>​			本文提出的 S3Net 的架构如下图所示。该网络基于<em><strong>《Knowledge transfer dehazing network for nonhomogeneous dehazing》</strong></em>，包含编码器和解码器部分。 </p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\S3net整体架构.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/S3net%E6%95%B4%E4%BD%93%E6%9E%B6%E6%9E%84.png"></p>
<p>​		【编码器】该文使用<em><strong>《Res2net: A new multi-scale backbone architecture》</strong></em>提出的Res2Net101网络主干作为编码器，因为Res2Net 可以在粒度级别表示多尺度特征，并增加每个网络层的感受野范围，输入通过主干后可以实现多尺度特征提取。该文的工作在Res2Net做了如下修改：</p>
<ul>
<li>修改第一个卷积使网络可以使用8 通道张量作为输入；</li>
<li>丢弃网络最后的全连接层，使最终输出的特征图的大小为 16分之一 ；</li>
<li>编码器的初始权重是用 ImageNet 训练的预训练参数，底部特征使用跳跃连接连接到解码器。</li>
</ul>
<p>​       【解码器】解码器由卷积堆栈组成，以细化特征图。</p>
<p>​		 利用注意力模块（Attention，P）来细化中间特征。 注意模块由残差层 （residual layer）<em><strong>《Deep residual learning for image recognition》</strong></em>、空间注意力模块（SAM）<em><strong>《Recurrent models of visual attention》</strong></em> 和通道注意力模块（CAM）<em><strong>《Squeeze-and-excitation networks》</strong></em> 组成。</p>
<p>​		 利用像素混洗（Pixel shuffle，P）<em><strong>《Real-time single image and video super-resolution using an efficient subpixel convolutional neural network》</strong></em>和转置卷积（Transposed convolution，T）<em><strong>《Pixel transposed convolutional networks》</strong></em>来放大特征图。</p>
<p>​		此外，受<em><strong>《Enhanced pix2pix dehazing network》</strong></em>的启发，该文章在 S3Net 中添加了增强模块。 增强模块利用不同步幅的平均池化来改变特征图和感受野的大小，这对于提取多尺度特征是有效的。 最后，应用上采样来恢复减少的特征图，并将所有特征图拼接起来。 </p>
<p>​		【跳跃连接】众所周知，类 U-Net 结构在许多任务中是有益的，例如图像去雾（《PMS-net: Robust haze removal based on patch map for single images》，《PMHLD: patch map-based hybrid learning dehazenet for single image haze removal》） 和语义分割 （<em><strong>《U-net: Convolutional networks for biomedical image segmentation》</strong></em>）。 它的跳跃连接鼓励特征重用。 因此S3Net 中也采用跳跃连接将来自主干的最后三个特征图合并到它们对应的特征图。</p>
<h2 id="2、损失函数"><a href="#2、损失函数" class="headerlink" title="2、损失函数"></a>2、损失函数</h2><p>​		该文章的S3Net一共使用了三个损失函数，其整体损失如下：<br>$$<br>L_{\text {Total }}&#x3D;\lambda_{1} L_{\text {cha }}+\lambda_{2} L_{W-S S I M}+\lambda_{3} L_{P e r}<br>$$<br>​		其中 $\lambda_{1}$、$$\lambda_{2}$ 和$ $\lambda_{3}$ 是缩放系数，用于调整三个分量的相对权重。</p>
<h3 id="（1）Charbonnier-损失"><a href="#（1）Charbonnier-损失" class="headerlink" title="（1）Charbonnier 损失"></a>（1）Charbonnier 损失</h3><p>​		该损失函数来自于《A general and adaptive robust loss function》，其可以看做是一个高鲁棒性的L1损失函数，该损失函数可以还原全局结构并且可以更鲁棒地处理异常值，其公式如下：<br>$$<br>L_{C h a}(I, \hat{I})&#x3D;\frac{1}{T} \sum_{i}^{T} \sqrt{\left(I_{i}-\hat{I}_{i}\right)^{2}+\epsilon^{2}}<br>$$<br>​       其中$I$ 和$\hat{I}$ 分别代表目标图像和该文网络输出的预测图像， $\epsilon$被视为一个微小的常数（例如$10^{-6}$）,用来实现稳定和鲁棒的收敛。</p>
<h3 id="（2）SSIM-损失"><a href="#（2）SSIM-损失" class="headerlink" title="（2）SSIM 损失"></a>（2）SSIM 损失</h3><p>​		该损失函数来自于《Loss functions for image restoration with neural networks》 ，其能够重建局部纹理和细节。 可以表示为：<br>$$<br>L_{S S I M}(I, \hat{I})&#x3D;-\frac{\left(2 \mu_{I} \mu_{\hat{I}}+C_{1}\right)\left(2 \sigma_{I \hat{I}}+C_{2}\right)}{\left(\mu_{I}^{2}+\mu_{\hat{I}}^{2}+C_{1}\right)\left(\sigma_{I}^{2}+\sigma_{\hat{I}}^{2}+C_{2}\right)}<br>$$<br>​		 其中 σ 和 µ 表示图像的标准偏差、协方差和均值。 </p>
<p>​		在图像重照明任务中，为了从原始图像中去除阴影，该文扩展了 SSIM 损失函数，以便使网络可以恢复更详细的部分。 </p>
<p>​		该文使用《Y-net: Multiscale feature aggregation network with wavelet structure similarity loss function for single image dehazing》 中的方法将 DWT 组合到 SSIM 损失中，这有利于重建重光照图像的清晰细节。最初，DWT 将预测图像分解为四个不同的小sub-band图像。 操作可以表示为：<br>$$<br>\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}&#x3D;\operatorname{DWT}(\hat{I})<br>$$</p>
<p>​       其中上标表示来自各个过滤器的输出（例如，$$\hat{I}^{L L}, \hat{I}^{L H}, \hat{I}^{H L}, \hat{I}^{H H}$$）。</p>
<p>​       $$\hat{I}^{H L}, \hat{I}^{L H}, \hat{I}^{H H}$$分别是水平边缘、垂直边缘和角点检测的高通滤波器。  fLL 被视为下采样操作。 此外，DWT 可以不断分解$$\hat{I}^{L L}$$ 以生成具有不同尺度和频率信息的图像。 这一步写成：<br>$$<br>\hat{I}<em>{i+1}^{L L}, \hat{I}</em>{i+1}^{L H}, \hat{I}<em>{i+1}^{H L}, \hat{I}</em>{i+1}^{H H}&#x3D;\operatorname{DWT}\left(\hat{I}<em>{i}^{L L}\right)<br>$$<br>​       其中下标 i 表示第 i 次 DWT 迭代的输出。 上述 SSIM 损失项是根据原始图像对和各种子带图像对计算得出的。  SSIM损失和DWT的融合整合为：<br>$$<br>\begin{array}{l}<br>L</em>{W-S S I M}(I, \hat{I})&#x3D;\sum_{0}^{r} \gamma_{i} L_{\mathrm{SSIM}}\left(I_{i}^{w}, \hat{I}<em>{i}^{w}\right) \<br>w \in{L L, H L, L H, H H}<br>\end{array}<br>$$<br>       其中$$\gamma</em>{i}$$  基于原文来控制不同补丁的重要性。</p>
<h3 id="（3）感知损失"><a href="#（3）感知损失" class="headerlink" title="（3）感知损失"></a>（3）感知损失</h3><p>​			该损失函数来自于《Perceptual losses for real-time style transfer and super-resolution》， 与前面提到的两个损失函数不同，感知损失利用从预训练的深度神经网络（例如 VGG19 （《Very deep convolutional networks for large-scale image recognition》））获得的多尺度特征来测量预测图像和目标图像之间的视觉特征差异。该文章使用在ImageNet 上预训练的 VGG19 被用作损失函数网络。</p>
<p>​    		感知损失定义为<br>$$<br>L_{P e r}(I, \hat{I})&#x3D;\mid(\operatorname{VGG}(I)-\operatorname{VGG}(\hat{I}) \mid<br>$$</p>
<p>​			其中$\mid·\mid$ 是绝对值。</p>
<h1 id="四、实验"><a href="#四、实验" class="headerlink" title="四、实验"></a>四、实验</h1><pre><code>     该文的实验使用的是NTIRE 2021中使用的数据集是the Virtual Image Dataset for Illumination Transfer (VIDIT) 。 该图像数据集总共有15600张图片，包含390 个不同的虚拟场景及其对应的390 张深度图，每个场景具有40种不同的照明设置（从2500到6500K的五种不同色温和 8 个方位角）。 所有训练图像和深度图的大小分别为 1024 × 1024 × 3 和 1024 × 1024 × 1。  
</code></pre>
<p>​		在整个数据集中300 个场景用于训练，剩下的 90 个场景用于验证和测试。</p>
<table>
<thead>
<tr>
<th><strong>作者年份</strong></th>
<th><strong>论文题目</strong></th>
<th><strong>主要贡献</strong></th>
</tr>
</thead>
<tbody><tr>
<td>Helou和Zhou等人，2020</td>
<td>《Vidit: Virtual image dataset for illumination transfer》</td>
<td>提出了用于图像重光照的虚拟图像数据集VIDIT</td>
</tr>
</tbody></table>
<h2 id="1、消融实验的定量分析"><a href="#1、消融实验的定量分析" class="headerlink" title="1、消融实验的定量分析"></a>1、消融实验的定量分析</h2><p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\消融实验的定量分析.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C%E7%9A%84%E5%AE%9A%E9%87%8F%E5%88%86%E6%9E%90.png"></p>
<h2 id="2、消融实验的定性分析"><a href="#2、消融实验的定性分析" class="headerlink" title="2、消融实验的定性分析"></a>2、消融实验的定性分析</h2><p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\消融实验的定性分析.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%B6%88%E8%9E%8D%E5%AE%9E%E9%AA%8C%E7%9A%84%E5%AE%9A%E6%80%A7%E5%88%86%E6%9E%90.png"></p>
<h2 id="3、与其他方法的对比实验"><a href="#3、与其他方法的对比实验" class="headerlink" title="3、与其他方法的对比实验"></a>3、与其他方法的对比实验</h2><p>​		如下表所示，列出的是本文提出的方法和在NTIRE2021 workshop的深度引导的any-to-any重光照挑战中的其他竞争方法的对比结构：</p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\对比实验.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E5%AF%B9%E6%AF%94%E5%AE%9E%E9%AA%8C.png"></p>
<p>​        结果显示本文方法的结果在 SSIM、PSNR、LPIPS 和 MPS 方面分别获得了第 3、第 4、第 2 和第 3 名。<br>​        本文模型在测试阶段平均需要 2.042 秒来生成 1024 × 1024大小的 重光照图像。</p>
<h1 id="五、总结与不足"><a href="#五、总结与不足" class="headerlink" title="五、总结与不足"></a>五、总结与不足</h1><p>​		该文提出了一种单流结构网络（S3Net）用于深度引导的任意对任意的图像重照明。该网络的编码器部分基于Res2Net，解码器部分加入了注意力模块和增强模块 ；损失函数中加入了离散小波变换的SSIM损失。</p>
<p>​		该方法在NTIRE 2021的PMS 和 SSIM 方面获得了第三名，但是实验证明，该文的方法也会在某些条件下可能会失败，如下图所示，当原始图像包含大面积的阴影时，该文的模型无法识别它们的前景和背面，导致预测图像与真实图像非常不同，论文作者认为这是因为即使给出了深度图，这些信息也只是提供了正面而不是全方位的空间信息。  </p>
<p>![](\img-post\论文分享\2021-11-04-s3net：深度引导图像重照明的单流结构\模型的失败案例.png)</p>
<p><img src="/../img-post/%E8%AE%BA%E6%96%87%E5%88%86%E4%BA%AB/2021-11-04-s3net%EF%BC%9A%E6%B7%B1%E5%BA%A6%E5%BC%95%E5%AF%BC%E5%9B%BE%E5%83%8F%E9%87%8D%E7%85%A7%E6%98%8E%E7%9A%84%E5%8D%95%E6%B5%81%E7%BB%93%E6%9E%84/%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%A4%B1%E8%B4%A5%E6%A1%88%E4%BE%8B.png"></p>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91S3net%E7%9A%84%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" class="post-title-link" itemprop="url">「科研笔记」S3net的损失函数</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-02 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-02T00:00:00+00:00">2021-11-02</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <h1 id="感知损失"><a href="#感知损失" class="headerlink" title="感知损失"></a>感知损失</h1><p>项目DRN和S3Net都是用的 J. Johnson, A. Alahi, and L. Fei-Fei,  2016《Perceptual losses for real-time style transfer and super-resolution,” in European conference on computer vision》的感知函数</p>
<p>   感知损失利用从预训练的深度神经网络（例如 VGG19 ）中获得的多尺度特征来测量真实图像和网络预测图像之间的视觉特征差异。 在DRN、S3Net中使用 ImageNet训练集 上预训练的 VGG19 网络来计算感知损失。  </p>
<p>​      感知损失（使用VGG）公式为：</p>
<p><img src="D:/个人文件夹/123wangju123.github.io/_posts//img-post/科研笔记/2021-11-02-【科研笔记】感知损失函数/VGGLOSS.png"></p>
<p><img src="/../img-post/%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0/2021-11-02-%E3%80%90%E7%A7%91%E7%A0%94%E7%AC%94%E8%AE%B0%E3%80%91%E6%84%9F%E7%9F%A5%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/VGGLOSS.png"></p>
<h2 id="Vgg19网络结构："><a href="#Vgg19网络结构：" class="headerlink" title="Vgg19网络结构："></a>Vgg19网络结构：</h2><p>VGG19包含了19个隐藏层（16个卷积层和3个全连接层）。</p>
<p><img src="https://cdn.nlark.com/yuque/0/2021/png/13013014/1632217897702-0d271030-b1b5-4953-b286-6e291f0ba5ae.png" alt="img"></p>
<h2 id="DRN代码中，使用Pytorch获取Vgg19网络："><a href="#DRN代码中，使用Pytorch获取Vgg19网络：" class="headerlink" title="DRN代码中，使用Pytorch获取Vgg19网络："></a>DRN代码中，使用Pytorch获取Vgg19网络：</h2><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> torchvision.models as models</span><br><span class="line"># 加载预训练的模型</span><br><span class="line">vgg_model = models.<span class="built_in">vgg19</span>(pretrained=True)</span><br><span class="line"># 获取中间层特征</span><br><span class="line">vgg_pretrained_features = vgg_model.features</span><br><span class="line"><span class="built_in">print</span>(<span class="string">&#x27;model.features[0]&#x27;</span>, model.features[<span class="number">0</span>]) #<span class="built_in">Conv2d</span>(<span class="number">3</span>, <span class="number">64</span>, kernel_size=(<span class="number">3</span>, <span class="number">3</span>), stride=(<span class="number">1</span>, <span class="number">1</span>), padding=(<span class="number">1</span>, <span class="number">1</span>))</span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><span class="line">from torchvision import models</span><br><span class="line"></span><br><span class="line">class Vgg19(torch.nn.Module):</span><br><span class="line">    def __init__(self, requires_grad=False):</span><br><span class="line">        super(Vgg19, self).__init__()</span><br><span class="line">        # 加载预训练的模型</span><br><span class="line">        # vgg_pretrained_features = models.vgg19(pretrained=True).features</span><br><span class="line">        </span><br><span class="line">        # 加载预训练模型</span><br><span class="line">        model = models.vgg19(pretrained=True)</span><br><span class="line">        # 获取中间层特征</span><br><span class="line">        vgg_pretrained_features = model.features</span><br><span class="line">        </span><br><span class="line">        self.slice1 = torch.nn.Sequential()</span><br><span class="line">        self.slice2 = torch.nn.Sequential()</span><br><span class="line">        self.slice3 = torch.nn.Sequential()</span><br><span class="line">        self.slice4 = torch.nn.Sequential()</span><br><span class="line">        self.slice5 = torch.nn.Sequential()</span><br><span class="line">        # 把不同层的特征分别加入不同的模块</span><br><span class="line">        for x in range(2):</span><br><span class="line">            self.slice1.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(2, 7):</span><br><span class="line">            self.slice2.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(7, 12):</span><br><span class="line">            self.slice3.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(12, 21):</span><br><span class="line">            self.slice4.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        for x in range(21, 28):</span><br><span class="line">            self.slice5.add_module(str(x), vgg_pretrained_features[x])</span><br><span class="line">        # 设置所有参数都不需要计算梯度</span><br><span class="line">        if not requires_grad:</span><br><span class="line">            for param in self.parameters():</span><br><span class="line">                param.requires_grad = False</span><br><span class="line"></span><br><span class="line">    def forward(self, X):</span><br><span class="line">        # 获取不同模块的特征</span><br><span class="line">        h_relu1 = self.slice1(X)</span><br><span class="line">        h_relu2 = self.slice2(h_relu1)</span><br><span class="line">        h_relu3 = self.slice3(h_relu2)</span><br><span class="line">        #h_relu4 = self.slice4(h_relu3)</span><br><span class="line">        #h_relu5 = self.slice5(h_relu4)</span><br><span class="line">        #out = [h_relu1, h_relu2, h_relu3, h_relu4, h_relu5]</span><br><span class="line">        out = [h_relu1, h_relu2, h_relu3]#, h_relu4, h_relu5]</span><br><span class="line">        return out</span><br></pre></td></tr></table></figure>

<h2 id="用vgg计算感知损失（VGGLoss）"><a href="#用vgg计算感知损失（VGGLoss）" class="headerlink" title="用vgg计算感知损失（VGGLoss）"></a>用vgg计算感知损失（VGGLoss）</h2><p>VGG19本是用来进行分类的，进行可视化和用作VGG loss 自然也就是用到全连接层之前的内容</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">class VGGLoss(nn.Module):</span><br><span class="line">    def __init__(self, gpu_ids):</span><br><span class="line">        super(VGGLoss, self).__init__()</span><br><span class="line">        self.vgg = Vgg19().cuda()</span><br><span class="line">        self.criterion = nn.L1Loss()</span><br><span class="line">        self.weights = [1.0 / 32, 1.0 / 16, 1.0 / 8, 1.0 / 4, 1.0]</span><br><span class="line"></span><br><span class="line">    def forward(self, x, y):</span><br><span class="line">        x_vgg, y_vgg = self.vgg(x), self.vgg(y)</span><br><span class="line">        loss = 0</span><br><span class="line">        for i in range(len(x_vgg)):</span><br><span class="line">            loss += self.weights[i] * self.criterion(x_vgg[i], y_vgg[i].detach())</span><br><span class="line">        return loss</span><br></pre></td></tr></table></figure>

<h1 id="Charbonnier-loss"><a href="#Charbonnier-loss" class="headerlink" title="Charbonnier loss"></a>Charbonnier loss</h1><p>Charbonnier 损失 （ A general and adaptive robust loss function ），可以看作是鲁棒的 L1 损失函数。</p>
<p>  其中 I 和 I^ 分别代表真实图像和来自提出网络的 relit 图像，并且 e 被视为一个微小的常数（例如 10−6 ）以实现稳定和鲁棒的收敛。 LC ha 可以还原全局结构并且可以更鲁棒地处理异常值。</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211103001556088.png" alt="image-20211103001556088"></p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;</span><span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">@文件名: ChaLoss.py</span></span><br><span class="line"><span class="string">@作者: XW</span></span><br><span class="line"><span class="string">@时间: 2021/11/2 23:05</span></span><br><span class="line"><span class="string">@环境: Python,Numpy</span></span><br><span class="line"><span class="string">@描述: 无</span></span><br><span class="line"><span class="string">@参考: 无</span></span><br><span class="line"><span class="string">&#x27;&#x27;&#x27;</span><span class="string">&#x27;&#x27;&#x27;&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="keyword">import</span> torch</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="comment">#定义L1损失函数</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">cha_loss</span>(<span class="params">y_true,y_pre</span>):</span><br><span class="line"></span><br><span class="line">    e = <span class="number">10</span>**(-<span class="number">6</span>)</span><br><span class="line">    loss=torch.mean(torch.sqrt((y_true-y_pre)**<span class="number">2</span>)+e**<span class="number">2</span>)</span><br><span class="line">    <span class="comment"># loss = torch.sqrt((y_true-y_pre)**2)</span></span><br><span class="line">    <span class="comment"># loss = np.mean(np.sqrt((y_true - y_pre) ** 2) )</span></span><br><span class="line">    <span class="keyword">return</span> loss</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">&#x27;__main__&#x27;</span>:</span><br><span class="line">    y_true=torch.tensor([<span class="number">1.0</span>,<span class="number">2.0</span>,<span class="number">3.0</span>])</span><br><span class="line">    y_pre=torch.tensor([<span class="number">4.0</span>,<span class="number">5.0</span>,<span class="number">6.0</span>])</span><br><span class="line">    res=cha_loss(y_true,y_pre)</span><br><span class="line">    <span class="built_in">print</span>(<span class="built_in">type</span>(res))</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-11-01-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E6%B1%82%E5%87%A0%E4%B8%AA%E6%95%B0%E4%B9%8B%E5%92%8C/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-11-01-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E6%B1%82%E5%87%A0%E4%B8%AA%E6%95%B0%E4%B9%8B%E5%92%8C/" class="post-title-link" itemprop="url">「算法刷题」求几个数之和</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-11-01 00:00:00" itemprop="dateCreated datePublished" datetime="2021-11-01T00:00:00+00:00">2021-11-01</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>15</td>
<td>三数之和（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/3sum/">15. 三数之和 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>

      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91c++%E4%B8%ADsort%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91c++%E4%B8%ADsort%E5%87%BD%E6%95%B0%E7%9A%84%E4%BD%BF%E7%94%A8%E6%96%B9%E6%B3%95/" class="post-title-link" itemprop="url">「算法刷题」c++中sort函数的使用方法</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <p>参考链接： <a target="_blank" rel="noopener" href="https://www.cnblogs.com/junbaobei/p/10776066.html">C++中sort函数使用方法 - 俊宝贝 - 博客园 (cnblogs.com)</a> </p>
<p>1.sort函数包含在头文件为#include<algorithm>的c++标准库中，调用标准库里的排序方法可以实现对数据的排序，但是sort函数是如何实现的，我们不用考虑！</p>
<p>2.sort函数的模板有三个参数：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">void sort (RandomAccessIterator first, RandomAccessIterator last, Compare comp);</span><br></pre></td></tr></table></figure>

<p>（1）第一个参数first：是要排序的数组的起始地址。</p>
<p>（2）第二个参数last：是结束的地址（最后一个数据的后一个数据的地址）</p>
<p>（3）第三个参数comp是排序的方法：可以是从升序也可是降序。如果第三个参数不写，则默认的排序方法是从小到大排序。</p>
<p>3 实例</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> 1 #include&lt;iostream&gt;</span><br><span class="line"> 2 #include&lt;algorithm&gt;</span><br><span class="line"> 3 using namespace std;</span><br><span class="line"> 4 main()</span><br><span class="line"> 5 &#123;</span><br><span class="line"> 6 　　//sort函数第三个参数采用默认从小到大</span><br><span class="line"> 7 　　int a[]=&#123;45,12,34,77,90,11,2,4,5,55&#125;;</span><br><span class="line"> 8 　　sort(a,a+10);</span><br><span class="line"> 9 　　for(int i=0;i&lt;10;i++)</span><br><span class="line">10 　　cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;;     </span><br><span class="line">11 &#125; </span><br></pre></td></tr></table></figure>

<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line"> 1 #include&lt;iostream&gt;</span><br><span class="line"> 2 #include&lt;algorithm&gt;</span><br><span class="line"> 3 using namespace std;</span><br><span class="line"> 4 bool cmp(int a,int b);</span><br><span class="line"> 5 main()&#123;</span><br><span class="line"> 6 　　//sort函数第三个参数自己定义，实现从大到小 </span><br><span class="line"> 7 　　int a[]=&#123;45,12,34,77,90,11,2,4,5,55&#125;;</span><br><span class="line"> 8 　　sort(a,a+10,cmp);</span><br><span class="line"> 9 　　for(int i=0;i&lt;10;i++)</span><br><span class="line">10 　　　　cout&lt;&lt;a[i]&lt;&lt;&quot; &quot;;     </span><br><span class="line">11 &#125;</span><br><span class="line">12 //自定义函数</span><br><span class="line">13 bool cmp(int a,int b)&#123;</span><br><span class="line">14 　　return a&gt;b;</span><br><span class="line">15 &#125;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




    


<div class="post-block">
  
  

  <article itemscope itemtype="http://schema.org/Article" class="post-content" lang="">
    <link itemprop="mainEntityOfPage" href="https://www.vvbuys.com/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="vvbuys">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="VVbuys Blog">
      <meta itemprop="description" content="Share some post and some issue for linux program">
    </span>

    <span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork">
      <meta itemprop="name" content="undefined | VVbuys Blog">
      <meta itemprop="description" content="">
    </span>
      <header class="post-header">
        <h2 class="post-title" itemprop="name headline">
          <a href="/2021-10-29-%E3%80%90%E7%AE%97%E6%B3%95%E5%88%B7%E9%A2%98%E3%80%91%E5%93%88%E5%B8%8C%E8%A1%A8%E7%9A%84%E7%9B%B8%E5%85%B3%E7%BB%8F%E5%85%B8%E9%A2%98%E7%9B%AE/" class="post-title-link" itemprop="url">「算法刷题」哈希表的相关经典题目</a>
        </h2>

        <div class="post-meta-container">
          <div class="post-meta">
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar"></i>
      </span>
      <span class="post-meta-item-text">Posted on</span>

      <time title="Created: 2021-10-29 00:00:00" itemprop="dateCreated datePublished" datetime="2021-10-29T00:00:00+00:00">2021-10-29</time>
    </span>
    <span class="post-meta-item">
      <span class="post-meta-item-icon">
        <i class="far fa-calendar-check"></i>
      </span>
      <span class="post-meta-item-text">Edited on</span>
      <time title="Modified: 2024-02-02 01:00:55" itemprop="dateModified" datetime="2024-02-02T01:00:55+00:00">2024-02-02</time>
    </span>

  
</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">
          <table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>383</td>
<td>赎金信（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/ransom-note/">383. 赎金信 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function"><span class="type">bool</span> <span class="title">canConstruct</span><span class="params">(string ransomNote, string magazine)</span> </span>&#123;</span><br><span class="line">        <span class="type">int</span> record[<span class="number">26</span>]=&#123;<span class="number">0</span>&#125;;</span><br><span class="line">        <span class="comment">// 记录magazine里各个字符出现的次数</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;magazine.<span class="built_in">length</span>();i++)&#123;</span><br><span class="line">            record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 遍历ransomNote，在record里对应的字符个数做--操作</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> j=<span class="number">0</span>;j&lt;ransomNote.<span class="built_in">length</span>();j++)&#123;</span><br><span class="line">            record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]--;</span><br><span class="line">            <span class="comment">// 如果小于零，说明ransomNote里出现的字符，magazine里没有</span></span><br><span class="line">            <span class="keyword">if</span>(record[magazine[i]-<span class="string">&#x27;a&#x27;</span>]&lt;<span class="number">0</span>)&#123;</span><br><span class="line">                <span class="keyword">return</span> <span class="literal">false</span>;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> <span class="literal">true</span>;</span><br><span class="line">        </span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<p>类似题目：</p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>242</td>
<td>有效的字母异位词（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/valid-anagram/">242. 有效的字母异位词 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p><strong>数组其实就是一个简单哈希表</strong>，而且这道题目中字符串只有小写字符，那么就可以定义一个数组，来记录字符串s里字符出现的次数。</p>
<p>定义一个数组叫做record用来上记录字符串s里字符出现的次数。</p>
<p>1、需要把字符映射到数组也就是哈希表的索引下表上，<strong>因为字符a到字符z的ASCII是26个连续的数值，所以字符a映射为下表0，相应的字符z映射为下表25。</strong></p>
<p>再遍历 字符串s的时候，<strong>只需要将 s[i] - ‘a’ 所在的元素做+1 操作即可，并不需要记住字符a的ASCII，只要求出一个相对数值就可以了。</strong> 这样就将字符串s中字符出现的次数，统计出来了。</p>
<p>2、那看一下如何检查字符串t中是否出现了这些字符，同样在遍历字符串t的时候，对t中出现的字符映射哈希表索引上的数值再做-1的操作。</p>
<p>3、那么最后检查一下，<strong>record数组如果有的元素不为零0，说明字符串s和t一定是谁多了字符或者谁少了字符，return false。</strong></p>
<p>最后如果record数组所有元素都为零0，说明字符串s和t是字母异位词，return true。</p>
<p>时间复杂度为O(n)，空间上因为定义是的一个常量大小的辅助数组，所以空间复杂度为O(1)。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    bool isAnagram(string s, string t) &#123;</span><br><span class="line">        int record[26] = &#123;0&#125;;</span><br><span class="line">        for (int i = 0; i &lt; s.size(); i++) &#123;</span><br><span class="line">            // 并不需要记住字符a的ASCII，只要求出一个相对数值就可以了</span><br><span class="line">            record[s[i] - &#x27;a&#x27;]++;</span><br><span class="line">        &#125;</span><br><span class="line">        for (int i = 0; i &lt; t.size(); i++) &#123;</span><br><span class="line">            record[t[i] - &#x27;a&#x27;]--;</span><br><span class="line">        &#125;</span><br><span class="line">        for (int i = 0; i &lt; 26; i++) &#123;</span><br><span class="line">            if (record[i] != 0) &#123;</span><br><span class="line">                // record数组如果有的元素不为零0，说明字符串s和t 一定是谁多了字符或者谁少了字符。</span><br><span class="line">                return false;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        // record数组所有元素都为零0，说明字符串s和t是字母异位词</span><br><span class="line">        return true;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="知识补充："><a href="#知识补充：" class="headerlink" title="知识补充："></a>知识补充：</h1><h2 id="1、c-memset-函数"><a href="#1、c-memset-函数" class="headerlink" title="1、c++ memset()函数"></a>1、c++ memset()函数</h2><p>memset 函数是内存赋值函数，用来给某一块内存空间进行赋值的；</p>
<p>包含在&lt;string.h&gt;头文件中,可以用它对一片内存空间逐字节进行初始化；</p>
<p>原型为 ：</p>
<p>void *memset(void *s, int v, size_t n);</p>
<p>这里s可以是数组名，也可以是指向某一内在空间的指针；</p>
<p>v为要填充的值；</p>
<p>n为要填充的字节数；</p>
<p>示例1：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">struct data</span><br><span class="line">&#123;</span><br><span class="line">char num[100];</span><br><span class="line">char name[100];</span><br><span class="line">int  n;</span><br><span class="line">&#125;;</span><br><span class="line">struct data  a, b[10];</span><br><span class="line"></span><br><span class="line">memset( &amp;a, 0, sizeof(a) ); //注意第一个参数是指针类型，a不是指针变量，要加&amp;</span><br><span class="line">memset( b, 0, sizeof(b) );  //b是数组名，就是指针类型，不需要加&amp;</span><br></pre></td></tr></table></figure>

<p>示例2：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">char str[9];</span><br><span class="line"></span><br><span class="line">//我们用memset给str初始化为“00000000”，用法如下</span><br><span class="line"></span><br><span class="line">memset(str,0,8); </span><br><span class="line"></span><br><span class="line">//注意，memset是逐字节 拷贝的。</span><br></pre></td></tr></table></figure>

<p>示例3：</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">int num[8];</span><br><span class="line"></span><br><span class="line">//我们用memset给str初始化为&#123;1,1,1,1,1,1,1,1&#125;，</span><br><span class="line">memset(num,1,8);//这样是不对的</span><br><span class="line"></span><br><span class="line">//一个int是4个字节的，8个int是32个字节，所以首先要赋值的长度就不应该为8而是32。</span><br><span class="line"></span><br><span class="line">//因为memset是 逐字节 拷贝，以num为首地址的8字节空间都被赋值为1，</span><br><span class="line"></span><br><span class="line">//即一个int变为0X00000001 00000001 00000001 00000001，显然，把这个数化为十进制不会等于1的</span><br><span class="line"></span><br></pre></td></tr></table></figure>



<h2 id="2、-常见的-string-类构造函数有以下几种形式："><a href="#2、-常见的-string-类构造函数有以下几种形式：" class="headerlink" title="2、 常见的 string 类构造函数有以下几种形式："></a>2、 常见的 string 类构造函数有以下几种形式：</h2><p> strings(num, c) &#x2F;&#x2F;生成一个字符串，包含num个c字符 </p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1002</td>
<td>查找常用字符（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/find-common-characters/">1002. 查找共用字符 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;string&gt; <span class="title">commonChars</span><span class="params">(vector&lt;string&gt;&amp; words)</span> </span>&#123;</span><br><span class="line">        vector&lt;string&gt; result;</span><br><span class="line">        <span class="keyword">if</span> (words.<span class="built_in">size</span>() == <span class="number">0</span>) <span class="keyword">return</span> result;</span><br><span class="line">        <span class="type">int</span> hash[<span class="number">26</span>] = &#123;<span class="number">0</span>&#125;; <span class="comment">// 用来统计所有字符串里字符出现的最小频率</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; words[<span class="number">0</span>].<span class="built_in">size</span>(); i++) &#123; <span class="comment">// 用第一个字符串给hash初始化</span></span><br><span class="line">            hash[words[<span class="number">0</span>][i] - <span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="type">int</span> hashOtherStr[<span class="number">26</span>] = &#123;<span class="number">0</span>&#125;; <span class="comment">// 统计除第一个字符串外字符的出现频率</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">1</span>; i &lt; words.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="built_in">memset</span>(hashOtherStr, <span class="number">0</span>, <span class="number">26</span> * <span class="built_in">sizeof</span>(<span class="type">int</span>));</span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> j = <span class="number">0</span>; j &lt; words[i].<span class="built_in">size</span>(); j++) &#123;</span><br><span class="line">                hashOtherStr[words[i][j] - <span class="string">&#x27;a&#x27;</span>]++;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 更新hash，保证hash里统计26个字符在所有字符串里出现的最小次数</span></span><br><span class="line">            <span class="keyword">for</span> (<span class="type">int</span> k = <span class="number">0</span>; k &lt; <span class="number">26</span>; k++) &#123;</span><br><span class="line">                hash[k] = <span class="built_in">min</span>(hash[k], hashOtherStr[k]);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">// 将hash统计的字符次数，转成输出形式</span></span><br><span class="line">        <span class="keyword">for</span> (<span class="type">int</span> i = <span class="number">0</span>; i &lt; <span class="number">26</span>; i++) &#123;</span><br><span class="line">            <span class="keyword">while</span> (hash[i] != <span class="number">0</span>) &#123; <span class="comment">// 注意这里是while，多个重复的字符</span></span><br><span class="line">                <span class="function">string <span class="title">s</span><span class="params">(<span class="number">1</span>, i + <span class="string">&#x27;a&#x27;</span>)</span></span>; <span class="comment">// char -&gt; string</span></span><br><span class="line">                result.<span class="built_in">push_back</span>(s);</span><br><span class="line">                hash[i]--;</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="keyword">return</span> result;</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h1 id="知识补充：-1"><a href="#知识补充：-1" class="headerlink" title="知识补充："></a>知识补充：</h1><h2 id="哈希数据结构：unordered-set"><a href="#哈希数据结构：unordered-set" class="headerlink" title="哈希数据结构：unordered_set"></a>哈希数据结构：unordered_set</h2><p><strong>参考链接</strong>： <a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7250.html">C++ STL unordered_set容器完全攻略 (biancheng.net)</a> </p>
<p>注意题目特意说明：<strong>输出结果中的每个元素一定是唯一的，也就是说输出的结果是去除了重复的元素， 同时可以不考虑输出结果的顺序</strong></p>
<p>那么用数组来做哈希表也是不错的选择，例如<a target="_blank" rel="noopener" href="https://programmercarl.com/0242.%E6%9C%89%E6%95%88%E7%9A%84%E5%AD%97%E6%AF%8D%E5%BC%82%E4%BD%8D%E8%AF%8D.html">242. 有效的字母异位词</a></p>
<p>但是要注意，<strong>使用数组来做哈希的题目，是因为题目都限制了数值的大小。</strong></p>
<p><strong>而且如果哈希值比较少、特别分散、跨度非常大，使用数组就造成空间的极大浪费。</strong></p>
<p>此时就要使用另一种结构体了，set ，关于set，C++ 给提供了如下三种可用的数据结构：</p>
<ul>
<li>std::set</li>
<li>std::multiset</li>
<li>std::unordered_set</li>
</ul>
<p>std::set和std::multiset底层实现都是红黑树，std::unordered_set的底层实现是哈希表， 使用unordered_set 读写效率是最高的，并不需要对数据进行排序，而且还不要让数据重复，所以选择unordered_set。</p>
<h3 id="c-unordered-set容器的成员方法："><a href="#c-unordered-set容器的成员方法：" class="headerlink" title="c++ unordered_set容器的成员方法："></a>c++ unordered_set容器的成员方法：</h3><p>find(key): 查找以值为 key 的元素，如果找到，则返回一个指向该元素的正向迭代器；反之，则返回一个指向容器中最后一个元素之后位置的迭代器（如果 end() 方法返回的迭代器）。 </p>
<p>思路如图所示：</p>
<p><img src="C:\Users\WJ\AppData\Roaming\Typora\typora-user-images\image-20211030230213881.png" alt="image-20211030230213881"></p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>349</td>
<td>两个数组的交集（简单难度）</td>
<td></td>
</tr>
</tbody></table>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; intersection(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;</span><br><span class="line">        unordered_set&lt;int&gt; result_set; // 存放结果</span><br><span class="line">        unordered_set&lt;int&gt; nums_set(nums1.begin(), nums1.end());</span><br><span class="line">        for (int num : nums2) &#123;</span><br><span class="line">            // 下面的代码表示：发现nums2的元素 在nums_set里又出现过</span><br><span class="line">            //不理解的话，复习unordered_set的成员方法</span><br><span class="line">            if (nums_set.find(num) != nums_set.end()) &#123;</span><br><span class="line">                result_set.insert(num);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">        return vector&lt;int&gt;(result_set.begin(), result_set.end());</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>

<h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><p>那有同学可能问了，遇到哈希问题我直接都用set不就得了，用什么数组啊。</p>
<p>直接使用set 不仅占用空间比数组大，而且速度要比数组慢，set把数值映射到key上都要做hash计算的。</p>
<p>不要小瞧 这个耗时，在数据量大的情况，差距是很明显的。</p>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>350</td>
<td>两个数组的交集2（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/intersection-of-two-arrays-ii/">350. 两个数组的交集 II - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>这道题和349不一样，没有要求 输出不能重复</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    vector&lt;int&gt; intersect(vector&lt;int&gt;&amp; nums1, vector&lt;int&gt;&amp; nums2) &#123;</span><br><span class="line">        // 对两个数组进行排序</span><br><span class="line">        sort(nums1.begin(),nums1.end());</span><br><span class="line">        sort(nums2.begin(),nums2.end());</span><br><span class="line">        int i=0,j=0;</span><br><span class="line">        vector&lt;int&gt; res;</span><br><span class="line">        //同时对两个数组遍历，有一个遍历完就结束</span><br><span class="line">        while(i&lt;nums1.size() &amp;&amp; j&lt;nums2.size())&#123;</span><br><span class="line">            // 相等，则添加到结果里</span><br><span class="line">            if(nums1[i]==nums2[j])&#123;</span><br><span class="line"></span><br><span class="line">                res.push_back(nums1[i]);</span><br><span class="line">                ++i;</span><br><span class="line">                ++j;</span><br><span class="line">            &#125;</span><br><span class="line">            else if(nums1[i]&lt;nums2[j])</span><br><span class="line">                ++i;</span><br><span class="line">            else                    </span><br><span class="line">               ++j;</span><br><span class="line">        &#125;</span><br><span class="line">        return res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>202</td>
<td>快乐数（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/happy-number/submissions/">202. 快乐数 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>题目中说了会无限循环，即在求和的过程中，sum会重复出现，这一点对解题很重要。</p>
<p>正如：<a target="_blank" rel="noopener" href="https://programmercarl.com/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html">关于哈希表，你该了解这些！</a>中所说，<strong>当我们遇到了要快速判断一个元素是否出现集合里的时候，就要考虑哈希法了。</strong></p>
<p>这道题用哈希法，来判断这个sum是否重复出现，重复则return false， 否则一直找到sum为1为止。</p>
<p>判断sum是否重复出现就可以使用unordered_set。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line">class Solution &#123;</span><br><span class="line">public:</span><br><span class="line">    // 取数值各个位上的单数之和</span><br><span class="line">    int getSum(int n) &#123;</span><br><span class="line">        int sum = 0;</span><br><span class="line">        while (n) &#123;</span><br><span class="line">            sum += (n % 10) * (n % 10);</span><br><span class="line">            n /= 10;</span><br><span class="line">        &#125;</span><br><span class="line">        return sum;</span><br><span class="line">    &#125;</span><br><span class="line">    bool isHappy(int n) &#123;</span><br><span class="line">        unordered_set&lt;int&gt; set;</span><br><span class="line">        while(1) &#123;</span><br><span class="line">            int sum = getSum(n);</span><br><span class="line">            if (sum == 1) &#123;</span><br><span class="line">                return true;</span><br><span class="line">            &#125;</span><br><span class="line">            // 如果这个sum曾经出现过，说明已经陷入了无限循环了，立刻return false</span><br><span class="line">            if (set.find(sum) != set.end()) &#123;</span><br><span class="line">                return false;</span><br><span class="line">            &#125; else &#123;</span><br><span class="line">                set.insert(sum);</span><br><span class="line">            &#125;</span><br><span class="line">            n = sum;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>



<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>1</td>
<td>（简单难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/intersection-of-two-arrays-ii/">1. 两数之和 - 力扣（LeetCode）</a></td>
</tr>
</tbody></table>
<p>则要使用map，那么来看一下使用数组和set来做哈希法的局限。</p>
<ul>
<li><p>数组的大小是受限制的，而且如果元素很少，而哈希值太大会造成内存空间的浪费。</p>
</li>
<li><p>set是一个集合，里面放的元素只能是一个key，而两数之和这道题目，不仅要判断y是否存在而且还要记录y的下标位置，因为要返回x 和 y的下标。所以set 也不能用。</p>
<p>此时就要选择另一种数据结构：map ，map是一种key value的存储结构，可以用key保存数值，用value在保存数值所在的下表。</p>
<p>C++中map，有三种类型：</p>
<table>
<thead>
<tr>
<th>映射</th>
<th>底层实现</th>
<th>是否有序</th>
<th>数值是否可以重复</th>
<th>能否更改数值</th>
<th>查询效率</th>
<th>增删效率</th>
</tr>
</thead>
<tbody><tr>
<td>std::map</td>
<td>红黑树</td>
<td>key有序</td>
<td>key不可重复</td>
<td>key不可修改</td>
<td>O(logn)</td>
<td>O(logn)</td>
</tr>
<tr>
<td>std::multimap</td>
<td>红黑树</td>
<td>key有序</td>
<td>key可重复</td>
<td>key不可修改</td>
<td>O(logn)</td>
<td>O(logn)</td>
</tr>
<tr>
<td>std::unordered_map</td>
<td>哈希表</td>
<td>key无序</td>
<td>key不可重复</td>
<td>key不可修改</td>
<td>O(1)</td>
<td>O(1)</td>
</tr>
</tbody></table>
<p>std::unordered_map 底层实现为哈希表，std::map 和std::multimap 的底层实现是红黑树。</p>
<p>同理，std::map 和std::multimap 的key也是有序的（这个问题也经常作为面试题，考察对语言容器底层的理解）。 更多哈希表的理论知识请看<a target="_blank" rel="noopener" href="https://www.programmercarl.com/%E5%93%88%E5%B8%8C%E8%A1%A8%E7%90%86%E8%AE%BA%E5%9F%BA%E7%A1%80.html">关于哈希表，你该了解这些！</a>。</p>
<p><strong>这道题目中并不需要key有序，选择std::unordered_map 效率更高！</strong></p>
<p><strong>解题思路：</strong></p>
<p>例如：nums&#x3D;[2,7,11,15],target&#x3D;9</p>
<p>遍历数组</p>
<p>1、寻找target-nums[i]是否在map中，</p>
<p>2、没有，9-2&#x3D;7,7不在map中，把2和对应下标0放进map中</p>
<p>3、有，9-7&#x3D;2,2在map中，找到了数值2和7相加等于9，返回其下标</p>
<p>遍历结束后，没有返回值，则返回空的数组</p>
<p>参考链接： <a target="_blank" rel="noopener" href="http://c.biancheng.net/view/7231.html">C++ STL unordered_map容器用法详解 (biancheng.net)</a> </p>
<p>C++代码：</p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    <span class="function">vector&lt;<span class="type">int</span>&gt; <span class="title">twoSum</span><span class="params">(vector&lt;<span class="type">int</span>&gt;&amp; nums, <span class="type">int</span> target)</span> </span>&#123;</span><br><span class="line">        std::unordered_map &lt;<span class="type">int</span>,<span class="type">int</span>&gt; map;<span class="comment">//创建空的umap容器</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i = <span class="number">0</span>; i &lt; nums.<span class="built_in">size</span>(); i++) &#123;</span><br><span class="line">            <span class="comment">//查找target - nums[i]是否在map中，</span></span><br><span class="line">            <span class="keyword">auto</span> iter = map.<span class="built_in">find</span>(target - nums[i]);</span><br><span class="line">            <span class="comment">// 有，返回两个数的下标</span></span><br><span class="line">            <span class="keyword">if</span>(iter != map.<span class="built_in">end</span>()) &#123;</span><br><span class="line">                <span class="keyword">return</span> &#123;iter-&gt;second, i&#125;;</span><br><span class="line">            &#125;</span><br><span class="line">            <span class="comment">// 没有，把该数值和其下标加入到map中</span></span><br><span class="line">            map.<span class="built_in">insert</span>(<span class="built_in">pair</span>&lt;<span class="type">int</span>, <span class="type">int</span>&gt;(nums[i], i));</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="comment">//没找到</span></span><br><span class="line">        <span class="keyword">return</span> &#123;&#125;;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure></li>
</ul>
<table>
<thead>
<tr>
<th><strong>LeetCode题目</strong></th>
<th><strong>相关题目类型</strong></th>
<th><strong>相关链接</strong></th>
</tr>
</thead>
<tbody><tr>
<td>49</td>
<td>（中等难度）</td>
<td><a target="_blank" rel="noopener" href="https://leetcode-cn.com/problems/group-anagrams/">49. 字母异位词分组 - 力扣（LeetCode） (leetcode-cn.com)</a></td>
</tr>
</tbody></table>
<p>参考链接：<a target="_blank" rel="noopener" href="https://blog.csdn.net/fuqiuai/article/details/83589593">https://blog.csdn.net/fuqiuai/article/details/83589593</a></p>
<p>解题思路：</p>
<p>1、对字符串每个词的字母按照字典序进行排序，异位词对字母进行排序后有相同的字母序列。</p>
<p>用排序后的字母序列作为map的key，将所有异位词都保存到字符串数组中，用map建立key和字符串数组之间的映射（不需要结果有序，所以用unordered map)</p>
<p>2、最后把归纳好的字符串数组存入结果res中。</p>
<figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Solution</span> &#123;</span><br><span class="line"><span class="keyword">public</span>:</span><br><span class="line">    vector&lt;vector&lt;string&gt;&gt; <span class="built_in">groupAnagrams</span>(vector&lt;string&gt;&amp; strs) &#123;</span><br><span class="line">        vector&lt;vector&lt;string&gt;&gt; res;</span><br><span class="line">        <span class="keyword">if</span>(strs.<span class="built_in">size</span>()==<span class="number">0</span>)<span class="keyword">return</span> res;</span><br><span class="line">        <span class="comment">// 键为string字符串类型，值为字符串数组类型</span></span><br><span class="line">        unordered_map&lt;string,vector&lt;string&gt;&gt; map1;</span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> i=<span class="number">0</span>;i&lt;strs.<span class="built_in">size</span>();i++)&#123;</span><br><span class="line">            string s=strs[i];</span><br><span class="line">            <span class="built_in">sort</span>(s.<span class="built_in">begin</span>(),s.<span class="built_in">end</span>());</span><br><span class="line">            <span class="comment">// 排序后相同的字符串放到一个数组里，键为排序后的字符串</span></span><br><span class="line">            map1[s].<span class="built_in">push_back</span>(strs[i]);<span class="comment">//map1[s]是一个值类型为字符串的数组</span></span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">for</span>(<span class="keyword">auto</span> v:map1)&#123;</span><br><span class="line">            res.<span class="built_in">push_back</span>(v.second);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">return</span> res;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>


      
    </div>

    
    
    

    <footer class="post-footer">
        <div class="post-eof"></div>
      
    </footer>
  </article>
</div>




  <nav class="pagination">
    <a class="extend prev" rel="prev" title="Previous page" aria-label="Previous page" href="/page/22/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/22/">22</a><span class="page-number current">23</span><a class="page-number" href="/page/24/">24</a><span class="space">&hellip;</span><a class="page-number" href="/page/27/">27</a><a class="extend next" rel="next" title="Next page" aria-label="Next page" href="/page/24/"><i class="fa fa-angle-right"></i></a>
  </nav>

</div>
  </main>

  <footer class="footer">
    <div class="footer-inner">

  <div class="copyright">
    &copy; 
    <span itemprop="copyrightYear">2024</span>
    <span class="with-love">
      <i class="fa fa-heart"></i>
    </span>
    <span class="author" itemprop="copyrightHolder">vvbuys</span>
  </div>
  <div class="powered-by">Powered by <a href="https://hexo.io/" rel="noopener" target="_blank">Hexo</a> & <a href="https://theme-next.js.org/muse/" rel="noopener" target="_blank">NexT.Muse</a>
  </div>

    </div>
  </footer>

  
  <div class="toggle sidebar-toggle" role="button">
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
    <span class="toggle-line"></span>
  </div>
  <div class="sidebar-dimmer"></div>
  <div class="back-to-top" role="button" aria-label="Back to top">
    <i class="fa fa-arrow-up fa-lg"></i>
    <span>0%</span>
  </div>

<noscript>
  <div class="noscript-warning">Theme NexT works best with JavaScript enabled</div>
</noscript>


  
  <script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script>
<script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/next-boot.js"></script>

  






  





</body>
</html>
